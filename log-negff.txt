2025-01-17 06:54:52.187 | INFO     | __main__:<module>:63 - Got args Namespace(max_steps=20000, eval_interval=1000, eval_steps=100, batch_size=16, gradient_accum=32, model_size='124M', tensorboard=1)
2025-01-17 06:54:52.187 | INFO     | __main__:<module>:88 - Training 124M model with config.n_layer=12, config.n_embd=768config.n_head=12, config.context_size=1024, config.dropout=0.0, config.vocab_size=50304
2025-01-17 06:54:54.403 | DEBUG    | __main__:<module>:138 - ddp_rank=0 ddp_local_rank=0
2025-01-17 06:54:54.403 | INFO     | __main__:<module>:152 - Training data is 9,035,582,489 tokens
2025-01-17 06:54:54.403 | INFO     | __main__:<module>:153 - Evaluation data is 4,434,606 tokens
2025-01-17 06:54:54.403 | INFO     | __main__:<module>:160 - job_name='gpt2-training-124M-2025-01-17-06-54-52'
2025-01-17 06:54:54.403 | INFO     | __main__:<module>:161 - Tokens / step: 524,288
2025-01-17 06:54:54.403 | INFO     | __main__:<module>:162 - Total training tokens: 10,485,760,000
2025-01-17 06:54:54.403 | INFO     | __main__:<module>:163 - Effective batch size with grad accumulation: batch_size * gradient_accumulation_steps=512
2025-01-17 06:54:54.403 | DEBUG    | __main__:<module>:164 - gradient_accumulation_steps_per_gpu=32
2025-01-17 06:54:54.404 | DEBUG    | __main__:<module>:165 - Directories: train_dir='/home/v-youransun/repgpt/input/data/train', eval_dir='/home/v-youransun/repgpt/input/data/eval' model_dir='/home/v-youransun/repgpt/model' log_dir='/home/v-youransun/repgpt/output/tensorboard/nov/gpt2-training-124M-2025-01-17-06-54-52'
2025-01-17 06:54:54.404 | INFO     | __main__:<module>:166 - Loaded dataset 2.2177491188049316
2025-01-17 06:54:57.726 | INFO     | __main__:<module>:200 - OptimizedModule(
  (_orig_mod): DistributedDataParallel(
    (module): GPT2(
      (token_embedding_table): Embedding(50304, 768)
      (position_embedding_table): Embedding(1024, 768)
      (blocks): Sequential(
        (0): Transformer(
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (multi_headed_attention): MultiheadedAttention(
            (key): Linear(in_features=768, out_features=768, bias=False)
            (query): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (proj): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=768, out_features=3072, bias=False)
            (activation): GELU(approximate='none')
            (linear2): Linear(in_features=3072, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Transformer(
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (multi_headed_attention): MultiheadedAttention(
            (key): Linear(in_features=768, out_features=768, bias=False)
            (query): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (proj): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=768, out_features=3072, bias=False)
            (activation): GELU(approximate='none')
            (linear2): Linear(in_features=3072, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Transformer(
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (multi_headed_attention): MultiheadedAttention(
            (key): Linear(in_features=768, out_features=768, bias=False)
            (query): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (proj): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=768, out_features=3072, bias=False)
            (activation): GELU(approximate='none')
            (linear2): Linear(in_features=3072, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Transformer(
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (multi_headed_attention): MultiheadedAttention(
            (key): Linear(in_features=768, out_features=768, bias=False)
            (query): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (proj): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=768, out_features=3072, bias=False)
            (activation): GELU(approximate='none')
            (linear2): Linear(in_features=3072, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Transformer(
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (multi_headed_attention): MultiheadedAttention(
            (key): Linear(in_features=768, out_features=768, bias=False)
            (query): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (proj): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=768, out_features=3072, bias=False)
            (activation): GELU(approximate='none')
            (linear2): Linear(in_features=3072, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Transformer(
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (multi_headed_attention): MultiheadedAttention(
            (key): Linear(in_features=768, out_features=768, bias=False)
            (query): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (proj): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=768, out_features=3072, bias=False)
            (activation): GELU(approximate='none')
            (linear2): Linear(in_features=3072, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Transformer(
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (multi_headed_attention): MultiheadedAttention(
            (key): Linear(in_features=768, out_features=768, bias=False)
            (query): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (proj): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=768, out_features=3072, bias=False)
            (activation): GELU(approximate='none')
            (linear2): Linear(in_features=3072, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Transformer(
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (multi_headed_attention): MultiheadedAttention(
            (key): Linear(in_features=768, out_features=768, bias=False)
            (query): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (proj): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=768, out_features=3072, bias=False)
            (activation): GELU(approximate='none')
            (linear2): Linear(in_features=3072, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Transformer(
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (multi_headed_attention): MultiheadedAttention(
            (key): Linear(in_features=768, out_features=768, bias=False)
            (query): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (proj): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=768, out_features=3072, bias=False)
            (activation): GELU(approximate='none')
            (linear2): Linear(in_features=3072, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Transformer(
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (multi_headed_attention): MultiheadedAttention(
            (key): Linear(in_features=768, out_features=768, bias=False)
            (query): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (proj): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=768, out_features=3072, bias=False)
            (activation): GELU(approximate='none')
            (linear2): Linear(in_features=3072, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Transformer(
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (multi_headed_attention): MultiheadedAttention(
            (key): Linear(in_features=768, out_features=768, bias=False)
            (query): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (proj): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=768, out_features=3072, bias=False)
            (activation): GELU(approximate='none')
            (linear2): Linear(in_features=3072, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Transformer(
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (multi_headed_attention): MultiheadedAttention(
            (key): Linear(in_features=768, out_features=768, bias=False)
            (query): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (proj): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=768, out_features=3072, bias=False)
            (activation): GELU(approximate='none')
            (linear2): Linear(in_features=3072, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (layer_norm_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (lm_head): Linear(in_features=768, out_features=50304, bias=False)
    )
  )
)
2025-01-17 06:54:57.726 | INFO     | __main__:<module>:203 - Training model with 123,587,328 parameters for max_steps=20,000 on total_training_tokens=10,485,760,000
2025-01-17 06:54:57.726 | INFO     | __main__:<module>:206 - Decayed parameter tensors: 74, with 124,354,560 parameters
2025-01-17 06:54:57.727 | INFO     | __main__:<module>:207 - Non-decayed parameter tensors: 25, with 19,200 parameters
[rank0]:W0117 06:54:57.745000 27473 torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
2025-01-17 06:55:08.775 | INFO     | __main__:<module>:265 - Step 0/20,000 loss: 10.9870 (T) 10.9877 (V) | lr=0.0e+00
2025-01-17 06:55:08.776 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 06:55:23.415 | DEBUG    | __main__:<module>:313 - Training step 0: loss = 10.9956 | 25685.58ms | Tokens/s = 20,411.8
2025-01-17 06:55:52.476 | DEBUG    | __main__:<module>:313 - Training step 10: loss = 9.3897 | 2919.09ms | Tokens/s = 179,606.6
2025-01-17 06:56:21.854 | DEBUG    | __main__:<module>:313 - Training step 20: loss = 8.7021 | 2951.32ms | Tokens/s = 177,645.5
2025-01-17 06:56:51.495 | DEBUG    | __main__:<module>:313 - Training step 30: loss = 7.9706 | 2973.75ms | Tokens/s = 176,305.6
2025-01-17 06:57:21.310 | DEBUG    | __main__:<module>:313 - Training step 40: loss = 7.3097 | 2981.43ms | Tokens/s = 175,851.4
2025-01-17 06:57:51.220 | DEBUG    | __main__:<module>:313 - Training step 50: loss = 6.8455 | 2996.18ms | Tokens/s = 174,985.5
2025-01-17 06:58:21.238 | DEBUG    | __main__:<module>:313 - Training step 60: loss = 6.5771 | 3004.02ms | Tokens/s = 174,528.9
2025-01-17 06:58:51.314 | DEBUG    | __main__:<module>:313 - Training step 70: loss = 6.7715 | 3007.95ms | Tokens/s = 174,300.8
2025-01-17 06:59:21.420 | DEBUG    | __main__:<module>:313 - Training step 80: loss = 6.4384 | 3012.25ms | Tokens/s = 174,051.9
2025-01-17 06:59:51.560 | DEBUG    | __main__:<module>:313 - Training step 90: loss = 6.2611 | 3013.62ms | Tokens/s = 173,972.7
2025-01-17 07:00:21.719 | DEBUG    | __main__:<module>:313 - Training step 100: loss = 6.0572 | 3014.43ms | Tokens/s = 173,926.2
2025-01-17 07:00:51.886 | DEBUG    | __main__:<module>:313 - Training step 110: loss = 6.2882 | 3016.93ms | Tokens/s = 173,781.7
2025-01-17 07:01:22.064 | DEBUG    | __main__:<module>:313 - Training step 120: loss = 6.1672 | 3017.65ms | Tokens/s = 173,740.3
2025-01-17 07:01:52.253 | DEBUG    | __main__:<module>:313 - Training step 130: loss = 6.0023 | 3018.67ms | Tokens/s = 173,681.9
2025-01-17 07:02:22.445 | DEBUG    | __main__:<module>:313 - Training step 140: loss = 5.8908 | 3019.65ms | Tokens/s = 173,625.5
2025-01-17 07:02:52.641 | DEBUG    | __main__:<module>:313 - Training step 150: loss = 5.8045 | 3019.46ms | Tokens/s = 173,636.5
2025-01-17 07:03:22.849 | DEBUG    | __main__:<module>:313 - Training step 160: loss = 5.9006 | 3020.55ms | Tokens/s = 173,573.9
2025-01-17 07:03:53.062 | DEBUG    | __main__:<module>:313 - Training step 170: loss = 5.9078 | 3018.22ms | Tokens/s = 173,707.8
2025-01-17 07:04:23.251 | DEBUG    | __main__:<module>:313 - Training step 180: loss = 5.7394 | 3017.56ms | Tokens/s = 173,745.9
2025-01-17 07:04:53.420 | DEBUG    | __main__:<module>:313 - Training step 190: loss = 5.9276 | 3016.90ms | Tokens/s = 173,783.9
2025-01-17 07:05:23.617 | DEBUG    | __main__:<module>:313 - Training step 200: loss = 5.7148 | 3018.36ms | Tokens/s = 173,699.8
2025-01-17 07:05:53.779 | DEBUG    | __main__:<module>:313 - Training step 210: loss = 5.5534 | 3014.82ms | Tokens/s = 173,903.4
2025-01-17 07:06:23.942 | DEBUG    | __main__:<module>:313 - Training step 220: loss = 5.7032 | 3016.75ms | Tokens/s = 173,792.4
2025-01-17 07:06:54.132 | DEBUG    | __main__:<module>:313 - Training step 230: loss = 5.5714 | 3018.88ms | Tokens/s = 173,669.7
2025-01-17 07:07:24.327 | DEBUG    | __main__:<module>:313 - Training step 240: loss = 5.4744 | 3019.10ms | Tokens/s = 173,657.3
2025-01-17 07:07:54.534 | DEBUG    | __main__:<module>:313 - Training step 250: loss = 5.5483 | 3020.95ms | Tokens/s = 173,550.5
2025-01-17 07:08:24.741 | DEBUG    | __main__:<module>:313 - Training step 260: loss = 5.5876 | 3021.63ms | Tokens/s = 173,511.5
2025-01-17 07:08:54.963 | DEBUG    | __main__:<module>:313 - Training step 270: loss = 5.4345 | 3021.99ms | Tokens/s = 173,490.9
2025-01-17 07:09:25.186 | DEBUG    | __main__:<module>:313 - Training step 280: loss = 5.3155 | 3021.64ms | Tokens/s = 173,511.1
2025-01-17 07:09:55.409 | DEBUG    | __main__:<module>:313 - Training step 290: loss = 5.3426 | 3024.50ms | Tokens/s = 173,346.7
2025-01-17 07:10:25.644 | DEBUG    | __main__:<module>:313 - Training step 300: loss = 5.3668 | 3022.56ms | Tokens/s = 173,458.2
2025-01-17 07:10:55.882 | DEBUG    | __main__:<module>:313 - Training step 310: loss = 5.1974 | 3025.11ms | Tokens/s = 173,312.0
2025-01-17 07:11:26.116 | DEBUG    | __main__:<module>:313 - Training step 320: loss = 5.2080 | 3022.07ms | Tokens/s = 173,486.6
2025-01-17 07:11:56.354 | DEBUG    | __main__:<module>:313 - Training step 330: loss = 5.2549 | 3025.54ms | Tokens/s = 173,287.5
2025-01-17 07:12:26.601 | DEBUG    | __main__:<module>:313 - Training step 340: loss = 5.2411 | 3025.88ms | Tokens/s = 173,267.7
2025-01-17 07:12:56.837 | DEBUG    | __main__:<module>:313 - Training step 350: loss = 5.0299 | 3025.83ms | Tokens/s = 173,270.9
2025-01-17 07:13:27.054 | DEBUG    | __main__:<module>:313 - Training step 360: loss = 5.0469 | 3019.45ms | Tokens/s = 173,637.1
2025-01-17 07:13:57.267 | DEBUG    | __main__:<module>:313 - Training step 370: loss = 5.2368 | 3022.99ms | Tokens/s = 173,433.7
2025-01-17 07:14:27.491 | DEBUG    | __main__:<module>:313 - Training step 380: loss = 4.9521 | 3022.40ms | Tokens/s = 173,467.6
2025-01-17 07:14:57.713 | DEBUG    | __main__:<module>:313 - Training step 390: loss = 5.0626 | 3022.14ms | Tokens/s = 173,482.3
2025-01-17 07:15:27.946 | DEBUG    | __main__:<module>:313 - Training step 400: loss = 5.0882 | 3024.19ms | Tokens/s = 173,364.7
2025-01-17 07:15:58.186 | DEBUG    | __main__:<module>:313 - Training step 410: loss = 4.7303 | 3023.26ms | Tokens/s = 173,418.3
2025-01-17 07:16:28.427 | DEBUG    | __main__:<module>:313 - Training step 420: loss = 4.7548 | 3022.24ms | Tokens/s = 173,476.4
2025-01-17 07:16:58.676 | DEBUG    | __main__:<module>:313 - Training step 430: loss = 4.7273 | 3024.88ms | Tokens/s = 173,325.0
2025-01-17 07:17:28.922 | DEBUG    | __main__:<module>:313 - Training step 440: loss = 4.8307 | 3026.68ms | Tokens/s = 173,222.0
2025-01-17 07:17:59.184 | DEBUG    | __main__:<module>:313 - Training step 450: loss = 4.8430 | 3027.58ms | Tokens/s = 173,170.8
2025-01-17 07:18:29.436 | DEBUG    | __main__:<module>:313 - Training step 460: loss = 4.7470 | 3024.48ms | Tokens/s = 173,347.9
2025-01-17 07:18:59.697 | DEBUG    | __main__:<module>:313 - Training step 470: loss = 4.6368 | 3025.92ms | Tokens/s = 173,265.4
2025-01-17 07:19:29.952 | DEBUG    | __main__:<module>:313 - Training step 480: loss = 4.7918 | 3026.10ms | Tokens/s = 173,255.3
2025-01-17 07:20:00.218 | DEBUG    | __main__:<module>:313 - Training step 490: loss = 4.8500 | 3024.90ms | Tokens/s = 173,324.2
2025-01-17 07:20:30.473 | DEBUG    | __main__:<module>:313 - Training step 500: loss = 4.4457 | 3023.25ms | Tokens/s = 173,418.7
2025-01-17 07:21:00.741 | DEBUG    | __main__:<module>:313 - Training step 510: loss = 4.5431 | 3028.44ms | Tokens/s = 173,121.7
2025-01-17 07:21:31.007 | DEBUG    | __main__:<module>:313 - Training step 520: loss = 4.5603 | 3028.35ms | Tokens/s = 173,126.5
2025-01-17 07:22:01.274 | DEBUG    | __main__:<module>:313 - Training step 530: loss = 4.4553 | 3027.84ms | Tokens/s = 173,155.8
2025-01-17 07:22:31.543 | DEBUG    | __main__:<module>:313 - Training step 540: loss = 4.5419 | 3026.66ms | Tokens/s = 173,223.2
2025-01-17 07:23:01.815 | DEBUG    | __main__:<module>:313 - Training step 550: loss = 4.4446 | 3026.49ms | Tokens/s = 173,232.7
2025-01-17 07:23:32.078 | DEBUG    | __main__:<module>:313 - Training step 560: loss = 4.4388 | 3027.57ms | Tokens/s = 173,171.1
2025-01-17 07:24:02.348 | DEBUG    | __main__:<module>:313 - Training step 570: loss = 4.4269 | 3028.34ms | Tokens/s = 173,127.3
2025-01-17 07:24:32.618 | DEBUG    | __main__:<module>:313 - Training step 580: loss = 4.3197 | 3026.43ms | Tokens/s = 173,236.3
2025-01-17 07:25:02.854 | DEBUG    | __main__:<module>:313 - Training step 590: loss = 4.3270 | 3023.37ms | Tokens/s = 173,412.0
2025-01-17 07:25:33.089 | DEBUG    | __main__:<module>:313 - Training step 600: loss = 4.4617 | 3020.53ms | Tokens/s = 173,574.9
2025-01-17 07:26:03.331 | DEBUG    | __main__:<module>:313 - Training step 610: loss = 4.3792 | 3024.72ms | Tokens/s = 173,334.6
2025-01-17 07:26:33.585 | DEBUG    | __main__:<module>:313 - Training step 620: loss = 4.3186 | 3023.99ms | Tokens/s = 173,376.4
2025-01-17 07:27:03.845 | DEBUG    | __main__:<module>:313 - Training step 630: loss = 4.2378 | 3026.82ms | Tokens/s = 173,214.3
2025-01-17 07:27:34.062 | DEBUG    | __main__:<module>:313 - Training step 640: loss = 4.3277 | 3018.83ms | Tokens/s = 173,672.7
2025-01-17 07:28:04.281 | DEBUG    | __main__:<module>:313 - Training step 650: loss = 4.1876 | 3023.47ms | Tokens/s = 173,405.9
2025-01-17 07:28:34.514 | DEBUG    | __main__:<module>:313 - Training step 660: loss = 4.1798 | 3024.60ms | Tokens/s = 173,341.1
2025-01-17 07:29:04.759 | DEBUG    | __main__:<module>:313 - Training step 670: loss = 4.2433 | 3024.29ms | Tokens/s = 173,359.1
2025-01-17 07:29:35.005 | DEBUG    | __main__:<module>:313 - Training step 680: loss = 4.1941 | 3026.23ms | Tokens/s = 173,247.9
2025-01-17 07:30:05.262 | DEBUG    | __main__:<module>:313 - Training step 690: loss = 4.1230 | 3026.53ms | Tokens/s = 173,230.8
2025-01-17 07:30:35.520 | DEBUG    | __main__:<module>:313 - Training step 700: loss = 4.1598 | 3022.34ms | Tokens/s = 173,470.9
2025-01-17 07:31:05.783 | DEBUG    | __main__:<module>:313 - Training step 710: loss = 4.0977 | 3024.64ms | Tokens/s = 173,339.2
2025-01-17 07:31:36.038 | DEBUG    | __main__:<module>:313 - Training step 720: loss = 4.1151 | 3024.70ms | Tokens/s = 173,335.6
2025-01-17 07:32:06.263 | DEBUG    | __main__:<module>:313 - Training step 730: loss = 4.1630 | 3023.52ms | Tokens/s = 173,403.2
2025-01-17 07:32:36.500 | DEBUG    | __main__:<module>:313 - Training step 740: loss = 4.1540 | 3024.73ms | Tokens/s = 173,333.7
2025-01-17 07:33:06.739 | DEBUG    | __main__:<module>:313 - Training step 750: loss = 4.0415 | 3024.87ms | Tokens/s = 173,325.7
2025-01-17 07:33:36.991 | DEBUG    | __main__:<module>:313 - Training step 760: loss = 4.0685 | 3025.20ms | Tokens/s = 173,307.2
2025-01-17 07:34:07.229 | DEBUG    | __main__:<module>:313 - Training step 770: loss = 4.0900 | 3022.94ms | Tokens/s = 173,436.6
2025-01-17 07:34:37.442 | DEBUG    | __main__:<module>:313 - Training step 780: loss = 4.0253 | 3023.74ms | Tokens/s = 173,390.6
2025-01-17 07:35:07.667 | DEBUG    | __main__:<module>:313 - Training step 790: loss = 4.0896 | 3024.02ms | Tokens/s = 173,374.6
2025-01-17 07:35:37.902 | DEBUG    | __main__:<module>:313 - Training step 800: loss = 4.0308 | 3024.35ms | Tokens/s = 173,355.8
2025-01-17 07:36:08.146 | DEBUG    | __main__:<module>:313 - Training step 810: loss = 4.1161 | 3025.51ms | Tokens/s = 173,289.1
2025-01-17 07:36:38.393 | DEBUG    | __main__:<module>:313 - Training step 820: loss = 4.0729 | 3023.81ms | Tokens/s = 173,386.8
2025-01-17 07:37:08.639 | DEBUG    | __main__:<module>:313 - Training step 830: loss = 4.0584 | 3022.02ms | Tokens/s = 173,489.5
2025-01-17 07:37:38.849 | DEBUG    | __main__:<module>:313 - Training step 840: loss = 4.2129 | 3018.69ms | Tokens/s = 173,680.5
2025-01-17 07:38:09.073 | DEBUG    | __main__:<module>:313 - Training step 850: loss = 4.0288 | 3022.27ms | Tokens/s = 173,475.1
2025-01-17 07:38:39.303 | DEBUG    | __main__:<module>:313 - Training step 860: loss = 3.7973 | 3021.93ms | Tokens/s = 173,494.6
2025-01-17 07:39:09.539 | DEBUG    | __main__:<module>:313 - Training step 870: loss = 4.2417 | 3022.14ms | Tokens/s = 173,482.5
2025-01-17 07:39:39.770 | DEBUG    | __main__:<module>:313 - Training step 880: loss = 3.9465 | 3021.32ms | Tokens/s = 173,529.7
2025-01-17 07:40:10.003 | DEBUG    | __main__:<module>:313 - Training step 890: loss = 3.9706 | 3023.83ms | Tokens/s = 173,385.6
2025-01-17 07:40:40.241 | DEBUG    | __main__:<module>:313 - Training step 900: loss = 3.9449 | 3024.66ms | Tokens/s = 173,337.9
2025-01-17 07:41:10.484 | DEBUG    | __main__:<module>:313 - Training step 910: loss = 3.9604 | 3025.81ms | Tokens/s = 173,272.0
2025-01-17 07:41:40.736 | DEBUG    | __main__:<module>:313 - Training step 920: loss = 3.8816 | 3024.88ms | Tokens/s = 173,325.0
2025-01-17 07:42:10.983 | DEBUG    | __main__:<module>:313 - Training step 930: loss = 4.0106 | 3022.75ms | Tokens/s = 173,447.2
2025-01-17 07:42:41.226 | DEBUG    | __main__:<module>:313 - Training step 940: loss = 3.9744 | 3023.28ms | Tokens/s = 173,416.7
2025-01-17 07:43:11.454 | DEBUG    | __main__:<module>:313 - Training step 950: loss = 3.8901 | 3023.57ms | Tokens/s = 173,400.5
2025-01-17 07:43:41.689 | DEBUG    | __main__:<module>:313 - Training step 960: loss = 3.8865 | 3024.14ms | Tokens/s = 173,367.6
2025-01-17 07:44:11.932 | DEBUG    | __main__:<module>:313 - Training step 970: loss = 3.9912 | 3024.97ms | Tokens/s = 173,320.0
2025-01-17 07:44:42.179 | DEBUG    | __main__:<module>:313 - Training step 980: loss = 3.9810 | 3025.83ms | Tokens/s = 173,270.6
2025-01-17 07:45:12.415 | DEBUG    | __main__:<module>:313 - Training step 990: loss = 3.9144 | 3023.05ms | Tokens/s = 173,430.2
2025-01-17 07:45:46.046 | INFO     | __main__:<module>:265 - Step 1,000/20,000 loss: 3.9165 (T) 3.9077 (V) | lr=5.0e-03
2025-01-17 07:45:46.047 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 07:45:59.082 | DEBUG    | __main__:<module>:313 - Training step 1000: loss = 3.9058 | 19486.72ms | Tokens/s = 26,904.9
2025-01-17 07:46:29.152 | DEBUG    | __main__:<module>:313 - Training step 1010: loss = 3.8693 | 3011.60ms | Tokens/s = 174,089.7
2025-01-17 07:46:59.321 | DEBUG    | __main__:<module>:313 - Training step 1020: loss = 3.9513 | 3019.99ms | Tokens/s = 173,605.7
2025-01-17 07:47:29.508 | DEBUG    | __main__:<module>:313 - Training step 1030: loss = 3.8862 | 3020.09ms | Tokens/s = 173,600.4
2025-01-17 07:47:59.699 | DEBUG    | __main__:<module>:313 - Training step 1040: loss = 3.9533 | 3017.87ms | Tokens/s = 173,727.8
2025-01-17 07:48:29.895 | DEBUG    | __main__:<module>:313 - Training step 1050: loss = 3.8313 | 3018.37ms | Tokens/s = 173,698.9
2025-01-17 07:49:00.089 | DEBUG    | __main__:<module>:313 - Training step 1060: loss = 3.9773 | 3020.35ms | Tokens/s = 173,585.1
2025-01-17 07:49:30.293 | DEBUG    | __main__:<module>:313 - Training step 1070: loss = 3.9037 | 3018.91ms | Tokens/s = 173,667.9
2025-01-17 07:50:00.493 | DEBUG    | __main__:<module>:313 - Training step 1080: loss = 3.9261 | 3019.85ms | Tokens/s = 173,613.6
2025-01-17 07:50:30.699 | DEBUG    | __main__:<module>:313 - Training step 1090: loss = 3.7552 | 3021.56ms | Tokens/s = 173,515.6
2025-01-17 07:51:00.910 | DEBUG    | __main__:<module>:313 - Training step 1100: loss = 3.7788 | 3020.36ms | Tokens/s = 173,584.4
2025-01-17 07:51:31.110 | DEBUG    | __main__:<module>:313 - Training step 1110: loss = 3.9216 | 3020.70ms | Tokens/s = 173,564.8
2025-01-17 07:52:01.301 | DEBUG    | __main__:<module>:313 - Training step 1120: loss = 3.6817 | 3018.40ms | Tokens/s = 173,697.5
2025-01-17 07:52:31.501 | DEBUG    | __main__:<module>:313 - Training step 1130: loss = 4.0110 | 3022.86ms | Tokens/s = 173,440.9
2025-01-17 07:53:01.697 | DEBUG    | __main__:<module>:313 - Training step 1140: loss = 3.9343 | 3018.03ms | Tokens/s = 173,718.6
2025-01-17 07:53:31.900 | DEBUG    | __main__:<module>:313 - Training step 1150: loss = 3.9435 | 3021.72ms | Tokens/s = 173,506.3
2025-01-17 07:54:02.110 | DEBUG    | __main__:<module>:313 - Training step 1160: loss = 3.9796 | 3019.17ms | Tokens/s = 173,653.2
2025-01-17 07:54:32.314 | DEBUG    | __main__:<module>:313 - Training step 1170: loss = 3.9960 | 3021.03ms | Tokens/s = 173,546.3
2025-01-17 07:55:02.512 | DEBUG    | __main__:<module>:313 - Training step 1180: loss = 3.9585 | 3019.94ms | Tokens/s = 173,608.9
2025-01-17 07:55:32.708 | DEBUG    | __main__:<module>:313 - Training step 1190: loss = 3.8283 | 3019.31ms | Tokens/s = 173,645.0
2025-01-17 07:56:02.913 | DEBUG    | __main__:<module>:313 - Training step 1200: loss = 3.7766 | 3020.13ms | Tokens/s = 173,597.6
2025-01-17 07:56:33.112 | DEBUG    | __main__:<module>:313 - Training step 1210: loss = 3.8445 | 3018.10ms | Tokens/s = 173,714.5
2025-01-17 07:57:03.317 | DEBUG    | __main__:<module>:313 - Training step 1220: loss = 3.6758 | 3022.06ms | Tokens/s = 173,486.8
2025-01-17 07:57:33.514 | DEBUG    | __main__:<module>:313 - Training step 1230: loss = 3.7473 | 3019.60ms | Tokens/s = 173,628.1
2025-01-17 07:58:03.722 | DEBUG    | __main__:<module>:313 - Training step 1240: loss = 3.9026 | 3020.45ms | Tokens/s = 173,579.3
2025-01-17 07:58:33.925 | DEBUG    | __main__:<module>:313 - Training step 1250: loss = 3.7902 | 3021.27ms | Tokens/s = 173,532.3
2025-01-17 07:59:04.132 | DEBUG    | __main__:<module>:313 - Training step 1260: loss = 3.8640 | 3019.55ms | Tokens/s = 173,631.4
2025-01-17 07:59:34.341 | DEBUG    | __main__:<module>:313 - Training step 1270: loss = 3.7653 | 3021.62ms | Tokens/s = 173,512.4
2025-01-17 08:00:04.548 | DEBUG    | __main__:<module>:313 - Training step 1280: loss = 3.7271 | 3020.68ms | Tokens/s = 173,566.1
2025-01-17 08:00:34.744 | DEBUG    | __main__:<module>:313 - Training step 1290: loss = 3.8088 | 3020.09ms | Tokens/s = 173,599.9
2025-01-17 08:01:04.944 | DEBUG    | __main__:<module>:313 - Training step 1300: loss = 3.8423 | 3018.47ms | Tokens/s = 173,693.3
2025-01-17 08:01:35.152 | DEBUG    | __main__:<module>:313 - Training step 1310: loss = 3.8612 | 3020.34ms | Tokens/s = 173,585.8
2025-01-17 08:02:05.380 | DEBUG    | __main__:<module>:313 - Training step 1320: loss = 3.7886 | 3025.03ms | Tokens/s = 173,316.7
2025-01-17 08:02:35.619 | DEBUG    | __main__:<module>:313 - Training step 1330: loss = 3.7844 | 3021.71ms | Tokens/s = 173,506.8
2025-01-17 08:03:05.861 | DEBUG    | __main__:<module>:313 - Training step 1340: loss = 3.7957 | 3024.69ms | Tokens/s = 173,336.0
2025-01-17 08:03:36.117 | DEBUG    | __main__:<module>:313 - Training step 1350: loss = 3.6145 | 3026.92ms | Tokens/s = 173,208.6
2025-01-17 08:04:06.349 | DEBUG    | __main__:<module>:313 - Training step 1360: loss = 3.6496 | 3019.40ms | Tokens/s = 173,640.0
2025-01-17 08:04:36.557 | DEBUG    | __main__:<module>:313 - Training step 1370: loss = 3.6603 | 3023.19ms | Tokens/s = 173,421.9
2025-01-17 08:05:06.798 | DEBUG    | __main__:<module>:313 - Training step 1380: loss = 3.8236 | 3025.58ms | Tokens/s = 173,285.0
2025-01-17 08:05:37.046 | DEBUG    | __main__:<module>:313 - Training step 1390: loss = 3.9211 | 3025.20ms | Tokens/s = 173,306.7
2025-01-17 08:06:07.307 | DEBUG    | __main__:<module>:313 - Training step 1400: loss = 3.6729 | 3025.88ms | Tokens/s = 173,267.9
2025-01-17 08:06:37.567 | DEBUG    | __main__:<module>:313 - Training step 1410: loss = 3.7031 | 3026.17ms | Tokens/s = 173,251.5
2025-01-17 08:07:07.803 | DEBUG    | __main__:<module>:313 - Training step 1420: loss = 3.6944 | 3022.69ms | Tokens/s = 173,450.7
2025-01-17 08:07:38.014 | DEBUG    | __main__:<module>:313 - Training step 1430: loss = 3.8624 | 3022.25ms | Tokens/s = 173,475.8
2025-01-17 08:08:08.245 | DEBUG    | __main__:<module>:313 - Training step 1440: loss = 3.7110 | 3022.94ms | Tokens/s = 173,436.5
2025-01-17 08:08:38.494 | DEBUG    | __main__:<module>:313 - Training step 1450: loss = 3.7740 | 3025.76ms | Tokens/s = 173,275.0
2025-01-17 08:09:08.745 | DEBUG    | __main__:<module>:313 - Training step 1460: loss = 3.6003 | 3025.69ms | Tokens/s = 173,279.0
2025-01-17 08:09:39.006 | DEBUG    | __main__:<module>:313 - Training step 1470: loss = 3.6994 | 3025.96ms | Tokens/s = 173,263.3
2025-01-17 08:10:09.281 | DEBUG    | __main__:<module>:313 - Training step 1480: loss = 3.8389 | 3026.78ms | Tokens/s = 173,216.2
2025-01-17 08:10:39.564 | DEBUG    | __main__:<module>:313 - Training step 1490: loss = 3.4737 | 3028.65ms | Tokens/s = 173,109.7
2025-01-17 08:11:09.825 | DEBUG    | __main__:<module>:313 - Training step 1500: loss = 3.6901 | 3024.11ms | Tokens/s = 173,369.3
2025-01-17 08:11:40.061 | DEBUG    | __main__:<module>:313 - Training step 1510: loss = 3.8861 | 3023.40ms | Tokens/s = 173,410.1
2025-01-17 08:12:10.284 | DEBUG    | __main__:<module>:313 - Training step 1520: loss = 3.7511 | 3023.88ms | Tokens/s = 173,382.4
2025-01-17 08:12:40.522 | DEBUG    | __main__:<module>:313 - Training step 1530: loss = 3.7312 | 3025.07ms | Tokens/s = 173,314.4
2025-01-17 08:13:10.775 | DEBUG    | __main__:<module>:313 - Training step 1540: loss = 3.7519 | 3025.51ms | Tokens/s = 173,289.2
2025-01-17 08:13:41.036 | DEBUG    | __main__:<module>:313 - Training step 1550: loss = 3.8897 | 3026.51ms | Tokens/s = 173,232.0
2025-01-17 08:14:11.305 | DEBUG    | __main__:<module>:313 - Training step 1560: loss = 3.5680 | 3027.39ms | Tokens/s = 173,181.3
2025-01-17 08:14:41.584 | DEBUG    | __main__:<module>:313 - Training step 1570: loss = 3.5971 | 3029.07ms | Tokens/s = 173,085.3
2025-01-17 08:15:11.838 | DEBUG    | __main__:<module>:313 - Training step 1580: loss = 3.5972 | 3022.59ms | Tokens/s = 173,456.5
2025-01-17 08:15:42.065 | DEBUG    | __main__:<module>:313 - Training step 1590: loss = 3.6789 | 3021.96ms | Tokens/s = 173,492.8
2025-01-17 08:16:12.271 | DEBUG    | __main__:<module>:313 - Training step 1600: loss = 3.7759 | 3019.71ms | Tokens/s = 173,621.7
2025-01-17 08:16:42.495 | DEBUG    | __main__:<module>:313 - Training step 1610: loss = 3.8213 | 3024.69ms | Tokens/s = 173,336.2
2025-01-17 08:17:12.757 | DEBUG    | __main__:<module>:313 - Training step 1620: loss = 3.7333 | 3028.18ms | Tokens/s = 173,136.3
2025-01-17 08:17:43.032 | DEBUG    | __main__:<module>:313 - Training step 1630: loss = 3.5225 | 3027.55ms | Tokens/s = 173,172.5
2025-01-17 08:18:13.317 | DEBUG    | __main__:<module>:313 - Training step 1640: loss = 3.8106 | 3029.35ms | Tokens/s = 173,069.4
2025-01-17 08:18:43.590 | DEBUG    | __main__:<module>:313 - Training step 1650: loss = 3.6358 | 3025.55ms | Tokens/s = 173,286.7
2025-01-17 08:19:13.824 | DEBUG    | __main__:<module>:313 - Training step 1660: loss = 3.7712 | 3022.34ms | Tokens/s = 173,470.8
2025-01-17 08:19:44.062 | DEBUG    | __main__:<module>:313 - Training step 1670: loss = 3.5689 | 3027.30ms | Tokens/s = 173,186.7
2025-01-17 08:20:14.324 | DEBUG    | __main__:<module>:313 - Training step 1680: loss = 3.5356 | 3026.76ms | Tokens/s = 173,217.7
2025-01-17 08:20:44.564 | DEBUG    | __main__:<module>:313 - Training step 1690: loss = 3.6368 | 3023.08ms | Tokens/s = 173,428.5
2025-01-17 08:21:14.786 | DEBUG    | __main__:<module>:313 - Training step 1700: loss = 3.6705 | 3021.43ms | Tokens/s = 173,523.0
2025-01-17 08:21:45.039 | DEBUG    | __main__:<module>:313 - Training step 1710: loss = 3.3250 | 3026.37ms | Tokens/s = 173,239.7
2025-01-17 08:22:15.293 | DEBUG    | __main__:<module>:313 - Training step 1720: loss = 3.7309 | 3023.88ms | Tokens/s = 173,382.6
2025-01-17 08:22:45.517 | DEBUG    | __main__:<module>:313 - Training step 1730: loss = 3.7503 | 3022.15ms | Tokens/s = 173,481.9
2025-01-17 08:23:15.747 | DEBUG    | __main__:<module>:313 - Training step 1740: loss = 3.7252 | 3024.88ms | Tokens/s = 173,325.1
2025-01-17 08:23:46.003 | DEBUG    | __main__:<module>:313 - Training step 1750: loss = 3.5114 | 3026.57ms | Tokens/s = 173,228.2
2025-01-17 08:24:16.280 | DEBUG    | __main__:<module>:313 - Training step 1760: loss = 3.7181 | 3026.32ms | Tokens/s = 173,242.9
2025-01-17 08:24:46.543 | DEBUG    | __main__:<module>:313 - Training step 1770: loss = 3.7012 | 3025.02ms | Tokens/s = 173,317.0
2025-01-17 08:25:16.804 | DEBUG    | __main__:<module>:313 - Training step 1780: loss = 3.6427 | 3025.62ms | Tokens/s = 173,283.1
2025-01-17 08:25:47.026 | DEBUG    | __main__:<module>:313 - Training step 1790: loss = 3.6702 | 3025.01ms | Tokens/s = 173,317.7
2025-01-17 08:26:17.278 | DEBUG    | __main__:<module>:313 - Training step 1800: loss = 3.7005 | 3024.88ms | Tokens/s = 173,325.1
2025-01-17 08:26:47.535 | DEBUG    | __main__:<module>:313 - Training step 1810: loss = 3.6881 | 3025.94ms | Tokens/s = 173,264.4
2025-01-17 08:27:17.808 | DEBUG    | __main__:<module>:313 - Training step 1820: loss = 3.6000 | 3025.73ms | Tokens/s = 173,276.7
2025-01-17 08:27:48.079 | DEBUG    | __main__:<module>:313 - Training step 1830: loss = 3.5705 | 3025.35ms | Tokens/s = 173,298.2
2025-01-17 08:28:18.322 | DEBUG    | __main__:<module>:313 - Training step 1840: loss = 3.5279 | 3023.56ms | Tokens/s = 173,400.6
2025-01-17 08:28:48.571 | DEBUG    | __main__:<module>:313 - Training step 1850: loss = 3.6234 | 3024.14ms | Tokens/s = 173,367.5
2025-01-17 08:29:18.825 | DEBUG    | __main__:<module>:313 - Training step 1860: loss = 3.4652 | 3024.23ms | Tokens/s = 173,362.5
2025-01-17 08:29:49.050 | DEBUG    | __main__:<module>:313 - Training step 1870: loss = 3.7437 | 3020.50ms | Tokens/s = 173,576.6
2025-01-17 08:30:19.243 | DEBUG    | __main__:<module>:313 - Training step 1880: loss = 3.5845 | 3020.10ms | Tokens/s = 173,599.6
2025-01-17 08:30:49.443 | DEBUG    | __main__:<module>:313 - Training step 1890: loss = 3.6591 | 3022.24ms | Tokens/s = 173,476.7
2025-01-17 08:31:19.679 | DEBUG    | __main__:<module>:313 - Training step 1900: loss = 3.5340 | 3022.65ms | Tokens/s = 173,453.0
2025-01-17 08:31:49.904 | DEBUG    | __main__:<module>:313 - Training step 1910: loss = 3.5863 | 3021.48ms | Tokens/s = 173,520.5
2025-01-17 08:32:20.123 | DEBUG    | __main__:<module>:313 - Training step 1920: loss = 3.7879 | 3024.07ms | Tokens/s = 173,371.6
2025-01-17 08:32:50.368 | DEBUG    | __main__:<module>:313 - Training step 1930: loss = 3.7454 | 3025.16ms | Tokens/s = 173,309.2
2025-01-17 08:33:20.636 | DEBUG    | __main__:<module>:313 - Training step 1940: loss = 3.6632 | 3027.89ms | Tokens/s = 173,152.7
2025-01-17 08:33:50.898 | DEBUG    | __main__:<module>:313 - Training step 1950: loss = 3.6758 | 3027.30ms | Tokens/s = 173,186.7
2025-01-17 08:34:21.124 | DEBUG    | __main__:<module>:313 - Training step 1960: loss = 3.7555 | 3022.54ms | Tokens/s = 173,459.6
2025-01-17 08:34:51.348 | DEBUG    | __main__:<module>:313 - Training step 1970: loss = 3.5910 | 3024.58ms | Tokens/s = 173,342.6
2025-01-17 08:35:21.606 | DEBUG    | __main__:<module>:313 - Training step 1980: loss = 3.6549 | 3026.39ms | Tokens/s = 173,238.8
2025-01-17 08:35:51.872 | DEBUG    | __main__:<module>:313 - Training step 1990: loss = 3.5879 | 3024.60ms | Tokens/s = 173,341.2
2025-01-17 08:36:25.574 | INFO     | __main__:<module>:265 - Step 2,000/20,000 loss: 3.6486 (T) 3.6366 (V) | lr=1.0e-02
2025-01-17 08:36:25.575 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 08:36:38.745 | DEBUG    | __main__:<module>:313 - Training step 2000: loss = 3.6221 | 19642.75ms | Tokens/s = 26,691.2
2025-01-17 08:37:08.849 | DEBUG    | __main__:<module>:313 - Training step 2010: loss = 3.6691 | 3016.40ms | Tokens/s = 173,812.3
2025-01-17 08:37:39.041 | DEBUG    | __main__:<module>:313 - Training step 2020: loss = 3.6364 | 3021.73ms | Tokens/s = 173,505.8
2025-01-17 08:38:09.264 | DEBUG    | __main__:<module>:313 - Training step 2030: loss = 3.4695 | 3023.92ms | Tokens/s = 173,380.3
2025-01-17 08:38:39.505 | DEBUG    | __main__:<module>:313 - Training step 2040: loss = 3.3847 | 3026.36ms | Tokens/s = 173,240.6
2025-01-17 08:39:09.772 | DEBUG    | __main__:<module>:313 - Training step 2050: loss = 3.5752 | 3027.87ms | Tokens/s = 173,153.9
2025-01-17 08:39:40.040 | DEBUG    | __main__:<module>:313 - Training step 2060: loss = 3.4524 | 3027.21ms | Tokens/s = 173,191.6
2025-01-17 08:40:10.313 | DEBUG    | __main__:<module>:313 - Training step 2070: loss = 3.3801 | 3027.81ms | Tokens/s = 173,157.2
2025-01-17 08:40:40.597 | DEBUG    | __main__:<module>:313 - Training step 2080: loss = 3.5905 | 3029.74ms | Tokens/s = 173,047.0
2025-01-17 08:41:10.878 | DEBUG    | __main__:<module>:313 - Training step 2090: loss = 3.7341 | 3025.61ms | Tokens/s = 173,283.3
2025-01-17 08:41:41.112 | DEBUG    | __main__:<module>:313 - Training step 2100: loss = 3.7668 | 3022.87ms | Tokens/s = 173,440.4
2025-01-17 08:42:11.352 | DEBUG    | __main__:<module>:313 - Training step 2110: loss = 3.6663 | 3025.41ms | Tokens/s = 173,294.8
2025-01-17 08:42:41.607 | DEBUG    | __main__:<module>:313 - Training step 2120: loss = 3.5896 | 3026.32ms | Tokens/s = 173,242.5
2025-01-17 08:43:11.861 | DEBUG    | __main__:<module>:313 - Training step 2130: loss = 3.5966 | 3025.44ms | Tokens/s = 173,293.0
2025-01-17 08:43:42.097 | DEBUG    | __main__:<module>:313 - Training step 2140: loss = 3.6920 | 3026.02ms | Tokens/s = 173,259.7
2025-01-17 08:44:12.349 | DEBUG    | __main__:<module>:313 - Training step 2150: loss = 3.6161 | 3026.09ms | Tokens/s = 173,255.8
2025-01-17 08:44:42.611 | DEBUG    | __main__:<module>:313 - Training step 2160: loss = 3.5245 | 3027.83ms | Tokens/s = 173,156.2
2025-01-17 08:45:12.876 | DEBUG    | __main__:<module>:313 - Training step 2170: loss = 3.6755 | 3025.17ms | Tokens/s = 173,308.5
2025-01-17 08:45:43.102 | DEBUG    | __main__:<module>:313 - Training step 2180: loss = 3.5776 | 3019.61ms | Tokens/s = 173,627.6
2025-01-17 08:46:13.309 | DEBUG    | __main__:<module>:313 - Training step 2190: loss = 3.8047 | 3024.15ms | Tokens/s = 173,367.3
2025-01-17 08:46:43.533 | DEBUG    | __main__:<module>:313 - Training step 2200: loss = 3.6507 | 3023.08ms | Tokens/s = 173,428.3
2025-01-17 08:47:13.785 | DEBUG    | __main__:<module>:313 - Training step 2210: loss = 3.7437 | 3027.56ms | Tokens/s = 173,172.0
2025-01-17 08:47:44.051 | DEBUG    | __main__:<module>:313 - Training step 2220: loss = 3.6114 | 3027.90ms | Tokens/s = 173,152.3
2025-01-17 08:48:14.313 | DEBUG    | __main__:<module>:313 - Training step 2230: loss = 3.6355 | 3024.22ms | Tokens/s = 173,362.9
2025-01-17 08:48:44.580 | DEBUG    | __main__:<module>:313 - Training step 2240: loss = 3.5888 | 3026.27ms | Tokens/s = 173,245.8
2025-01-17 08:49:14.850 | DEBUG    | __main__:<module>:313 - Training step 2250: loss = 3.6906 | 3022.33ms | Tokens/s = 173,471.2
2025-01-17 08:49:45.070 | DEBUG    | __main__:<module>:313 - Training step 2260: loss = 3.8886 | 3020.12ms | Tokens/s = 173,598.5
2025-01-17 08:50:15.274 | DEBUG    | __main__:<module>:313 - Training step 2270: loss = 4.1172 | 3022.81ms | Tokens/s = 173,443.7
2025-01-17 08:50:45.503 | DEBUG    | __main__:<module>:313 - Training step 2280: loss = 3.7833 | 3022.97ms | Tokens/s = 173,434.9
2025-01-17 08:51:15.750 | DEBUG    | __main__:<module>:313 - Training step 2290: loss = 3.5903 | 3025.82ms | Tokens/s = 173,271.3
2025-01-17 08:51:46.010 | DEBUG    | __main__:<module>:313 - Training step 2300: loss = 3.5844 | 3024.41ms | Tokens/s = 173,352.0
2025-01-17 08:52:16.231 | DEBUG    | __main__:<module>:313 - Training step 2310: loss = 3.5577 | 3020.69ms | Tokens/s = 173,565.9
2025-01-17 08:52:46.438 | DEBUG    | __main__:<module>:313 - Training step 2320: loss = 3.6554 | 3023.65ms | Tokens/s = 173,395.7
2025-01-17 08:53:16.673 | DEBUG    | __main__:<module>:313 - Training step 2330: loss = 3.6350 | 3024.13ms | Tokens/s = 173,368.2
2025-01-17 08:53:46.922 | DEBUG    | __main__:<module>:313 - Training step 2340: loss = 3.4270 | 3026.67ms | Tokens/s = 173,222.6
2025-01-17 08:54:17.179 | DEBUG    | __main__:<module>:313 - Training step 2350: loss = 3.6537 | 3026.00ms | Tokens/s = 173,261.1
2025-01-17 08:54:47.413 | DEBUG    | __main__:<module>:313 - Training step 2360: loss = 3.4054 | 3024.58ms | Tokens/s = 173,342.4
2025-01-17 08:55:17.625 | DEBUG    | __main__:<module>:313 - Training step 2370: loss = 3.5212 | 3022.35ms | Tokens/s = 173,470.4
2025-01-17 08:55:47.863 | DEBUG    | __main__:<module>:313 - Training step 2380: loss = 3.5114 | 3024.35ms | Tokens/s = 173,355.7
2025-01-17 08:56:18.112 | DEBUG    | __main__:<module>:313 - Training step 2390: loss = 3.6385 | 3024.41ms | Tokens/s = 173,352.3
2025-01-17 08:56:48.327 | DEBUG    | __main__:<module>:313 - Training step 2400: loss = 3.5075 | 3019.09ms | Tokens/s = 173,657.6
2025-01-17 08:57:18.541 | DEBUG    | __main__:<module>:313 - Training step 2410: loss = 3.5798 | 3022.69ms | Tokens/s = 173,450.6
2025-01-17 08:57:48.784 | DEBUG    | __main__:<module>:313 - Training step 2420: loss = 3.5067 | 3023.34ms | Tokens/s = 173,413.7
2025-01-17 08:58:19.018 | DEBUG    | __main__:<module>:313 - Training step 2430: loss = 3.5033 | 3022.33ms | Tokens/s = 173,471.6
2025-01-17 08:58:49.242 | DEBUG    | __main__:<module>:313 - Training step 2440: loss = 3.6991 | 3022.75ms | Tokens/s = 173,447.6
2025-01-17 08:59:19.483 | DEBUG    | __main__:<module>:313 - Training step 2450: loss = 3.5404 | 3024.27ms | Tokens/s = 173,360.4
2025-01-17 08:59:49.738 | DEBUG    | __main__:<module>:313 - Training step 2460: loss = 3.6471 | 3023.81ms | Tokens/s = 173,386.8
2025-01-17 09:00:19.969 | DEBUG    | __main__:<module>:313 - Training step 2470: loss = 3.6848 | 3022.74ms | Tokens/s = 173,448.2
2025-01-17 09:00:50.171 | DEBUG    | __main__:<module>:313 - Training step 2480: loss = 3.5649 | 3019.69ms | Tokens/s = 173,623.0
2025-01-17 09:01:20.367 | DEBUG    | __main__:<module>:313 - Training step 2490: loss = 3.5570 | 3020.72ms | Tokens/s = 173,564.0
2025-01-17 09:01:50.581 | DEBUG    | __main__:<module>:313 - Training step 2500: loss = 3.6925 | 3021.18ms | Tokens/s = 173,537.4
2025-01-17 09:02:20.803 | DEBUG    | __main__:<module>:313 - Training step 2510: loss = 3.6197 | 3023.01ms | Tokens/s = 173,432.6
2025-01-17 09:02:51.023 | DEBUG    | __main__:<module>:313 - Training step 2520: loss = 3.4868 | 3021.00ms | Tokens/s = 173,547.7
2025-01-17 09:03:21.265 | DEBUG    | __main__:<module>:313 - Training step 2530: loss = 3.5909 | 3025.06ms | Tokens/s = 173,314.8
2025-01-17 09:03:51.529 | DEBUG    | __main__:<module>:313 - Training step 2540: loss = 3.5442 | 3027.14ms | Tokens/s = 173,195.9
2025-01-17 09:04:21.804 | DEBUG    | __main__:<module>:313 - Training step 2550: loss = 3.5148 | 3025.74ms | Tokens/s = 173,276.0
2025-01-17 09:04:52.068 | DEBUG    | __main__:<module>:313 - Training step 2560: loss = 3.6566 | 3025.59ms | Tokens/s = 173,284.6
2025-01-17 09:05:22.327 | DEBUG    | __main__:<module>:313 - Training step 2570: loss = 3.5790 | 3028.01ms | Tokens/s = 173,146.3
2025-01-17 09:05:52.583 | DEBUG    | __main__:<module>:313 - Training step 2580: loss = 3.4514 | 3025.90ms | Tokens/s = 173,266.7
2025-01-17 09:06:22.835 | DEBUG    | __main__:<module>:313 - Training step 2590: loss = 3.3145 | 3024.20ms | Tokens/s = 173,364.4
2025-01-17 09:06:53.086 | DEBUG    | __main__:<module>:313 - Training step 2600: loss = 3.5355 | 3022.98ms | Tokens/s = 173,434.2
2025-01-17 09:07:23.339 | DEBUG    | __main__:<module>:313 - Training step 2610: loss = 3.4528 | 3026.44ms | Tokens/s = 173,236.0
2025-01-17 09:07:53.585 | DEBUG    | __main__:<module>:313 - Training step 2620: loss = 3.5990 | 3025.57ms | Tokens/s = 173,285.6
2025-01-17 09:08:23.840 | DEBUG    | __main__:<module>:313 - Training step 2630: loss = 3.6277 | 3024.95ms | Tokens/s = 173,321.1
2025-01-17 09:08:54.104 | DEBUG    | __main__:<module>:313 - Training step 2640: loss = 3.4829 | 3026.63ms | Tokens/s = 173,225.1
2025-01-17 09:09:24.365 | DEBUG    | __main__:<module>:313 - Training step 2650: loss = 3.5276 | 3026.89ms | Tokens/s = 173,210.2
2025-01-17 09:09:54.642 | DEBUG    | __main__:<module>:313 - Training step 2660: loss = 3.5369 | 3028.10ms | Tokens/s = 173,140.9
2025-01-17 09:10:24.922 | DEBUG    | __main__:<module>:313 - Training step 2670: loss = 3.7651 | 3027.88ms | Tokens/s = 173,153.2
2025-01-17 09:10:55.202 | DEBUG    | __main__:<module>:313 - Training step 2680: loss = 3.6457 | 3027.80ms | Tokens/s = 173,157.9
2025-01-17 09:11:25.475 | DEBUG    | __main__:<module>:313 - Training step 2690: loss = 3.6912 | 3025.84ms | Tokens/s = 173,270.1
2025-01-17 09:11:55.751 | DEBUG    | __main__:<module>:313 - Training step 2700: loss = 3.4483 | 3027.25ms | Tokens/s = 173,189.7
2025-01-17 09:12:26.026 | DEBUG    | __main__:<module>:313 - Training step 2710: loss = 3.6457 | 3025.91ms | Tokens/s = 173,266.2
2025-01-17 09:12:56.299 | DEBUG    | __main__:<module>:313 - Training step 2720: loss = 3.4826 | 3027.30ms | Tokens/s = 173,186.9
2025-01-17 09:13:26.574 | DEBUG    | __main__:<module>:313 - Training step 2730: loss = 3.5257 | 3028.36ms | Tokens/s = 173,125.8
2025-01-17 09:13:56.848 | DEBUG    | __main__:<module>:313 - Training step 2740: loss = 3.7259 | 3027.64ms | Tokens/s = 173,167.5
2025-01-17 09:14:27.121 | DEBUG    | __main__:<module>:313 - Training step 2750: loss = 3.6531 | 3027.31ms | Tokens/s = 173,186.0
2025-01-17 09:14:57.390 | DEBUG    | __main__:<module>:313 - Training step 2760: loss = 3.5399 | 3025.60ms | Tokens/s = 173,284.2
2025-01-17 09:15:27.652 | DEBUG    | __main__:<module>:313 - Training step 2770: loss = 3.7167 | 3026.44ms | Tokens/s = 173,235.9
2025-01-17 09:15:57.924 | DEBUG    | __main__:<module>:313 - Training step 2780: loss = 3.3836 | 3025.95ms | Tokens/s = 173,264.2
2025-01-17 09:16:28.193 | DEBUG    | __main__:<module>:313 - Training step 2790: loss = 3.5224 | 3029.59ms | Tokens/s = 173,055.8
2025-01-17 09:16:58.460 | DEBUG    | __main__:<module>:313 - Training step 2800: loss = 3.6179 | 3024.71ms | Tokens/s = 173,335.0
2025-01-17 09:17:28.727 | DEBUG    | __main__:<module>:313 - Training step 2810: loss = 3.7327 | 3026.72ms | Tokens/s = 173,219.9
2025-01-17 09:17:58.996 | DEBUG    | __main__:<module>:313 - Training step 2820: loss = 3.4895 | 3025.81ms | Tokens/s = 173,271.9
2025-01-17 09:18:29.256 | DEBUG    | __main__:<module>:313 - Training step 2830: loss = 3.5088 | 3025.75ms | Tokens/s = 173,275.5
2025-01-17 09:18:59.528 | DEBUG    | __main__:<module>:313 - Training step 2840: loss = 3.5013 | 3026.94ms | Tokens/s = 173,207.3
2025-01-17 09:19:29.807 | DEBUG    | __main__:<module>:313 - Training step 2850: loss = 3.6134 | 3026.21ms | Tokens/s = 173,249.3
2025-01-17 09:20:00.083 | DEBUG    | __main__:<module>:313 - Training step 2860: loss = 3.4783 | 3028.03ms | Tokens/s = 173,145.2
2025-01-17 09:20:30.378 | DEBUG    | __main__:<module>:313 - Training step 2870: loss = 3.5207 | 3030.51ms | Tokens/s = 173,003.4
2025-01-17 09:21:00.667 | DEBUG    | __main__:<module>:313 - Training step 2880: loss = 3.3496 | 3028.31ms | Tokens/s = 173,129.1
2025-01-17 09:21:30.958 | DEBUG    | __main__:<module>:313 - Training step 2890: loss = 3.5012 | 3028.06ms | Tokens/s = 173,143.2
2025-01-17 09:22:01.240 | DEBUG    | __main__:<module>:313 - Training step 2900: loss = 3.4095 | 3027.87ms | Tokens/s = 173,154.1
2025-01-17 09:22:31.520 | DEBUG    | __main__:<module>:313 - Training step 2910: loss = 3.2676 | 3027.64ms | Tokens/s = 173,167.0
2025-01-17 09:23:01.802 | DEBUG    | __main__:<module>:313 - Training step 2920: loss = 3.6007 | 3028.02ms | Tokens/s = 173,145.5
2025-01-17 09:23:32.087 | DEBUG    | __main__:<module>:313 - Training step 2930: loss = 3.6750 | 3027.77ms | Tokens/s = 173,159.6
2025-01-17 09:24:02.377 | DEBUG    | __main__:<module>:313 - Training step 2940: loss = 3.5259 | 3028.89ms | Tokens/s = 173,095.6
2025-01-17 09:24:32.662 | DEBUG    | __main__:<module>:313 - Training step 2950: loss = 3.6481 | 3028.78ms | Tokens/s = 173,102.1
2025-01-17 09:25:02.945 | DEBUG    | __main__:<module>:313 - Training step 2960: loss = 3.3524 | 3028.44ms | Tokens/s = 173,121.3
2025-01-17 09:25:33.228 | DEBUG    | __main__:<module>:313 - Training step 2970: loss = 3.2712 | 3028.75ms | Tokens/s = 173,103.6
2025-01-17 09:26:03.502 | DEBUG    | __main__:<module>:313 - Training step 2980: loss = 3.7366 | 3026.02ms | Tokens/s = 173,259.7
2025-01-17 09:26:33.768 | DEBUG    | __main__:<module>:313 - Training step 2990: loss = 3.6094 | 3024.90ms | Tokens/s = 173,324.0
2025-01-17 09:27:07.470 | INFO     | __main__:<module>:265 - Step 3,000/20,000 loss: 3.5352 (T) 3.5163 (V) | lr=9.9e-03
2025-01-17 09:27:07.471 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 09:27:20.520 | DEBUG    | __main__:<module>:313 - Training step 3000: loss = 3.4616 | 19516.36ms | Tokens/s = 26,864.0
2025-01-17 09:27:50.646 | DEBUG    | __main__:<module>:313 - Training step 3010: loss = 3.5324 | 3020.54ms | Tokens/s = 173,574.2
2025-01-17 09:28:20.891 | DEBUG    | __main__:<module>:313 - Training step 3020: loss = 3.6918 | 3029.22ms | Tokens/s = 173,077.2
2025-01-17 09:28:51.170 | DEBUG    | __main__:<module>:313 - Training step 3030: loss = 3.6327 | 3026.07ms | Tokens/s = 173,257.1
2025-01-17 09:29:21.455 | DEBUG    | __main__:<module>:313 - Training step 3040: loss = 3.4317 | 3028.85ms | Tokens/s = 173,098.2
2025-01-17 09:29:51.731 | DEBUG    | __main__:<module>:313 - Training step 3050: loss = 3.6102 | 3027.64ms | Tokens/s = 173,167.2
2025-01-17 09:30:22.007 | DEBUG    | __main__:<module>:313 - Training step 3060: loss = 3.5905 | 3025.93ms | Tokens/s = 173,265.1
2025-01-17 09:30:52.283 | DEBUG    | __main__:<module>:313 - Training step 3070: loss = 3.5121 | 3028.00ms | Tokens/s = 173,146.7
2025-01-17 09:31:22.563 | DEBUG    | __main__:<module>:313 - Training step 3080: loss = 3.7129 | 3026.69ms | Tokens/s = 173,221.3
2025-01-17 09:31:52.838 | DEBUG    | __main__:<module>:313 - Training step 3090: loss = 3.5756 | 3027.20ms | Tokens/s = 173,192.6
2025-01-17 09:32:23.111 | DEBUG    | __main__:<module>:313 - Training step 3100: loss = 3.4958 | 3027.21ms | Tokens/s = 173,191.9
2025-01-17 09:32:53.388 | DEBUG    | __main__:<module>:313 - Training step 3110: loss = 3.4589 | 3029.76ms | Tokens/s = 173,046.1
2025-01-17 09:33:23.672 | DEBUG    | __main__:<module>:313 - Training step 3120: loss = 3.5002 | 3028.60ms | Tokens/s = 173,112.4
2025-01-17 09:33:53.954 | DEBUG    | __main__:<module>:313 - Training step 3130: loss = 3.4838 | 3027.44ms | Tokens/s = 173,178.4
2025-01-17 09:34:24.227 | DEBUG    | __main__:<module>:313 - Training step 3140: loss = 3.6277 | 3027.58ms | Tokens/s = 173,170.5
2025-01-17 09:34:54.498 | DEBUG    | __main__:<module>:313 - Training step 3150: loss = 3.5012 | 3027.26ms | Tokens/s = 173,188.9
2025-01-17 09:35:24.777 | DEBUG    | __main__:<module>:313 - Training step 3160: loss = 3.6020 | 3029.40ms | Tokens/s = 173,066.7
2025-01-17 09:35:55.080 | DEBUG    | __main__:<module>:313 - Training step 3170: loss = 3.4955 | 3029.24ms | Tokens/s = 173,075.9
2025-01-17 09:36:25.377 | DEBUG    | __main__:<module>:313 - Training step 3180: loss = 3.6432 | 3030.17ms | Tokens/s = 173,022.7
2025-01-17 09:36:55.667 | DEBUG    | __main__:<module>:313 - Training step 3190: loss = 3.4366 | 3030.39ms | Tokens/s = 173,010.2
2025-01-17 09:37:25.959 | DEBUG    | __main__:<module>:313 - Training step 3200: loss = 3.4246 | 3028.62ms | Tokens/s = 173,111.4
2025-01-17 09:37:56.253 | DEBUG    | __main__:<module>:313 - Training step 3210: loss = 3.3297 | 3031.21ms | Tokens/s = 172,963.5
2025-01-17 09:38:26.545 | DEBUG    | __main__:<module>:313 - Training step 3220: loss = 3.5179 | 3028.04ms | Tokens/s = 173,144.5
2025-01-17 09:38:56.834 | DEBUG    | __main__:<module>:313 - Training step 3230: loss = 3.5320 | 3030.41ms | Tokens/s = 173,009.0
2025-01-17 09:39:27.110 | DEBUG    | __main__:<module>:313 - Training step 3240: loss = 3.4411 | 3027.63ms | Tokens/s = 173,167.8
2025-01-17 09:39:57.389 | DEBUG    | __main__:<module>:313 - Training step 3250: loss = 3.3372 | 3026.69ms | Tokens/s = 173,221.3
2025-01-17 09:40:27.670 | DEBUG    | __main__:<module>:313 - Training step 3260: loss = 3.5332 | 3028.47ms | Tokens/s = 173,119.9
2025-01-17 09:40:57.948 | DEBUG    | __main__:<module>:313 - Training step 3270: loss = 3.5263 | 3027.79ms | Tokens/s = 173,158.8
2025-01-17 09:41:28.230 | DEBUG    | __main__:<module>:313 - Training step 3280: loss = 3.5847 | 3028.91ms | Tokens/s = 173,094.6
2025-01-17 09:41:58.508 | DEBUG    | __main__:<module>:313 - Training step 3290: loss = 3.6385 | 3029.28ms | Tokens/s = 173,073.6
2025-01-17 09:42:28.790 | DEBUG    | __main__:<module>:313 - Training step 3300: loss = 3.5807 | 3029.94ms | Tokens/s = 173,035.7
2025-01-17 09:42:59.072 | DEBUG    | __main__:<module>:313 - Training step 3310: loss = 3.5360 | 3030.09ms | Tokens/s = 173,027.4
2025-01-17 09:43:29.357 | DEBUG    | __main__:<module>:313 - Training step 3320: loss = 3.6070 | 3028.32ms | Tokens/s = 173,128.3
2025-01-17 09:43:59.645 | DEBUG    | __main__:<module>:313 - Training step 3330: loss = 3.5335 | 3028.93ms | Tokens/s = 173,093.7
2025-01-17 09:44:29.930 | DEBUG    | __main__:<module>:313 - Training step 3340: loss = 3.5469 | 3028.44ms | Tokens/s = 173,121.6
2025-01-17 09:45:00.213 | DEBUG    | __main__:<module>:313 - Training step 3350: loss = 3.3755 | 3027.53ms | Tokens/s = 173,173.6
2025-01-17 09:45:30.495 | DEBUG    | __main__:<module>:313 - Training step 3360: loss = 3.4470 | 3028.70ms | Tokens/s = 173,106.7
2025-01-17 09:46:00.777 | DEBUG    | __main__:<module>:313 - Training step 3370: loss = 3.3329 | 3027.31ms | Tokens/s = 173,186.1
2025-01-17 09:46:31.055 | DEBUG    | __main__:<module>:313 - Training step 3380: loss = 3.4055 | 3028.82ms | Tokens/s = 173,099.5
2025-01-17 09:47:01.343 | DEBUG    | __main__:<module>:313 - Training step 3390: loss = 3.7060 | 3028.36ms | Tokens/s = 173,126.3
2025-01-17 09:47:31.628 | DEBUG    | __main__:<module>:313 - Training step 3400: loss = 3.4386 | 3027.21ms | Tokens/s = 173,192.0
2025-01-17 09:48:01.911 | DEBUG    | __main__:<module>:313 - Training step 3410: loss = 3.5149 | 3028.87ms | Tokens/s = 173,097.2
2025-01-17 09:48:32.196 | DEBUG    | __main__:<module>:313 - Training step 3420: loss = 3.5763 | 3029.03ms | Tokens/s = 173,087.7
2025-01-17 09:49:02.471 | DEBUG    | __main__:<module>:313 - Training step 3430: loss = 3.6270 | 3027.27ms | Tokens/s = 173,188.2
2025-01-17 09:49:32.757 | DEBUG    | __main__:<module>:313 - Training step 3440: loss = 3.3084 | 3028.76ms | Tokens/s = 173,103.1
2025-01-17 09:50:03.043 | DEBUG    | __main__:<module>:313 - Training step 3450: loss = 3.6747 | 3029.18ms | Tokens/s = 173,079.4
2025-01-17 09:50:33.323 | DEBUG    | __main__:<module>:313 - Training step 3460: loss = 3.3681 | 3029.32ms | Tokens/s = 173,071.4
2025-01-17 09:51:03.600 | DEBUG    | __main__:<module>:313 - Training step 3470: loss = 3.4983 | 3025.60ms | Tokens/s = 173,283.7
2025-01-17 09:51:33.864 | DEBUG    | __main__:<module>:313 - Training step 3480: loss = 3.3345 | 3025.53ms | Tokens/s = 173,288.0
2025-01-17 09:52:04.137 | DEBUG    | __main__:<module>:313 - Training step 3490: loss = 3.3036 | 3027.68ms | Tokens/s = 173,164.8
2025-01-17 09:52:34.423 | DEBUG    | __main__:<module>:313 - Training step 3500: loss = 3.6267 | 3027.61ms | Tokens/s = 173,168.9
2025-01-17 09:53:04.709 | DEBUG    | __main__:<module>:313 - Training step 3510: loss = 3.5124 | 3028.48ms | Tokens/s = 173,119.0
2025-01-17 09:53:35.001 | DEBUG    | __main__:<module>:313 - Training step 3520: loss = 3.4075 | 3031.50ms | Tokens/s = 172,946.6
2025-01-17 09:54:05.281 | DEBUG    | __main__:<module>:313 - Training step 3530: loss = 3.4826 | 3026.23ms | Tokens/s = 173,247.9
2025-01-17 09:54:35.558 | DEBUG    | __main__:<module>:313 - Training step 3540: loss = 3.3023 | 3026.25ms | Tokens/s = 173,246.7
2025-01-17 09:55:05.837 | DEBUG    | __main__:<module>:313 - Training step 3550: loss = 3.4094 | 3028.54ms | Tokens/s = 173,115.8
2025-01-17 09:55:36.112 | DEBUG    | __main__:<module>:313 - Training step 3560: loss = 3.5190 | 3028.03ms | Tokens/s = 173,145.0
2025-01-17 09:56:06.393 | DEBUG    | __main__:<module>:313 - Training step 3570: loss = 3.4185 | 3028.30ms | Tokens/s = 173,129.3
2025-01-17 09:56:36.675 | DEBUG    | __main__:<module>:313 - Training step 3580: loss = 3.3703 | 3030.71ms | Tokens/s = 172,992.0
2025-01-17 09:57:06.956 | DEBUG    | __main__:<module>:313 - Training step 3590: loss = 3.5676 | 3027.09ms | Tokens/s = 173,198.4
2025-01-17 09:57:37.237 | DEBUG    | __main__:<module>:313 - Training step 3600: loss = 3.6016 | 3026.18ms | Tokens/s = 173,250.8
2025-01-17 09:58:07.517 | DEBUG    | __main__:<module>:313 - Training step 3610: loss = 3.3614 | 3029.74ms | Tokens/s = 173,047.2
2025-01-17 09:58:37.799 | DEBUG    | __main__:<module>:313 - Training step 3620: loss = 3.4617 | 3027.51ms | Tokens/s = 173,174.6
2025-01-17 09:59:08.080 | DEBUG    | __main__:<module>:313 - Training step 3630: loss = 3.6234 | 3028.50ms | Tokens/s = 173,117.8
2025-01-17 09:59:38.352 | DEBUG    | __main__:<module>:313 - Training step 3640: loss = 3.4633 | 3027.58ms | Tokens/s = 173,170.7
2025-01-17 10:00:08.625 | DEBUG    | __main__:<module>:313 - Training step 3650: loss = 3.4928 | 3027.58ms | Tokens/s = 173,170.5
2025-01-17 10:00:38.903 | DEBUG    | __main__:<module>:313 - Training step 3660: loss = 3.4135 | 3027.00ms | Tokens/s = 173,204.1
2025-01-17 10:01:09.184 | DEBUG    | __main__:<module>:313 - Training step 3670: loss = 3.4543 | 3028.41ms | Tokens/s = 173,123.1
2025-01-17 10:01:39.460 | DEBUG    | __main__:<module>:313 - Training step 3680: loss = 3.5347 | 3028.65ms | Tokens/s = 173,109.6
2025-01-17 10:02:09.740 | DEBUG    | __main__:<module>:313 - Training step 3690: loss = 3.3752 | 3027.70ms | Tokens/s = 173,163.7
2025-01-17 10:02:40.017 | DEBUG    | __main__:<module>:313 - Training step 3700: loss = 3.4048 | 3026.02ms | Tokens/s = 173,260.2
2025-01-17 10:03:10.298 | DEBUG    | __main__:<module>:313 - Training step 3710: loss = 3.6142 | 3028.16ms | Tokens/s = 173,137.2
2025-01-17 10:03:40.572 | DEBUG    | __main__:<module>:313 - Training step 3720: loss = 3.3241 | 3030.09ms | Tokens/s = 173,027.1
2025-01-17 10:04:10.866 | DEBUG    | __main__:<module>:313 - Training step 3730: loss = 3.3731 | 3029.76ms | Tokens/s = 173,046.1
2025-01-17 10:04:41.153 | DEBUG    | __main__:<module>:313 - Training step 3740: loss = 3.4913 | 3028.17ms | Tokens/s = 173,137.0
2025-01-17 10:05:11.415 | DEBUG    | __main__:<module>:313 - Training step 3750: loss = 3.6461 | 3025.99ms | Tokens/s = 173,261.5
2025-01-17 10:05:41.669 | DEBUG    | __main__:<module>:313 - Training step 3760: loss = 3.5123 | 3026.21ms | Tokens/s = 173,249.0
2025-01-17 10:06:11.920 | DEBUG    | __main__:<module>:313 - Training step 3770: loss = 3.5065 | 3025.26ms | Tokens/s = 173,303.4
2025-01-17 10:06:42.189 | DEBUG    | __main__:<module>:313 - Training step 3780: loss = 3.5644 | 3027.59ms | Tokens/s = 173,170.1
2025-01-17 10:07:12.449 | DEBUG    | __main__:<module>:313 - Training step 3790: loss = 3.4791 | 3023.45ms | Tokens/s = 173,407.3
2025-01-17 10:07:42.699 | DEBUG    | __main__:<module>:313 - Training step 3800: loss = 3.5174 | 3023.45ms | Tokens/s = 173,407.2
2025-01-17 10:08:12.937 | DEBUG    | __main__:<module>:313 - Training step 3810: loss = 3.4510 | 3023.69ms | Tokens/s = 173,393.2
2025-01-17 10:08:43.185 | DEBUG    | __main__:<module>:313 - Training step 3820: loss = 3.3849 | 3024.74ms | Tokens/s = 173,333.0
2025-01-17 10:09:13.424 | DEBUG    | __main__:<module>:313 - Training step 3830: loss = 3.3087 | 3024.46ms | Tokens/s = 173,349.1
2025-01-17 10:09:43.655 | DEBUG    | __main__:<module>:313 - Training step 3840: loss = 3.3793 | 3021.52ms | Tokens/s = 173,518.2
2025-01-17 10:10:13.882 | DEBUG    | __main__:<module>:313 - Training step 3850: loss = 3.4827 | 3023.70ms | Tokens/s = 173,392.9
2025-01-17 10:10:44.151 | DEBUG    | __main__:<module>:313 - Training step 3860: loss = 3.6137 | 3026.56ms | Tokens/s = 173,229.3
2025-01-17 10:11:14.401 | DEBUG    | __main__:<module>:313 - Training step 3870: loss = 3.4714 | 3024.90ms | Tokens/s = 173,324.4
2025-01-17 10:11:44.644 | DEBUG    | __main__:<module>:313 - Training step 3880: loss = 3.5601 | 3023.22ms | Tokens/s = 173,420.6
2025-01-17 10:12:14.880 | DEBUG    | __main__:<module>:313 - Training step 3890: loss = 3.4764 | 3022.67ms | Tokens/s = 173,451.9
2025-01-17 10:12:45.119 | DEBUG    | __main__:<module>:313 - Training step 3900: loss = 3.6576 | 3023.97ms | Tokens/s = 173,377.5
2025-01-17 10:13:15.374 | DEBUG    | __main__:<module>:313 - Training step 3910: loss = 3.3135 | 3024.84ms | Tokens/s = 173,327.5
2025-01-17 10:13:45.618 | DEBUG    | __main__:<module>:313 - Training step 3920: loss = 3.5110 | 3024.13ms | Tokens/s = 173,368.5
2025-01-17 10:14:15.859 | DEBUG    | __main__:<module>:313 - Training step 3930: loss = 3.3243 | 3024.22ms | Tokens/s = 173,363.0
2025-01-17 10:14:46.098 | DEBUG    | __main__:<module>:313 - Training step 3940: loss = 3.4958 | 3024.00ms | Tokens/s = 173,375.8
2025-01-17 10:15:16.327 | DEBUG    | __main__:<module>:313 - Training step 3950: loss = 3.4980 | 3022.78ms | Tokens/s = 173,445.9
2025-01-17 10:15:46.548 | DEBUG    | __main__:<module>:313 - Training step 3960: loss = 3.4649 | 3020.81ms | Tokens/s = 173,558.9
2025-01-17 10:16:16.778 | DEBUG    | __main__:<module>:313 - Training step 3970: loss = 3.4343 | 3022.79ms | Tokens/s = 173,444.8
2025-01-17 10:16:47.007 | DEBUG    | __main__:<module>:313 - Training step 3980: loss = 3.3845 | 3022.60ms | Tokens/s = 173,456.1
2025-01-17 10:17:17.232 | DEBUG    | __main__:<module>:313 - Training step 3990: loss = 3.4191 | 3020.78ms | Tokens/s = 173,560.7
2025-01-17 10:17:50.886 | INFO     | __main__:<module>:265 - Step 4,000/20,000 loss: 3.4520 (T) 3.4892 (V) | lr=9.7e-03
2025-01-17 10:17:50.888 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 10:18:04.088 | DEBUG    | __main__:<module>:313 - Training step 4000: loss = 3.3613 | 19661.76ms | Tokens/s = 26,665.4
2025-01-17 10:18:34.183 | DEBUG    | __main__:<module>:313 - Training step 4010: loss = 3.4732 | 3015.21ms | Tokens/s = 173,881.2
2025-01-17 10:19:04.382 | DEBUG    | __main__:<module>:313 - Training step 4020: loss = 3.5733 | 3023.61ms | Tokens/s = 173,398.2
2025-01-17 10:19:34.625 | DEBUG    | __main__:<module>:313 - Training step 4030: loss = 3.4269 | 3025.08ms | Tokens/s = 173,313.7
2025-01-17 10:20:04.881 | DEBUG    | __main__:<module>:313 - Training step 4040: loss = 3.3443 | 3023.97ms | Tokens/s = 173,377.2
2025-01-17 10:20:35.114 | DEBUG    | __main__:<module>:313 - Training step 4050: loss = 3.3903 | 3022.15ms | Tokens/s = 173,482.0
2025-01-17 10:21:05.345 | DEBUG    | __main__:<module>:313 - Training step 4060: loss = 3.4295 | 3023.46ms | Tokens/s = 173,406.9
2025-01-17 10:21:35.567 | DEBUG    | __main__:<module>:313 - Training step 4070: loss = 3.4558 | 3022.50ms | Tokens/s = 173,461.8
2025-01-17 10:22:05.780 | DEBUG    | __main__:<module>:313 - Training step 4080: loss = 3.3284 | 3021.15ms | Tokens/s = 173,539.4
2025-01-17 10:22:35.989 | DEBUG    | __main__:<module>:313 - Training step 4090: loss = 3.4149 | 3020.16ms | Tokens/s = 173,596.3
2025-01-17 10:23:06.220 | DEBUG    | __main__:<module>:313 - Training step 4100: loss = 3.4608 | 3024.02ms | Tokens/s = 173,374.5
2025-01-17 10:23:36.460 | DEBUG    | __main__:<module>:313 - Training step 4110: loss = 3.5802 | 3023.09ms | Tokens/s = 173,427.8
2025-01-17 10:24:06.702 | DEBUG    | __main__:<module>:313 - Training step 4120: loss = 3.6014 | 3026.96ms | Tokens/s = 173,206.3
2025-01-17 10:24:36.980 | DEBUG    | __main__:<module>:313 - Training step 4130: loss = 3.3715 | 3027.56ms | Tokens/s = 173,171.7
2025-01-17 10:25:07.248 | DEBUG    | __main__:<module>:313 - Training step 4140: loss = 3.5340 | 3025.24ms | Tokens/s = 173,304.8
2025-01-17 10:25:37.500 | DEBUG    | __main__:<module>:313 - Training step 4150: loss = 3.4125 | 3022.16ms | Tokens/s = 173,481.2
2025-01-17 10:26:07.741 | DEBUG    | __main__:<module>:313 - Training step 4160: loss = 3.5331 | 3022.80ms | Tokens/s = 173,444.7
2025-01-17 10:26:37.980 | DEBUG    | __main__:<module>:313 - Training step 4170: loss = 3.5600 | 3024.47ms | Tokens/s = 173,348.5
2025-01-17 10:27:08.218 | DEBUG    | __main__:<module>:313 - Training step 4180: loss = 3.3544 | 3025.17ms | Tokens/s = 173,308.7
2025-01-17 10:27:38.448 | DEBUG    | __main__:<module>:313 - Training step 4190: loss = 3.4583 | 3022.31ms | Tokens/s = 173,472.4
2025-01-17 10:28:08.667 | DEBUG    | __main__:<module>:313 - Training step 4200: loss = 3.4812 | 3022.67ms | Tokens/s = 173,451.7
2025-01-17 10:28:38.914 | DEBUG    | __main__:<module>:313 - Training step 4210: loss = 3.2916 | 3024.86ms | Tokens/s = 173,326.5
2025-01-17 10:29:09.163 | DEBUG    | __main__:<module>:313 - Training step 4220: loss = 3.5112 | 3024.28ms | Tokens/s = 173,359.9
2025-01-17 10:29:39.413 | DEBUG    | __main__:<module>:313 - Training step 4230: loss = 3.3817 | 3026.08ms | Tokens/s = 173,256.3
2025-01-17 10:30:09.683 | DEBUG    | __main__:<module>:313 - Training step 4240: loss = 3.5450 | 3026.91ms | Tokens/s = 173,209.1
2025-01-17 10:30:39.944 | DEBUG    | __main__:<module>:313 - Training step 4250: loss = 3.5144 | 3024.44ms | Tokens/s = 173,350.6
2025-01-17 10:31:10.186 | DEBUG    | __main__:<module>:313 - Training step 4260: loss = 3.3318 | 3022.84ms | Tokens/s = 173,442.4
2025-01-17 10:31:40.418 | DEBUG    | __main__:<module>:313 - Training step 4270: loss = 3.6417 | 3022.00ms | Tokens/s = 173,490.6
2025-01-17 10:32:10.647 | DEBUG    | __main__:<module>:313 - Training step 4280: loss = 3.5996 | 3025.18ms | Tokens/s = 173,307.9
2025-01-17 10:32:40.913 | DEBUG    | __main__:<module>:313 - Training step 4290: loss = 3.4865 | 3028.55ms | Tokens/s = 173,115.4
2025-01-17 10:33:11.182 | DEBUG    | __main__:<module>:313 - Training step 4300: loss = 3.3551 | 3025.33ms | Tokens/s = 173,299.7
2025-01-17 10:33:41.419 | DEBUG    | __main__:<module>:313 - Training step 4310: loss = 3.6254 | 3023.40ms | Tokens/s = 173,410.2
2025-01-17 10:34:11.657 | DEBUG    | __main__:<module>:313 - Training step 4320: loss = 3.5950 | 3023.47ms | Tokens/s = 173,406.1
2025-01-17 10:34:41.900 | DEBUG    | __main__:<module>:313 - Training step 4330: loss = 3.3784 | 3025.56ms | Tokens/s = 173,286.4
2025-01-17 10:35:12.149 | DEBUG    | __main__:<module>:313 - Training step 4340: loss = 3.3747 | 3023.58ms | Tokens/s = 173,399.9
2025-01-17 10:35:42.384 | DEBUG    | __main__:<module>:313 - Training step 4350: loss = 3.4964 | 3022.08ms | Tokens/s = 173,486.0
2025-01-17 10:36:12.603 | DEBUG    | __main__:<module>:313 - Training step 4360: loss = 3.4534 | 3020.87ms | Tokens/s = 173,555.4
2025-01-17 10:36:42.823 | DEBUG    | __main__:<module>:313 - Training step 4370: loss = 3.4203 | 3020.17ms | Tokens/s = 173,595.4
2025-01-17 10:37:13.042 | DEBUG    | __main__:<module>:313 - Training step 4380: loss = 3.6012 | 3021.95ms | Tokens/s = 173,493.5
2025-01-17 10:37:43.266 | DEBUG    | __main__:<module>:313 - Training step 4390: loss = 3.4354 | 3022.64ms | Tokens/s = 173,453.8
2025-01-17 10:38:13.484 | DEBUG    | __main__:<module>:313 - Training step 4400: loss = 3.4445 | 3022.84ms | Tokens/s = 173,442.0
2025-01-17 10:38:43.707 | DEBUG    | __main__:<module>:313 - Training step 4410: loss = 3.4045 | 3023.41ms | Tokens/s = 173,409.4
2025-01-17 10:39:13.923 | DEBUG    | __main__:<module>:313 - Training step 4420: loss = 3.6211 | 3021.27ms | Tokens/s = 173,532.3
2025-01-17 10:39:44.157 | DEBUG    | __main__:<module>:313 - Training step 4430: loss = 3.3931 | 3024.06ms | Tokens/s = 173,371.9
2025-01-17 10:40:14.408 | DEBUG    | __main__:<module>:313 - Training step 4440: loss = 3.4641 | 3024.04ms | Tokens/s = 173,373.6
2025-01-17 10:40:44.636 | DEBUG    | __main__:<module>:313 - Training step 4450: loss = 3.4722 | 3020.57ms | Tokens/s = 173,572.3
2025-01-17 10:41:14.868 | DEBUG    | __main__:<module>:313 - Training step 4460: loss = 3.4309 | 3023.84ms | Tokens/s = 173,385.1
2025-01-17 10:41:45.098 | DEBUG    | __main__:<module>:313 - Training step 4470: loss = 3.4527 | 3022.01ms | Tokens/s = 173,489.9
2025-01-17 10:42:15.316 | DEBUG    | __main__:<module>:313 - Training step 4480: loss = 3.5324 | 3022.59ms | Tokens/s = 173,456.3
2025-01-17 10:42:45.527 | DEBUG    | __main__:<module>:313 - Training step 4490: loss = 3.4823 | 3021.01ms | Tokens/s = 173,547.0
2025-01-17 10:43:15.739 | DEBUG    | __main__:<module>:313 - Training step 4500: loss = 3.6058 | 3020.17ms | Tokens/s = 173,595.7
2025-01-17 10:43:45.952 | DEBUG    | __main__:<module>:313 - Training step 4510: loss = 3.3781 | 3021.61ms | Tokens/s = 173,512.8
2025-01-17 10:44:16.167 | DEBUG    | __main__:<module>:313 - Training step 4520: loss = 3.5277 | 3022.04ms | Tokens/s = 173,488.1
2025-01-17 10:44:46.377 | DEBUG    | __main__:<module>:313 - Training step 4530: loss = 3.5440 | 3022.86ms | Tokens/s = 173,441.2
2025-01-17 10:45:16.581 | DEBUG    | __main__:<module>:313 - Training step 4540: loss = 3.2571 | 3020.46ms | Tokens/s = 173,579.0
2025-01-17 10:45:46.795 | DEBUG    | __main__:<module>:313 - Training step 4550: loss = 3.5132 | 3022.82ms | Tokens/s = 173,443.3
2025-01-17 10:46:17.007 | DEBUG    | __main__:<module>:313 - Training step 4560: loss = 3.3278 | 3020.20ms | Tokens/s = 173,593.9
2025-01-17 10:46:47.224 | DEBUG    | __main__:<module>:313 - Training step 4570: loss = 3.3849 | 3022.58ms | Tokens/s = 173,457.0
2025-01-17 10:47:17.441 | DEBUG    | __main__:<module>:313 - Training step 4580: loss = 3.3967 | 3022.40ms | Tokens/s = 173,467.7
2025-01-17 10:47:47.653 | DEBUG    | __main__:<module>:313 - Training step 4590: loss = 3.3487 | 3020.70ms | Tokens/s = 173,565.0
2025-01-17 10:48:17.869 | DEBUG    | __main__:<module>:313 - Training step 4600: loss = 3.3389 | 3022.41ms | Tokens/s = 173,466.8
2025-01-17 10:48:48.079 | DEBUG    | __main__:<module>:313 - Training step 4610: loss = 3.5348 | 3019.73ms | Tokens/s = 173,620.6
2025-01-17 10:49:18.291 | DEBUG    | __main__:<module>:313 - Training step 4620: loss = 3.4141 | 3022.18ms | Tokens/s = 173,480.2
2025-01-17 10:49:48.553 | DEBUG    | __main__:<module>:313 - Training step 4630: loss = 3.5901 | 3028.95ms | Tokens/s = 173,092.2
2025-01-17 10:50:18.840 | DEBUG    | __main__:<module>:313 - Training step 4640: loss = 3.5663 | 3026.23ms | Tokens/s = 173,248.1
2025-01-17 10:50:49.110 | DEBUG    | __main__:<module>:313 - Training step 4650: loss = 3.3762 | 3028.44ms | Tokens/s = 173,121.7
2025-01-17 10:51:19.377 | DEBUG    | __main__:<module>:313 - Training step 4660: loss = 3.3862 | 3026.69ms | Tokens/s = 173,221.8
2025-01-17 10:51:49.621 | DEBUG    | __main__:<module>:313 - Training step 4670: loss = 3.4155 | 3023.53ms | Tokens/s = 173,402.3
2025-01-17 10:52:19.858 | DEBUG    | __main__:<module>:313 - Training step 4680: loss = 3.4528 | 3022.00ms | Tokens/s = 173,490.2
2025-01-17 10:52:50.110 | DEBUG    | __main__:<module>:313 - Training step 4690: loss = 3.6207 | 3023.90ms | Tokens/s = 173,381.4
2025-01-17 10:53:20.360 | DEBUG    | __main__:<module>:313 - Training step 4700: loss = 3.4919 | 3022.42ms | Tokens/s = 173,466.3
2025-01-17 10:53:50.595 | DEBUG    | __main__:<module>:313 - Training step 4710: loss = 3.1604 | 3022.84ms | Tokens/s = 173,442.1
2025-01-17 10:54:20.815 | DEBUG    | __main__:<module>:313 - Training step 4720: loss = 3.5024 | 3021.54ms | Tokens/s = 173,516.6
2025-01-17 10:54:51.035 | DEBUG    | __main__:<module>:313 - Training step 4730: loss = 3.2648 | 3021.97ms | Tokens/s = 173,492.2
2025-01-17 10:55:21.286 | DEBUG    | __main__:<module>:313 - Training step 4740: loss = 3.3903 | 3026.70ms | Tokens/s = 173,221.1
2025-01-17 10:55:51.552 | DEBUG    | __main__:<module>:313 - Training step 4750: loss = 3.5689 | 3025.60ms | Tokens/s = 173,284.0
2025-01-17 10:56:21.805 | DEBUG    | __main__:<module>:313 - Training step 4760: loss = 3.4010 | 3024.78ms | Tokens/s = 173,330.7
2025-01-17 10:56:52.065 | DEBUG    | __main__:<module>:313 - Training step 4770: loss = 3.5896 | 3027.03ms | Tokens/s = 173,202.3
2025-01-17 10:57:22.311 | DEBUG    | __main__:<module>:313 - Training step 4780: loss = 3.7144 | 3024.68ms | Tokens/s = 173,336.7
2025-01-17 10:57:52.561 | DEBUG    | __main__:<module>:313 - Training step 4790: loss = 3.3967 | 3025.70ms | Tokens/s = 173,278.2
2025-01-17 10:58:22.822 | DEBUG    | __main__:<module>:313 - Training step 4800: loss = 3.5197 | 3024.19ms | Tokens/s = 173,364.7
2025-01-17 10:58:53.071 | DEBUG    | __main__:<module>:313 - Training step 4810: loss = 3.5520 | 3024.54ms | Tokens/s = 173,344.7
2025-01-17 10:59:23.302 | DEBUG    | __main__:<module>:313 - Training step 4820: loss = 3.4563 | 3023.51ms | Tokens/s = 173,403.5
2025-01-17 10:59:53.526 | DEBUG    | __main__:<module>:313 - Training step 4830: loss = 3.4093 | 3019.44ms | Tokens/s = 173,637.2
2025-01-17 11:00:23.743 | DEBUG    | __main__:<module>:313 - Training step 4840: loss = 3.4652 | 3019.58ms | Tokens/s = 173,629.4
2025-01-17 11:00:53.959 | DEBUG    | __main__:<module>:313 - Training step 4850: loss = 3.3793 | 3021.46ms | Tokens/s = 173,521.6
2025-01-17 11:01:24.171 | DEBUG    | __main__:<module>:313 - Training step 4860: loss = 3.2908 | 3022.37ms | Tokens/s = 173,469.0
2025-01-17 11:01:54.376 | DEBUG    | __main__:<module>:313 - Training step 4870: loss = 3.4117 | 3019.47ms | Tokens/s = 173,635.6
2025-01-17 11:02:24.597 | DEBUG    | __main__:<module>:313 - Training step 4880: loss = 3.3587 | 3022.35ms | Tokens/s = 173,470.2
2025-01-17 11:02:54.808 | DEBUG    | __main__:<module>:313 - Training step 4890: loss = 3.3372 | 3022.57ms | Tokens/s = 173,457.8
2025-01-17 11:03:25.030 | DEBUG    | __main__:<module>:313 - Training step 4900: loss = 3.5251 | 3022.57ms | Tokens/s = 173,457.6
2025-01-17 11:03:55.290 | DEBUG    | __main__:<module>:313 - Training step 4910: loss = 3.5891 | 3026.74ms | Tokens/s = 173,219.0
2025-01-17 11:04:25.535 | DEBUG    | __main__:<module>:313 - Training step 4920: loss = 3.4320 | 3024.65ms | Tokens/s = 173,338.6
2025-01-17 11:04:55.773 | DEBUG    | __main__:<module>:313 - Training step 4930: loss = 3.4799 | 3021.12ms | Tokens/s = 173,540.7
2025-01-17 11:05:26.007 | DEBUG    | __main__:<module>:313 - Training step 4940: loss = 3.3377 | 3023.72ms | Tokens/s = 173,391.5
2025-01-17 11:05:56.236 | DEBUG    | __main__:<module>:313 - Training step 4950: loss = 3.3644 | 3023.22ms | Tokens/s = 173,420.5
2025-01-17 11:06:26.453 | DEBUG    | __main__:<module>:313 - Training step 4960: loss = 3.4985 | 3022.05ms | Tokens/s = 173,487.6
2025-01-17 11:06:56.680 | DEBUG    | __main__:<module>:313 - Training step 4970: loss = 3.4159 | 3024.98ms | Tokens/s = 173,319.7
2025-01-17 11:07:26.954 | DEBUG    | __main__:<module>:313 - Training step 4980: loss = 3.5449 | 3029.69ms | Tokens/s = 173,050.2
2025-01-17 11:07:57.228 | DEBUG    | __main__:<module>:313 - Training step 4990: loss = 3.4473 | 3026.42ms | Tokens/s = 173,237.2
2025-01-17 11:08:30.915 | INFO     | __main__:<module>:265 - Step 5,000/20,000 loss: 3.4267 (T) 3.4488 (V) | lr=9.3e-03
2025-01-17 11:08:30.916 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 11:08:44.103 | DEBUG    | __main__:<module>:313 - Training step 5000: loss = 3.3021 | 19651.45ms | Tokens/s = 26,679.4
2025-01-17 11:09:14.212 | DEBUG    | __main__:<module>:313 - Training step 5010: loss = 3.3761 | 3016.47ms | Tokens/s = 173,808.5
2025-01-17 11:09:44.429 | DEBUG    | __main__:<module>:313 - Training step 5020: loss = 3.5601 | 3023.23ms | Tokens/s = 173,419.7
2025-01-17 11:10:14.685 | DEBUG    | __main__:<module>:313 - Training step 5030: loss = 3.4032 | 3027.00ms | Tokens/s = 173,203.6
2025-01-17 11:10:44.957 | DEBUG    | __main__:<module>:313 - Training step 5040: loss = 3.4501 | 3026.80ms | Tokens/s = 173,215.1
2025-01-17 11:11:15.215 | DEBUG    | __main__:<module>:313 - Training step 5050: loss = 3.5313 | 3026.39ms | Tokens/s = 173,238.6
2025-01-17 11:11:45.461 | DEBUG    | __main__:<module>:313 - Training step 5060: loss = 3.3960 | 3023.66ms | Tokens/s = 173,395.3
2025-01-17 11:12:15.698 | DEBUG    | __main__:<module>:313 - Training step 5070: loss = 3.4270 | 3022.40ms | Tokens/s = 173,467.2
2025-01-17 11:12:45.928 | DEBUG    | __main__:<module>:313 - Training step 5080: loss = 3.5654 | 3023.05ms | Tokens/s = 173,430.4
2025-01-17 11:13:16.176 | DEBUG    | __main__:<module>:313 - Training step 5090: loss = 3.4760 | 3024.23ms | Tokens/s = 173,362.7
2025-01-17 11:13:46.414 | DEBUG    | __main__:<module>:313 - Training step 5100: loss = 3.6575 | 3023.34ms | Tokens/s = 173,413.3
2025-01-17 11:14:16.629 | DEBUG    | __main__:<module>:313 - Training step 5110: loss = 3.3810 | 3020.58ms | Tokens/s = 173,572.2
2025-01-17 11:14:46.849 | DEBUG    | __main__:<module>:313 - Training step 5120: loss = 3.5888 | 3021.77ms | Tokens/s = 173,503.8
2025-01-17 11:15:17.073 | DEBUG    | __main__:<module>:313 - Training step 5130: loss = 3.3895 | 3023.87ms | Tokens/s = 173,383.4
2025-01-17 11:15:47.303 | DEBUG    | __main__:<module>:313 - Training step 5140: loss = 3.6120 | 3024.03ms | Tokens/s = 173,374.1
2025-01-17 11:16:17.532 | DEBUG    | __main__:<module>:313 - Training step 5150: loss = 3.4026 | 3023.10ms | Tokens/s = 173,427.5
2025-01-17 11:16:47.771 | DEBUG    | __main__:<module>:313 - Training step 5160: loss = 3.4719 | 3023.37ms | Tokens/s = 173,411.8
2025-01-17 11:17:18.002 | DEBUG    | __main__:<module>:313 - Training step 5170: loss = 3.4285 | 3023.87ms | Tokens/s = 173,382.9
2025-01-17 11:17:48.225 | DEBUG    | __main__:<module>:313 - Training step 5180: loss = 3.5300 | 3022.56ms | Tokens/s = 173,458.0
2025-01-17 11:18:18.451 | DEBUG    | __main__:<module>:313 - Training step 5190: loss = 3.4597 | 3021.61ms | Tokens/s = 173,513.0
2025-01-17 11:18:48.672 | DEBUG    | __main__:<module>:313 - Training step 5200: loss = 3.3810 | 3021.74ms | Tokens/s = 173,505.1
2025-01-17 11:19:18.894 | DEBUG    | __main__:<module>:313 - Training step 5210: loss = 3.4588 | 3020.33ms | Tokens/s = 173,586.3
2025-01-17 11:19:49.132 | DEBUG    | __main__:<module>:313 - Training step 5220: loss = 3.5160 | 3022.79ms | Tokens/s = 173,445.0
2025-01-17 11:20:19.381 | DEBUG    | __main__:<module>:313 - Training step 5230: loss = 3.2743 | 3025.55ms | Tokens/s = 173,286.6
2025-01-17 11:20:49.613 | DEBUG    | __main__:<module>:313 - Training step 5240: loss = 3.5722 | 3023.11ms | Tokens/s = 173,426.8
2025-01-17 11:21:19.838 | DEBUG    | __main__:<module>:313 - Training step 5250: loss = 3.4212 | 3023.47ms | Tokens/s = 173,406.2
2025-01-17 11:21:50.064 | DEBUG    | __main__:<module>:313 - Training step 5260: loss = 3.5927 | 3022.84ms | Tokens/s = 173,442.5
2025-01-17 11:22:20.325 | DEBUG    | __main__:<module>:313 - Training step 5270: loss = 3.3880 | 3025.06ms | Tokens/s = 173,314.6
2025-01-17 11:22:50.577 | DEBUG    | __main__:<module>:313 - Training step 5280: loss = 3.4460 | 3024.70ms | Tokens/s = 173,335.5
2025-01-17 11:23:20.814 | DEBUG    | __main__:<module>:313 - Training step 5290: loss = 3.4202 | 3024.14ms | Tokens/s = 173,367.6
2025-01-17 11:23:51.040 | DEBUG    | __main__:<module>:313 - Training step 5300: loss = 3.4048 | 3020.31ms | Tokens/s = 173,587.3
2025-01-17 11:24:21.263 | DEBUG    | __main__:<module>:313 - Training step 5310: loss = 3.5839 | 3021.87ms | Tokens/s = 173,497.9
2025-01-17 11:24:51.507 | DEBUG    | __main__:<module>:313 - Training step 5320: loss = 3.4143 | 3026.15ms | Tokens/s = 173,252.3
2025-01-17 11:25:21.764 | DEBUG    | __main__:<module>:313 - Training step 5330: loss = 3.4585 | 3025.69ms | Tokens/s = 173,279.0
2025-01-17 11:25:52.010 | DEBUG    | __main__:<module>:313 - Training step 5340: loss = 3.4685 | 3024.21ms | Tokens/s = 173,363.5
2025-01-17 11:26:22.250 | DEBUG    | __main__:<module>:313 - Training step 5350: loss = 3.3393 | 3026.67ms | Tokens/s = 173,222.5
2025-01-17 11:26:52.532 | DEBUG    | __main__:<module>:313 - Training step 5360: loss = 3.4332 | 3027.79ms | Tokens/s = 173,158.8
2025-01-17 11:27:22.797 | DEBUG    | __main__:<module>:313 - Training step 5370: loss = 3.5069 | 3024.72ms | Tokens/s = 173,334.4
2025-01-17 11:27:53.043 | DEBUG    | __main__:<module>:313 - Training step 5380: loss = 3.4251 | 3021.51ms | Tokens/s = 173,518.3
2025-01-17 11:28:23.276 | DEBUG    | __main__:<module>:313 - Training step 5390: loss = 3.4930 | 3024.06ms | Tokens/s = 173,372.0
2025-01-17 11:28:53.498 | DEBUG    | __main__:<module>:313 - Training step 5400: loss = 3.4784 | 3020.99ms | Tokens/s = 173,548.5
2025-01-17 11:29:23.724 | DEBUG    | __main__:<module>:313 - Training step 5410: loss = 3.6129 | 3024.38ms | Tokens/s = 173,354.0
2025-01-17 11:29:53.967 | DEBUG    | __main__:<module>:313 - Training step 5420: loss = 3.5045 | 3023.00ms | Tokens/s = 173,433.0
2025-01-17 11:30:24.205 | DEBUG    | __main__:<module>:313 - Training step 5430: loss = 3.3191 | 3023.31ms | Tokens/s = 173,415.0
2025-01-17 11:30:54.426 | DEBUG    | __main__:<module>:313 - Training step 5440: loss = 3.4911 | 3021.14ms | Tokens/s = 173,539.9
2025-01-17 11:31:24.646 | DEBUG    | __main__:<module>:313 - Training step 5450: loss = 3.4664 | 3022.19ms | Tokens/s = 173,479.2
2025-01-17 11:31:54.859 | DEBUG    | __main__:<module>:313 - Training step 5460: loss = 3.4936 | 3018.96ms | Tokens/s = 173,664.9
2025-01-17 11:32:25.083 | DEBUG    | __main__:<module>:313 - Training step 5470: loss = 3.5521 | 3024.67ms | Tokens/s = 173,337.2
2025-01-17 11:32:55.336 | DEBUG    | __main__:<module>:313 - Training step 5480: loss = 3.4056 | 3024.78ms | Tokens/s = 173,330.9
2025-01-17 11:33:25.580 | DEBUG    | __main__:<module>:313 - Training step 5490: loss = 3.4681 | 3022.50ms | Tokens/s = 173,461.9
2025-01-17 11:33:55.818 | DEBUG    | __main__:<module>:313 - Training step 5500: loss = 3.3797 | 3025.86ms | Tokens/s = 173,269.1
2025-01-17 11:34:26.066 | DEBUG    | __main__:<module>:313 - Training step 5510: loss = 3.4295 | 3024.32ms | Tokens/s = 173,357.2
2025-01-17 11:34:56.302 | DEBUG    | __main__:<module>:313 - Training step 5520: loss = 3.5664 | 3022.14ms | Tokens/s = 173,482.5
2025-01-17 11:35:26.544 | DEBUG    | __main__:<module>:313 - Training step 5530: loss = 3.4827 | 3026.39ms | Tokens/s = 173,238.5
2025-01-17 11:35:56.796 | DEBUG    | __main__:<module>:313 - Training step 5540: loss = 3.4470 | 3024.88ms | Tokens/s = 173,325.4
2025-01-17 11:36:27.030 | DEBUG    | __main__:<module>:313 - Training step 5550: loss = 3.3693 | 3024.14ms | Tokens/s = 173,367.4
2025-01-17 11:36:57.257 | DEBUG    | __main__:<module>:313 - Training step 5560: loss = 3.2463 | 3022.54ms | Tokens/s = 173,459.2
2025-01-17 11:37:27.476 | DEBUG    | __main__:<module>:313 - Training step 5570: loss = 3.1478 | 3021.14ms | Tokens/s = 173,539.8
2025-01-17 11:37:57.692 | DEBUG    | __main__:<module>:313 - Training step 5580: loss = 3.4403 | 3021.75ms | Tokens/s = 173,504.6
2025-01-17 11:38:27.935 | DEBUG    | __main__:<module>:313 - Training step 5590: loss = 3.3818 | 3026.16ms | Tokens/s = 173,252.0
2025-01-17 11:38:58.206 | DEBUG    | __main__:<module>:313 - Training step 5600: loss = 3.3774 | 3026.43ms | Tokens/s = 173,236.7
2025-01-17 11:39:28.460 | DEBUG    | __main__:<module>:313 - Training step 5610: loss = 3.4332 | 3022.84ms | Tokens/s = 173,442.2
2025-01-17 11:39:58.705 | DEBUG    | __main__:<module>:313 - Training step 5620: loss = 3.5141 | 3025.42ms | Tokens/s = 173,294.1
2025-01-17 11:40:28.935 | DEBUG    | __main__:<module>:313 - Training step 5630: loss = 3.3622 | 3022.52ms | Tokens/s = 173,460.5
2025-01-17 11:40:59.152 | DEBUG    | __main__:<module>:313 - Training step 5640: loss = 3.4751 | 3022.13ms | Tokens/s = 173,482.9
2025-01-17 11:41:29.370 | DEBUG    | __main__:<module>:313 - Training step 5650: loss = 3.4155 | 3021.12ms | Tokens/s = 173,541.2
2025-01-17 11:41:59.596 | DEBUG    | __main__:<module>:313 - Training step 5660: loss = 3.4066 | 3022.53ms | Tokens/s = 173,460.0
2025-01-17 11:42:29.813 | DEBUG    | __main__:<module>:313 - Training step 5670: loss = 3.4088 | 3019.68ms | Tokens/s = 173,623.6
2025-01-17 11:43:00.031 | DEBUG    | __main__:<module>:313 - Training step 5680: loss = 3.3502 | 3022.43ms | Tokens/s = 173,465.5
2025-01-17 11:43:30.248 | DEBUG    | __main__:<module>:313 - Training step 5690: loss = 3.3711 | 3021.72ms | Tokens/s = 173,506.6
2025-01-17 11:44:00.463 | DEBUG    | __main__:<module>:313 - Training step 5700: loss = 3.4608 | 3021.51ms | Tokens/s = 173,518.3
2025-01-17 11:44:30.680 | DEBUG    | __main__:<module>:313 - Training step 5710: loss = 3.4604 | 3023.67ms | Tokens/s = 173,394.5
2025-01-17 11:45:00.924 | DEBUG    | __main__:<module>:313 - Training step 5720: loss = 3.4555 | 3025.32ms | Tokens/s = 173,299.9
2025-01-17 11:45:31.195 | DEBUG    | __main__:<module>:313 - Training step 5730: loss = 3.5720 | 3026.46ms | Tokens/s = 173,234.5
2025-01-17 11:46:01.448 | DEBUG    | __main__:<module>:313 - Training step 5740: loss = 3.4406 | 3024.92ms | Tokens/s = 173,323.0
2025-01-17 11:46:31.683 | DEBUG    | __main__:<module>:313 - Training step 5750: loss = 3.5090 | 3025.15ms | Tokens/s = 173,309.5
2025-01-17 11:47:01.915 | DEBUG    | __main__:<module>:313 - Training step 5760: loss = 3.4206 | 3024.13ms | Tokens/s = 173,368.5
2025-01-17 11:47:32.137 | DEBUG    | __main__:<module>:313 - Training step 5770: loss = 3.2773 | 3020.28ms | Tokens/s = 173,589.3
2025-01-17 11:48:02.349 | DEBUG    | __main__:<module>:313 - Training step 5780: loss = 3.5411 | 3021.28ms | Tokens/s = 173,531.5
2025-01-17 11:48:32.562 | DEBUG    | __main__:<module>:313 - Training step 5790: loss = 3.5504 | 3021.77ms | Tokens/s = 173,503.8
2025-01-17 11:49:02.766 | DEBUG    | __main__:<module>:313 - Training step 5800: loss = 3.3168 | 3018.42ms | Tokens/s = 173,696.3
2025-01-17 11:49:32.975 | DEBUG    | __main__:<module>:313 - Training step 5810: loss = 3.4554 | 3021.02ms | Tokens/s = 173,546.9
2025-01-17 11:50:03.188 | DEBUG    | __main__:<module>:313 - Training step 5820: loss = 3.4060 | 3021.14ms | Tokens/s = 173,539.5
2025-01-17 11:50:33.404 | DEBUG    | __main__:<module>:313 - Training step 5830: loss = 3.4695 | 3022.17ms | Tokens/s = 173,480.6
2025-01-17 11:51:03.611 | DEBUG    | __main__:<module>:313 - Training step 5840: loss = 3.5132 | 3021.68ms | Tokens/s = 173,509.0
2025-01-17 11:51:33.852 | DEBUG    | __main__:<module>:313 - Training step 5850: loss = 3.3096 | 3026.82ms | Tokens/s = 173,213.8
2025-01-17 11:52:04.123 | DEBUG    | __main__:<module>:313 - Training step 5860: loss = 3.3312 | 3028.94ms | Tokens/s = 173,093.0
2025-01-17 11:52:34.388 | DEBUG    | __main__:<module>:313 - Training step 5870: loss = 3.4602 | 3025.38ms | Tokens/s = 173,296.8
2025-01-17 11:53:04.639 | DEBUG    | __main__:<module>:313 - Training step 5880: loss = 3.4451 | 3021.14ms | Tokens/s = 173,539.8
2025-01-17 11:53:34.869 | DEBUG    | __main__:<module>:313 - Training step 5890: loss = 3.3468 | 3025.65ms | Tokens/s = 173,281.4
2025-01-17 11:54:05.094 | DEBUG    | __main__:<module>:313 - Training step 5900: loss = 3.2431 | 3024.25ms | Tokens/s = 173,361.3
2025-01-17 11:54:35.317 | DEBUG    | __main__:<module>:313 - Training step 5910: loss = 3.4914 | 3021.41ms | Tokens/s = 173,524.1
2025-01-17 11:55:05.533 | DEBUG    | __main__:<module>:313 - Training step 5920: loss = 3.6565 | 3019.98ms | Tokens/s = 173,606.7
2025-01-17 11:55:35.752 | DEBUG    | __main__:<module>:313 - Training step 5930: loss = 3.5801 | 3022.99ms | Tokens/s = 173,433.7
2025-01-17 11:56:05.988 | DEBUG    | __main__:<module>:313 - Training step 5940: loss = 3.1231 | 3026.67ms | Tokens/s = 173,222.9
2025-01-17 11:56:36.227 | DEBUG    | __main__:<module>:313 - Training step 5950: loss = 3.4581 | 3023.37ms | Tokens/s = 173,411.7
2025-01-17 11:57:06.456 | DEBUG    | __main__:<module>:313 - Training step 5960: loss = 3.4571 | 3022.40ms | Tokens/s = 173,467.7
2025-01-17 11:57:36.684 | DEBUG    | __main__:<module>:313 - Training step 5970: loss = 3.3421 | 3023.61ms | Tokens/s = 173,397.8
2025-01-17 11:58:06.905 | DEBUG    | __main__:<module>:313 - Training step 5980: loss = 3.4928 | 3021.35ms | Tokens/s = 173,527.6
2025-01-17 11:58:37.128 | DEBUG    | __main__:<module>:313 - Training step 5990: loss = 3.4124 | 3022.50ms | Tokens/s = 173,461.6
2025-01-17 11:59:10.775 | INFO     | __main__:<module>:265 - Step 6,000/20,000 loss: 3.4095 (T) 3.4296 (V) | lr=8.8e-03
2025-01-17 11:59:10.777 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 11:59:24.204 | DEBUG    | __main__:<module>:313 - Training step 6000: loss = 3.3494 | 19887.60ms | Tokens/s = 26,362.6
2025-01-17 11:59:54.295 | DEBUG    | __main__:<module>:313 - Training step 6010: loss = 3.2880 | 3016.45ms | Tokens/s = 173,809.6
2025-01-17 12:00:24.498 | DEBUG    | __main__:<module>:313 - Training step 6020: loss = 3.5249 | 3021.44ms | Tokens/s = 173,522.5
2025-01-17 12:00:54.735 | DEBUG    | __main__:<module>:313 - Training step 6030: loss = 3.4381 | 3023.16ms | Tokens/s = 173,423.7
2025-01-17 12:01:24.973 | DEBUG    | __main__:<module>:313 - Training step 6040: loss = 3.4174 | 3022.35ms | Tokens/s = 173,470.0
2025-01-17 12:01:55.193 | DEBUG    | __main__:<module>:313 - Training step 6050: loss = 3.3545 | 3019.24ms | Tokens/s = 173,649.2
2025-01-17 12:02:25.398 | DEBUG    | __main__:<module>:313 - Training step 6060: loss = 3.1896 | 3020.11ms | Tokens/s = 173,599.2
2025-01-17 12:02:55.602 | DEBUG    | __main__:<module>:313 - Training step 6070: loss = 3.3847 | 3018.32ms | Tokens/s = 173,701.8
2025-01-17 12:03:25.802 | DEBUG    | __main__:<module>:313 - Training step 6080: loss = 3.3997 | 3019.12ms | Tokens/s = 173,655.8
2025-01-17 12:03:56.011 | DEBUG    | __main__:<module>:313 - Training step 6090: loss = 3.4312 | 3021.70ms | Tokens/s = 173,507.8
2025-01-17 12:04:26.258 | DEBUG    | __main__:<module>:313 - Training step 6100: loss = 3.3665 | 3025.14ms | Tokens/s = 173,310.2
2025-01-17 12:04:56.524 | DEBUG    | __main__:<module>:313 - Training step 6110: loss = 3.5764 | 3026.86ms | Tokens/s = 173,212.0
2025-01-17 12:05:26.775 | DEBUG    | __main__:<module>:313 - Training step 6120: loss = 3.3622 | 3025.47ms | Tokens/s = 173,291.4
2025-01-17 12:05:57.015 | DEBUG    | __main__:<module>:313 - Training step 6130: loss = 3.5222 | 3024.14ms | Tokens/s = 173,367.6
2025-01-17 12:06:27.259 | DEBUG    | __main__:<module>:313 - Training step 6140: loss = 3.3957 | 3025.37ms | Tokens/s = 173,297.3
2025-01-17 12:06:57.493 | DEBUG    | __main__:<module>:313 - Training step 6150: loss = 3.5303 | 3023.34ms | Tokens/s = 173,413.5
2025-01-17 12:07:27.724 | DEBUG    | __main__:<module>:313 - Training step 6160: loss = 3.5032 | 3022.29ms | Tokens/s = 173,473.7
2025-01-17 12:07:57.955 | DEBUG    | __main__:<module>:313 - Training step 6170: loss = 3.4503 | 3022.82ms | Tokens/s = 173,443.5
2025-01-17 12:08:28.182 | DEBUG    | __main__:<module>:313 - Training step 6180: loss = 3.4107 | 3022.43ms | Tokens/s = 173,465.5
2025-01-17 12:08:58.399 | DEBUG    | __main__:<module>:313 - Training step 6190: loss = 3.4911 | 3022.57ms | Tokens/s = 173,457.6
2025-01-17 12:09:28.620 | DEBUG    | __main__:<module>:313 - Training step 6200: loss = 3.3515 | 3021.22ms | Tokens/s = 173,535.4
2025-01-17 12:09:58.842 | DEBUG    | __main__:<module>:313 - Training step 6210: loss = 3.4934 | 3021.26ms | Tokens/s = 173,532.7
2025-01-17 12:10:29.059 | DEBUG    | __main__:<module>:313 - Training step 6220: loss = 3.4123 | 3022.87ms | Tokens/s = 173,440.4
2025-01-17 12:10:59.280 | DEBUG    | __main__:<module>:313 - Training step 6230: loss = 3.4057 | 3025.24ms | Tokens/s = 173,304.4
2025-01-17 12:11:29.545 | DEBUG    | __main__:<module>:313 - Training step 6240: loss = 3.5474 | 3029.35ms | Tokens/s = 173,069.3
2025-01-17 12:11:59.819 | DEBUG    | __main__:<module>:313 - Training step 6250: loss = 3.4942 | 3027.44ms | Tokens/s = 173,178.8
2025-01-17 12:12:30.062 | DEBUG    | __main__:<module>:313 - Training step 6260: loss = 3.4488 | 3024.15ms | Tokens/s = 173,366.8
2025-01-17 12:13:00.300 | DEBUG    | __main__:<module>:313 - Training step 6270: loss = 3.3374 | 3024.27ms | Tokens/s = 173,360.4
2025-01-17 12:13:30.536 | DEBUG    | __main__:<module>:313 - Training step 6280: loss = 3.5908 | 3023.31ms | Tokens/s = 173,415.2
2025-01-17 12:14:00.767 | DEBUG    | __main__:<module>:313 - Training step 6290: loss = 3.3781 | 3024.56ms | Tokens/s = 173,343.8
2025-01-17 12:14:31.015 | DEBUG    | __main__:<module>:313 - Training step 6300: loss = 3.3281 | 3026.42ms | Tokens/s = 173,237.1
2025-01-17 12:15:01.281 | DEBUG    | __main__:<module>:313 - Training step 6310: loss = 3.4498 | 3023.48ms | Tokens/s = 173,405.4
2025-01-17 12:15:31.530 | DEBUG    | __main__:<module>:313 - Training step 6320: loss = 3.3650 | 3021.77ms | Tokens/s = 173,503.3
2025-01-17 12:16:01.763 | DEBUG    | __main__:<module>:313 - Training step 6330: loss = 3.4132 | 3021.63ms | Tokens/s = 173,511.8
2025-01-17 12:16:31.994 | DEBUG    | __main__:<module>:313 - Training step 6340: loss = 3.4460 | 3022.21ms | Tokens/s = 173,478.2
2025-01-17 12:17:02.256 | DEBUG    | __main__:<module>:313 - Training step 6350: loss = 3.4291 | 3026.10ms | Tokens/s = 173,255.2
2025-01-17 12:17:32.509 | DEBUG    | __main__:<module>:313 - Training step 6360: loss = 3.3445 | 3023.08ms | Tokens/s = 173,428.5
2025-01-17 12:18:02.743 | DEBUG    | __main__:<module>:313 - Training step 6370: loss = 3.5398 | 3023.44ms | Tokens/s = 173,407.8
2025-01-17 12:18:32.976 | DEBUG    | __main__:<module>:313 - Training step 6380: loss = 3.5208 | 3022.38ms | Tokens/s = 173,468.8
2025-01-17 12:19:03.195 | DEBUG    | __main__:<module>:313 - Training step 6390: loss = 3.4082 | 3023.57ms | Tokens/s = 173,400.2
2025-01-17 12:19:33.412 | DEBUG    | __main__:<module>:313 - Training step 6400: loss = 3.3617 | 3022.55ms | Tokens/s = 173,459.0
2025-01-17 12:20:03.635 | DEBUG    | __main__:<module>:313 - Training step 6410: loss = 3.2855 | 3021.30ms | Tokens/s = 173,530.3
2025-01-17 12:20:33.852 | DEBUG    | __main__:<module>:313 - Training step 6420: loss = 3.4435 | 3021.09ms | Tokens/s = 173,542.5
2025-01-17 12:21:04.065 | DEBUG    | __main__:<module>:313 - Training step 6430: loss = 3.2651 | 3020.75ms | Tokens/s = 173,562.5
2025-01-17 12:21:34.282 | DEBUG    | __main__:<module>:313 - Training step 6440: loss = 3.5164 | 3021.36ms | Tokens/s = 173,526.9
2025-01-17 12:22:04.509 | DEBUG    | __main__:<module>:313 - Training step 6450: loss = 3.2851 | 3025.35ms | Tokens/s = 173,298.5
2025-01-17 12:22:34.749 | DEBUG    | __main__:<module>:313 - Training step 6460: loss = 3.3445 | 3026.94ms | Tokens/s = 173,207.1
2025-01-17 12:23:05.006 | DEBUG    | __main__:<module>:313 - Training step 6470: loss = 3.5261 | 3024.61ms | Tokens/s = 173,340.8
2025-01-17 12:23:35.245 | DEBUG    | __main__:<module>:313 - Training step 6480: loss = 3.3787 | 3024.70ms | Tokens/s = 173,335.7
2025-01-17 12:24:05.484 | DEBUG    | __main__:<module>:313 - Training step 6490: loss = 3.2574 | 3024.51ms | Tokens/s = 173,346.5
2025-01-17 12:24:35.731 | DEBUG    | __main__:<module>:313 - Training step 6500: loss = 3.4953 | 3022.57ms | Tokens/s = 173,457.5
2025-01-17 12:25:05.974 | DEBUG    | __main__:<module>:313 - Training step 6510: loss = 3.1644 | 3025.05ms | Tokens/s = 173,315.7
2025-01-17 12:25:36.204 | DEBUG    | __main__:<module>:313 - Training step 6520: loss = 3.2254 | 3023.42ms | Tokens/s = 173,408.6
2025-01-17 12:26:06.458 | DEBUG    | __main__:<module>:313 - Training step 6530: loss = 3.2193 | 3027.21ms | Tokens/s = 173,191.8
2025-01-17 12:26:36.718 | DEBUG    | __main__:<module>:313 - Training step 6540: loss = 3.3029 | 3023.82ms | Tokens/s = 173,386.0
2025-01-17 12:27:06.965 | DEBUG    | __main__:<module>:313 - Training step 6550: loss = 3.2960 | 3025.16ms | Tokens/s = 173,309.3
2025-01-17 12:27:37.202 | DEBUG    | __main__:<module>:313 - Training step 6560: loss = 3.6232 | 3022.90ms | Tokens/s = 173,438.5
2025-01-17 12:28:07.432 | DEBUG    | __main__:<module>:313 - Training step 6570: loss = 3.2806 | 3024.50ms | Tokens/s = 173,347.0
2025-01-17 12:28:37.690 | DEBUG    | __main__:<module>:313 - Training step 6580: loss = 3.2710 | 3025.37ms | Tokens/s = 173,297.0
2025-01-17 12:29:07.922 | DEBUG    | __main__:<module>:313 - Training step 6590: loss = 3.4992 | 3022.81ms | Tokens/s = 173,443.7
2025-01-17 12:29:38.147 | DEBUG    | __main__:<module>:313 - Training step 6600: loss = 3.4468 | 3022.17ms | Tokens/s = 173,480.7
2025-01-17 12:30:08.365 | DEBUG    | __main__:<module>:313 - Training step 6610: loss = 3.4320 | 3021.73ms | Tokens/s = 173,505.6
2025-01-17 12:30:38.588 | DEBUG    | __main__:<module>:313 - Training step 6620: loss = 3.3913 | 3021.45ms | Tokens/s = 173,521.8
2025-01-17 12:31:08.810 | DEBUG    | __main__:<module>:313 - Training step 6630: loss = 3.2653 | 3021.91ms | Tokens/s = 173,495.7
2025-01-17 12:31:39.026 | DEBUG    | __main__:<module>:313 - Training step 6640: loss = 3.3727 | 3022.10ms | Tokens/s = 173,484.4
2025-01-17 12:32:09.255 | DEBUG    | __main__:<module>:313 - Training step 6650: loss = 3.5813 | 3024.32ms | Tokens/s = 173,357.5
2025-01-17 12:32:39.511 | DEBUG    | __main__:<module>:313 - Training step 6660: loss = 3.4460 | 3025.75ms | Tokens/s = 173,275.3
2025-01-17 12:33:09.753 | DEBUG    | __main__:<module>:313 - Training step 6670: loss = 3.4617 | 3023.50ms | Tokens/s = 173,404.1
2025-01-17 12:33:39.993 | DEBUG    | __main__:<module>:313 - Training step 6680: loss = 3.3265 | 3026.11ms | Tokens/s = 173,255.0
2025-01-17 12:34:10.229 | DEBUG    | __main__:<module>:313 - Training step 6690: loss = 3.3526 | 3024.40ms | Tokens/s = 173,352.7
2025-01-17 12:34:40.452 | DEBUG    | __main__:<module>:313 - Training step 6700: loss = 3.5334 | 3020.99ms | Tokens/s = 173,548.4
2025-01-17 12:35:10.673 | DEBUG    | __main__:<module>:313 - Training step 6710: loss = 3.3280 | 3023.65ms | Tokens/s = 173,395.8
2025-01-17 12:35:40.931 | DEBUG    | __main__:<module>:313 - Training step 6720: loss = 3.3151 | 3026.58ms | Tokens/s = 173,228.0
2025-01-17 12:36:11.200 | DEBUG    | __main__:<module>:313 - Training step 6730: loss = 3.5168 | 3024.96ms | Tokens/s = 173,320.4
2025-01-17 12:36:41.445 | DEBUG    | __main__:<module>:313 - Training step 6740: loss = 3.4460 | 3024.29ms | Tokens/s = 173,359.1
2025-01-17 12:37:11.682 | DEBUG    | __main__:<module>:313 - Training step 6750: loss = 3.4663 | 3023.45ms | Tokens/s = 173,407.0
2025-01-17 12:37:41.913 | DEBUG    | __main__:<module>:313 - Training step 6760: loss = 3.4670 | 3022.14ms | Tokens/s = 173,482.1
2025-01-17 12:38:12.131 | DEBUG    | __main__:<module>:313 - Training step 6770: loss = 3.2916 | 3022.22ms | Tokens/s = 173,477.7
2025-01-17 12:38:42.346 | DEBUG    | __main__:<module>:313 - Training step 6780: loss = 3.3564 | 3021.93ms | Tokens/s = 173,494.4
2025-01-17 12:39:12.561 | DEBUG    | __main__:<module>:313 - Training step 6790: loss = 3.4310 | 3018.09ms | Tokens/s = 173,715.0
2025-01-17 12:39:42.794 | DEBUG    | __main__:<module>:313 - Training step 6800: loss = 3.3547 | 3024.66ms | Tokens/s = 173,337.6
2025-01-17 12:40:13.047 | DEBUG    | __main__:<module>:313 - Training step 6810: loss = 3.3505 | 3025.82ms | Tokens/s = 173,271.5
2025-01-17 12:40:43.287 | DEBUG    | __main__:<module>:313 - Training step 6820: loss = 3.3543 | 3025.42ms | Tokens/s = 173,294.5
2025-01-17 12:41:13.517 | DEBUG    | __main__:<module>:313 - Training step 6830: loss = 3.3490 | 3023.39ms | Tokens/s = 173,410.8
2025-01-17 12:41:43.740 | DEBUG    | __main__:<module>:313 - Training step 6840: loss = 3.4630 | 3020.21ms | Tokens/s = 173,593.0
2025-01-17 12:42:13.965 | DEBUG    | __main__:<module>:313 - Training step 6850: loss = 3.3389 | 3024.06ms | Tokens/s = 173,372.0
2025-01-17 12:42:44.180 | DEBUG    | __main__:<module>:313 - Training step 6860: loss = 3.3216 | 3020.70ms | Tokens/s = 173,565.2
2025-01-17 12:43:14.407 | DEBUG    | __main__:<module>:313 - Training step 6870: loss = 3.3326 | 3022.62ms | Tokens/s = 173,455.0
2025-01-17 12:43:44.623 | DEBUG    | __main__:<module>:313 - Training step 6880: loss = 3.3486 | 3019.82ms | Tokens/s = 173,615.5
2025-01-17 12:44:14.839 | DEBUG    | __main__:<module>:313 - Training step 6890: loss = 3.3328 | 3021.66ms | Tokens/s = 173,509.9
2025-01-17 12:44:45.054 | DEBUG    | __main__:<module>:313 - Training step 6900: loss = 3.4411 | 3020.03ms | Tokens/s = 173,603.6
2025-01-17 12:45:15.268 | DEBUG    | __main__:<module>:313 - Training step 6910: loss = 3.3561 | 3021.93ms | Tokens/s = 173,494.5
2025-01-17 12:45:45.497 | DEBUG    | __main__:<module>:313 - Training step 6920: loss = 3.3874 | 3025.57ms | Tokens/s = 173,286.0
2025-01-17 12:46:15.761 | DEBUG    | __main__:<module>:313 - Training step 6930: loss = 3.4029 | 3027.17ms | Tokens/s = 173,194.1
2025-01-17 12:46:46.017 | DEBUG    | __main__:<module>:313 - Training step 6940: loss = 3.4119 | 3023.60ms | Tokens/s = 173,398.6
2025-01-17 12:47:16.257 | DEBUG    | __main__:<module>:313 - Training step 6950: loss = 3.4926 | 3024.91ms | Tokens/s = 173,323.8
2025-01-17 12:47:46.486 | DEBUG    | __main__:<module>:313 - Training step 6960: loss = 3.3555 | 3023.47ms | Tokens/s = 173,406.2
2025-01-17 12:48:16.712 | DEBUG    | __main__:<module>:313 - Training step 6970: loss = 3.3160 | 3022.23ms | Tokens/s = 173,477.4
2025-01-17 12:48:46.937 | DEBUG    | __main__:<module>:313 - Training step 6980: loss = 3.5249 | 3025.14ms | Tokens/s = 173,310.6
2025-01-17 12:49:17.197 | DEBUG    | __main__:<module>:313 - Training step 6990: loss = 3.3387 | 3029.82ms | Tokens/s = 173,042.6
2025-01-17 12:49:50.895 | INFO     | __main__:<module>:265 - Step 7,000/20,000 loss: 3.3843 (T) 3.3747 (V) | lr=8.2e-03
2025-01-17 12:49:50.896 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 12:50:03.998 | DEBUG    | __main__:<module>:313 - Training step 7000: loss = 3.4167 | 19566.61ms | Tokens/s = 26,795.0
2025-01-17 12:50:34.101 | DEBUG    | __main__:<module>:313 - Training step 7010: loss = 3.2985 | 3014.16ms | Tokens/s = 173,941.5
2025-01-17 12:51:04.302 | DEBUG    | __main__:<module>:313 - Training step 7020: loss = 3.5917 | 3022.07ms | Tokens/s = 173,486.4
2025-01-17 12:51:34.544 | DEBUG    | __main__:<module>:313 - Training step 7030: loss = 3.4835 | 3025.68ms | Tokens/s = 173,279.6
2025-01-17 12:52:04.799 | DEBUG    | __main__:<module>:313 - Training step 7040: loss = 3.5433 | 3023.86ms | Tokens/s = 173,383.9
2025-01-17 12:52:35.041 | DEBUG    | __main__:<module>:313 - Training step 7050: loss = 3.4039 | 3023.72ms | Tokens/s = 173,391.9
2025-01-17 12:53:05.282 | DEBUG    | __main__:<module>:313 - Training step 7060: loss = 3.2343 | 3024.69ms | Tokens/s = 173,335.9
2025-01-17 12:53:35.515 | DEBUG    | __main__:<module>:313 - Training step 7070: loss = 3.4568 | 3021.22ms | Tokens/s = 173,535.2
2025-01-17 12:54:05.750 | DEBUG    | __main__:<module>:313 - Training step 7080: loss = 3.5032 | 3023.24ms | Tokens/s = 173,419.5
2025-01-17 12:54:35.979 | DEBUG    | __main__:<module>:313 - Training step 7090: loss = 3.5206 | 3023.78ms | Tokens/s = 173,388.5
2025-01-17 12:55:06.200 | DEBUG    | __main__:<module>:313 - Training step 7100: loss = 3.5120 | 3022.67ms | Tokens/s = 173,451.8
2025-01-17 12:55:36.421 | DEBUG    | __main__:<module>:313 - Training step 7110: loss = 3.4792 | 3023.25ms | Tokens/s = 173,418.5
2025-01-17 12:56:06.648 | DEBUG    | __main__:<module>:313 - Training step 7120: loss = 3.5025 | 3022.22ms | Tokens/s = 173,477.8
2025-01-17 12:56:36.874 | DEBUG    | __main__:<module>:313 - Training step 7130: loss = 3.3750 | 3022.90ms | Tokens/s = 173,438.8
2025-01-17 12:57:07.097 | DEBUG    | __main__:<module>:313 - Training step 7140: loss = 3.4127 | 3022.41ms | Tokens/s = 173,467.0
2025-01-17 12:57:37.348 | DEBUG    | __main__:<module>:313 - Training step 7150: loss = 3.4570 | 3027.11ms | Tokens/s = 173,197.4
2025-01-17 12:58:07.629 | DEBUG    | __main__:<module>:313 - Training step 7160: loss = 3.5540 | 3027.94ms | Tokens/s = 173,150.0
2025-01-17 12:58:37.898 | DEBUG    | __main__:<module>:313 - Training step 7170: loss = 3.3676 | 3027.88ms | Tokens/s = 173,153.3
2025-01-17 12:59:08.154 | DEBUG    | __main__:<module>:313 - Training step 7180: loss = 3.4211 | 3024.90ms | Tokens/s = 173,324.1
2025-01-17 12:59:38.398 | DEBUG    | __main__:<module>:313 - Training step 7190: loss = 3.4684 | 3022.76ms | Tokens/s = 173,446.5
2025-01-17 13:00:08.635 | DEBUG    | __main__:<module>:313 - Training step 7200: loss = 3.5081 | 3022.12ms | Tokens/s = 173,483.3
2025-01-17 13:00:38.867 | DEBUG    | __main__:<module>:313 - Training step 7210: loss = 3.4652 | 3021.77ms | Tokens/s = 173,503.6
2025-01-17 13:01:09.090 | DEBUG    | __main__:<module>:313 - Training step 7220: loss = 3.5657 | 3022.60ms | Tokens/s = 173,455.7
2025-01-17 13:01:39.300 | DEBUG    | __main__:<module>:313 - Training step 7230: loss = 3.1929 | 3021.40ms | Tokens/s = 173,524.8
2025-01-17 13:02:09.490 | DEBUG    | __main__:<module>:313 - Training step 7240: loss = 3.5014 | 3017.48ms | Tokens/s = 173,750.1
2025-01-17 13:02:39.674 | DEBUG    | __main__:<module>:313 - Training step 7250: loss = 3.4412 | 3020.59ms | Tokens/s = 173,571.5
2025-01-17 13:03:09.866 | DEBUG    | __main__:<module>:313 - Training step 7260: loss = 3.3955 | 3019.18ms | Tokens/s = 173,652.6
2025-01-17 13:03:40.071 | DEBUG    | __main__:<module>:313 - Training step 7270: loss = 3.4368 | 3021.77ms | Tokens/s = 173,503.8
2025-01-17 13:04:10.277 | DEBUG    | __main__:<module>:313 - Training step 7280: loss = 3.3126 | 3021.04ms | Tokens/s = 173,545.8
2025-01-17 13:04:40.490 | DEBUG    | __main__:<module>:313 - Training step 7290: loss = 3.2544 | 3021.65ms | Tokens/s = 173,510.6
2025-01-17 13:05:10.709 | DEBUG    | __main__:<module>:313 - Training step 7300: loss = 3.2987 | 3019.73ms | Tokens/s = 173,620.6
2025-01-17 13:05:40.936 | DEBUG    | __main__:<module>:313 - Training step 7310: loss = 3.3121 | 3021.18ms | Tokens/s = 173,537.6
2025-01-17 13:06:11.163 | DEBUG    | __main__:<module>:313 - Training step 7320: loss = 3.3788 | 3024.84ms | Tokens/s = 173,327.4
2025-01-17 13:06:41.394 | DEBUG    | __main__:<module>:313 - Training step 7330: loss = 3.7042 | 3024.43ms | Tokens/s = 173,350.7
2025-01-17 13:07:11.629 | DEBUG    | __main__:<module>:313 - Training step 7340: loss = 3.3984 | 3021.79ms | Tokens/s = 173,502.2
2025-01-17 13:07:41.869 | DEBUG    | __main__:<module>:313 - Training step 7350: loss = 3.5071 | 3025.84ms | Tokens/s = 173,270.0
2025-01-17 13:08:12.092 | DEBUG    | __main__:<module>:313 - Training step 7360: loss = 3.3199 | 3018.99ms | Tokens/s = 173,663.6
2025-01-17 13:08:42.273 | DEBUG    | __main__:<module>:313 - Training step 7370: loss = 3.4268 | 3015.40ms | Tokens/s = 173,870.0
2025-01-17 13:09:12.437 | DEBUG    | __main__:<module>:313 - Training step 7380: loss = 3.4121 | 3014.97ms | Tokens/s = 173,894.9
2025-01-17 13:09:42.623 | DEBUG    | __main__:<module>:313 - Training step 7390: loss = 3.2892 | 3016.35ms | Tokens/s = 173,815.3
2025-01-17 13:10:12.841 | DEBUG    | __main__:<module>:313 - Training step 7400: loss = 3.2558 | 3023.74ms | Tokens/s = 173,390.8
2025-01-17 13:10:43.092 | DEBUG    | __main__:<module>:313 - Training step 7410: loss = 3.3882 | 3026.48ms | Tokens/s = 173,233.6
2025-01-17 13:11:13.337 | DEBUG    | __main__:<module>:313 - Training step 7420: loss = 3.4446 | 3023.87ms | Tokens/s = 173,383.2
2025-01-17 13:11:43.558 | DEBUG    | __main__:<module>:313 - Training step 7430: loss = 3.5233 | 3019.33ms | Tokens/s = 173,643.9
2025-01-17 13:12:13.753 | DEBUG    | __main__:<module>:313 - Training step 7440: loss = 3.5308 | 3018.41ms | Tokens/s = 173,696.8
2025-01-17 13:12:43.947 | DEBUG    | __main__:<module>:313 - Training step 7450: loss = 3.3273 | 3020.16ms | Tokens/s = 173,596.2
2025-01-17 13:13:14.144 | DEBUG    | __main__:<module>:313 - Training step 7460: loss = 3.3951 | 3019.49ms | Tokens/s = 173,634.8
2025-01-17 13:13:44.341 | DEBUG    | __main__:<module>:313 - Training step 7470: loss = 3.3312 | 3020.81ms | Tokens/s = 173,558.6
2025-01-17 13:14:14.537 | DEBUG    | __main__:<module>:313 - Training step 7480: loss = 3.5737 | 3022.58ms | Tokens/s = 173,457.2
2025-01-17 13:14:44.736 | DEBUG    | __main__:<module>:313 - Training step 7490: loss = 3.6106 | 3019.64ms | Tokens/s = 173,625.9
2025-01-17 13:15:14.942 | DEBUG    | __main__:<module>:313 - Training step 7500: loss = 3.5072 | 3019.35ms | Tokens/s = 173,642.4
2025-01-17 13:15:45.159 | DEBUG    | __main__:<module>:313 - Training step 7510: loss = 3.5207 | 3021.17ms | Tokens/s = 173,538.3
2025-01-17 13:16:15.374 | DEBUG    | __main__:<module>:313 - Training step 7520: loss = 3.4851 | 3022.44ms | Tokens/s = 173,465.4
2025-01-17 13:16:45.599 | DEBUG    | __main__:<module>:313 - Training step 7530: loss = 3.3966 | 3022.00ms | Tokens/s = 173,490.6
2025-01-17 13:17:15.824 | DEBUG    | __main__:<module>:313 - Training step 7540: loss = 3.4405 | 3023.31ms | Tokens/s = 173,415.2
2025-01-17 13:17:46.042 | DEBUG    | __main__:<module>:313 - Training step 7550: loss = 3.3051 | 3022.77ms | Tokens/s = 173,446.0
2025-01-17 13:18:16.276 | DEBUG    | __main__:<module>:313 - Training step 7560: loss = 3.3597 | 3022.12ms | Tokens/s = 173,483.8
2025-01-17 13:18:46.504 | DEBUG    | __main__:<module>:313 - Training step 7570: loss = 3.4083 | 3021.09ms | Tokens/s = 173,542.7
2025-01-17 13:19:16.704 | DEBUG    | __main__:<module>:313 - Training step 7580: loss = 3.2281 | 3018.51ms | Tokens/s = 173,691.1
2025-01-17 13:19:46.890 | DEBUG    | __main__:<module>:313 - Training step 7590: loss = 3.4798 | 3016.67ms | Tokens/s = 173,796.7
2025-01-17 13:20:17.087 | DEBUG    | __main__:<module>:313 - Training step 7600: loss = 3.2832 | 3018.80ms | Tokens/s = 173,674.2
2025-01-17 13:20:47.294 | DEBUG    | __main__:<module>:313 - Training step 7610: loss = 3.3885 | 3018.99ms | Tokens/s = 173,663.3
2025-01-17 13:21:17.498 | DEBUG    | __main__:<module>:313 - Training step 7620: loss = 3.3874 | 3019.75ms | Tokens/s = 173,619.8
2025-01-17 13:21:47.707 | DEBUG    | __main__:<module>:313 - Training step 7630: loss = 3.5732 | 3021.63ms | Tokens/s = 173,511.5
2025-01-17 13:22:17.919 | DEBUG    | __main__:<module>:313 - Training step 7640: loss = 3.3759 | 3020.46ms | Tokens/s = 173,579.0
2025-01-17 13:22:48.138 | DEBUG    | __main__:<module>:313 - Training step 7650: loss = 3.4479 | 3021.89ms | Tokens/s = 173,496.9
2025-01-17 13:23:18.361 | DEBUG    | __main__:<module>:313 - Training step 7660: loss = 3.4147 | 3021.42ms | Tokens/s = 173,523.8
2025-01-17 13:23:48.591 | DEBUG    | __main__:<module>:313 - Training step 7670: loss = 3.3347 | 3022.53ms | Tokens/s = 173,460.1
2025-01-17 13:24:18.811 | DEBUG    | __main__:<module>:313 - Training step 7680: loss = 3.1962 | 3021.59ms | Tokens/s = 173,514.2
2025-01-17 13:24:49.040 | DEBUG    | __main__:<module>:313 - Training step 7690: loss = 3.4605 | 3024.84ms | Tokens/s = 173,327.7
2025-01-17 13:25:19.258 | DEBUG    | __main__:<module>:313 - Training step 7700: loss = 3.1899 | 3020.08ms | Tokens/s = 173,600.9
2025-01-17 13:25:49.485 | DEBUG    | __main__:<module>:313 - Training step 7710: loss = 3.4386 | 3023.13ms | Tokens/s = 173,425.4
2025-01-17 13:26:19.713 | DEBUG    | __main__:<module>:313 - Training step 7720: loss = 3.4023 | 3020.71ms | Tokens/s = 173,564.7
2025-01-17 13:26:49.923 | DEBUG    | __main__:<module>:313 - Training step 7730: loss = 3.5119 | 3020.00ms | Tokens/s = 173,605.3
2025-01-17 13:27:20.117 | DEBUG    | __main__:<module>:313 - Training step 7740: loss = 3.4381 | 3017.51ms | Tokens/s = 173,748.3
2025-01-17 13:27:50.317 | DEBUG    | __main__:<module>:313 - Training step 7750: loss = 3.3394 | 3020.53ms | Tokens/s = 173,574.6
2025-01-17 13:28:20.525 | DEBUG    | __main__:<module>:313 - Training step 7760: loss = 3.3263 | 3022.25ms | Tokens/s = 173,476.3
2025-01-17 13:28:50.734 | DEBUG    | __main__:<module>:313 - Training step 7770: loss = 3.3907 | 3019.73ms | Tokens/s = 173,620.9
2025-01-17 13:29:20.946 | DEBUG    | __main__:<module>:313 - Training step 7780: loss = 3.4883 | 3021.70ms | Tokens/s = 173,507.7
2025-01-17 13:29:51.165 | DEBUG    | __main__:<module>:313 - Training step 7790: loss = 3.3227 | 3022.45ms | Tokens/s = 173,464.5
2025-01-17 13:30:21.373 | DEBUG    | __main__:<module>:313 - Training step 7800: loss = 3.3759 | 3015.69ms | Tokens/s = 173,853.3
2025-01-17 13:30:51.552 | DEBUG    | __main__:<module>:313 - Training step 7810: loss = 3.2536 | 3020.09ms | Tokens/s = 173,600.4
2025-01-17 13:31:21.739 | DEBUG    | __main__:<module>:313 - Training step 7820: loss = 3.2217 | 3020.66ms | Tokens/s = 173,567.2
2025-01-17 13:31:51.938 | DEBUG    | __main__:<module>:313 - Training step 7830: loss = 3.4960 | 3018.03ms | Tokens/s = 173,718.6
2025-01-17 13:32:22.133 | DEBUG    | __main__:<module>:313 - Training step 7840: loss = 3.3193 | 3019.62ms | Tokens/s = 173,627.4
2025-01-17 13:32:52.342 | DEBUG    | __main__:<module>:313 - Training step 7850: loss = 3.3203 | 3019.98ms | Tokens/s = 173,606.6
2025-01-17 13:33:22.553 | DEBUG    | __main__:<module>:313 - Training step 7860: loss = 3.3985 | 3019.52ms | Tokens/s = 173,633.1
2025-01-17 13:33:52.765 | DEBUG    | __main__:<module>:313 - Training step 7870: loss = 3.4328 | 3022.15ms | Tokens/s = 173,482.0
2025-01-17 13:34:22.980 | DEBUG    | __main__:<module>:313 - Training step 7880: loss = 3.5083 | 3021.78ms | Tokens/s = 173,502.8
2025-01-17 13:34:53.205 | DEBUG    | __main__:<module>:313 - Training step 7890: loss = 3.2810 | 3023.01ms | Tokens/s = 173,432.5
2025-01-17 13:35:23.414 | DEBUG    | __main__:<module>:313 - Training step 7900: loss = 3.3839 | 3018.65ms | Tokens/s = 173,683.2
2025-01-17 13:35:53.623 | DEBUG    | __main__:<module>:313 - Training step 7910: loss = 3.4333 | 3020.97ms | Tokens/s = 173,549.8
2025-01-17 13:36:23.842 | DEBUG    | __main__:<module>:313 - Training step 7920: loss = 3.3617 | 3021.61ms | Tokens/s = 173,512.9
2025-01-17 13:36:54.058 | DEBUG    | __main__:<module>:313 - Training step 7930: loss = 3.3214 | 3020.64ms | Tokens/s = 173,568.7
2025-01-17 13:37:24.269 | DEBUG    | __main__:<module>:313 - Training step 7940: loss = 3.4679 | 3021.68ms | Tokens/s = 173,508.8
2025-01-17 13:37:54.482 | DEBUG    | __main__:<module>:313 - Training step 7950: loss = 3.3712 | 3019.26ms | Tokens/s = 173,647.8
2025-01-17 13:38:24.698 | DEBUG    | __main__:<module>:313 - Training step 7960: loss = 3.4695 | 3020.49ms | Tokens/s = 173,577.3
2025-01-17 13:38:54.907 | DEBUG    | __main__:<module>:313 - Training step 7970: loss = 3.2158 | 3018.82ms | Tokens/s = 173,673.3
2025-01-17 13:39:25.116 | DEBUG    | __main__:<module>:313 - Training step 7980: loss = 3.3752 | 3022.86ms | Tokens/s = 173,441.1
2025-01-17 13:39:55.326 | DEBUG    | __main__:<module>:313 - Training step 7990: loss = 3.4920 | 3020.56ms | Tokens/s = 173,573.0
2025-01-17 13:40:28.972 | INFO     | __main__:<module>:265 - Step 8,000/20,000 loss: 3.3511 (T) 3.3617 (V) | lr=7.5e-03
2025-01-17 13:40:28.974 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 13:40:42.213 | DEBUG    | __main__:<module>:313 - Training step 8000: loss = 3.3382 | 19693.33ms | Tokens/s = 26,622.6
2025-01-17 13:41:12.275 | DEBUG    | __main__:<module>:313 - Training step 8010: loss = 3.3025 | 3010.99ms | Tokens/s = 174,125.0
2025-01-17 13:41:42.422 | DEBUG    | __main__:<module>:313 - Training step 8020: loss = 3.2704 | 3013.76ms | Tokens/s = 173,964.6
2025-01-17 13:42:12.594 | DEBUG    | __main__:<module>:313 - Training step 8030: loss = 3.3227 | 3018.20ms | Tokens/s = 173,709.1
2025-01-17 13:42:42.779 | DEBUG    | __main__:<module>:313 - Training step 8040: loss = 3.3745 | 3020.23ms | Tokens/s = 173,591.9
2025-01-17 13:43:12.968 | DEBUG    | __main__:<module>:313 - Training step 8050: loss = 3.5521 | 3020.01ms | Tokens/s = 173,604.8
2025-01-17 13:43:43.164 | DEBUG    | __main__:<module>:313 - Training step 8060: loss = 3.3832 | 3017.09ms | Tokens/s = 173,772.7
2025-01-17 13:44:13.361 | DEBUG    | __main__:<module>:313 - Training step 8070: loss = 3.5913 | 3020.82ms | Tokens/s = 173,558.1
2025-01-17 13:44:43.560 | DEBUG    | __main__:<module>:313 - Training step 8080: loss = 3.3923 | 3019.81ms | Tokens/s = 173,616.1
2025-01-17 13:45:13.761 | DEBUG    | __main__:<module>:313 - Training step 8090: loss = 3.4100 | 3022.19ms | Tokens/s = 173,479.8
2025-01-17 13:45:43.970 | DEBUG    | __main__:<module>:313 - Training step 8100: loss = 3.0980 | 3021.51ms | Tokens/s = 173,518.6
2025-01-17 13:46:14.185 | DEBUG    | __main__:<module>:313 - Training step 8110: loss = 3.2460 | 3021.42ms | Tokens/s = 173,523.5
2025-01-17 13:46:44.398 | DEBUG    | __main__:<module>:313 - Training step 8120: loss = 3.2801 | 3020.89ms | Tokens/s = 173,554.4
2025-01-17 13:47:14.612 | DEBUG    | __main__:<module>:313 - Training step 8130: loss = 3.4961 | 3020.71ms | Tokens/s = 173,564.6
2025-01-17 13:47:44.823 | DEBUG    | __main__:<module>:313 - Training step 8140: loss = 3.2737 | 3021.31ms | Tokens/s = 173,530.2
2025-01-17 13:48:15.036 | DEBUG    | __main__:<module>:313 - Training step 8150: loss = 3.3864 | 3021.37ms | Tokens/s = 173,526.7
2025-01-17 13:48:45.253 | DEBUG    | __main__:<module>:313 - Training step 8160: loss = 3.3455 | 3020.20ms | Tokens/s = 173,593.7
2025-01-17 13:49:15.469 | DEBUG    | __main__:<module>:313 - Training step 8170: loss = 3.3248 | 3022.00ms | Tokens/s = 173,490.3
2025-01-17 13:49:45.688 | DEBUG    | __main__:<module>:313 - Training step 8180: loss = 3.4759 | 3021.95ms | Tokens/s = 173,493.3
2025-01-17 13:50:15.894 | DEBUG    | __main__:<module>:313 - Training step 8190: loss = 3.1766 | 3020.35ms | Tokens/s = 173,585.1
2025-01-17 13:50:46.106 | DEBUG    | __main__:<module>:313 - Training step 8200: loss = 3.3416 | 3019.34ms | Tokens/s = 173,643.5
2025-01-17 13:51:16.317 | DEBUG    | __main__:<module>:313 - Training step 8210: loss = 3.2844 | 3021.89ms | Tokens/s = 173,496.6
2025-01-17 13:51:46.536 | DEBUG    | __main__:<module>:313 - Training step 8220: loss = 3.3320 | 3022.09ms | Tokens/s = 173,485.0
2025-01-17 13:52:16.760 | DEBUG    | __main__:<module>:313 - Training step 8230: loss = 3.3415 | 3022.98ms | Tokens/s = 173,434.4
2025-01-17 13:52:46.993 | DEBUG    | __main__:<module>:313 - Training step 8240: loss = 3.3288 | 3022.75ms | Tokens/s = 173,447.3
2025-01-17 13:53:17.206 | DEBUG    | __main__:<module>:313 - Training step 8250: loss = 3.4469 | 3021.49ms | Tokens/s = 173,519.4
2025-01-17 13:53:47.398 | DEBUG    | __main__:<module>:313 - Training step 8260: loss = 3.1641 | 3017.09ms | Tokens/s = 173,772.6
2025-01-17 13:54:17.596 | DEBUG    | __main__:<module>:313 - Training step 8270: loss = 3.3949 | 3019.52ms | Tokens/s = 173,633.1
2025-01-17 13:54:47.811 | DEBUG    | __main__:<module>:313 - Training step 8280: loss = 3.4349 | 3022.38ms | Tokens/s = 173,468.7
2025-01-17 13:55:18.042 | DEBUG    | __main__:<module>:313 - Training step 8290: loss = 3.3500 | 3025.45ms | Tokens/s = 173,292.4
2025-01-17 13:55:48.267 | DEBUG    | __main__:<module>:313 - Training step 8300: loss = 3.4244 | 3019.46ms | Tokens/s = 173,636.1
2025-01-17 13:56:18.489 | DEBUG    | __main__:<module>:313 - Training step 8310: loss = 3.4312 | 3022.77ms | Tokens/s = 173,446.4
2025-01-17 13:56:48.726 | DEBUG    | __main__:<module>:313 - Training step 8320: loss = 3.3909 | 3025.20ms | Tokens/s = 173,306.7
2025-01-17 13:57:18.983 | DEBUG    | __main__:<module>:313 - Training step 8330: loss = 3.3761 | 3027.07ms | Tokens/s = 173,199.9
2025-01-17 13:57:49.223 | DEBUG    | __main__:<module>:313 - Training step 8340: loss = 3.1923 | 3021.51ms | Tokens/s = 173,518.5
2025-01-17 13:58:19.436 | DEBUG    | __main__:<module>:313 - Training step 8350: loss = 3.4161 | 3020.37ms | Tokens/s = 173,583.9
2025-01-17 13:58:49.632 | DEBUG    | __main__:<module>:313 - Training step 8360: loss = 3.3731 | 3017.92ms | Tokens/s = 173,725.0
2025-01-17 13:59:19.850 | DEBUG    | __main__:<module>:313 - Training step 8370: loss = 3.4668 | 3022.07ms | Tokens/s = 173,486.4
2025-01-17 13:59:50.082 | DEBUG    | __main__:<module>:313 - Training step 8380: loss = 3.2017 | 3021.89ms | Tokens/s = 173,496.7
2025-01-17 14:00:20.311 | DEBUG    | __main__:<module>:313 - Training step 8390: loss = 3.4703 | 3023.72ms | Tokens/s = 173,391.8
2025-01-17 14:00:50.546 | DEBUG    | __main__:<module>:313 - Training step 8400: loss = 3.2273 | 3022.08ms | Tokens/s = 173,485.7
2025-01-17 14:01:20.787 | DEBUG    | __main__:<module>:313 - Training step 8410: loss = 3.4524 | 3024.64ms | Tokens/s = 173,339.1
2025-01-17 14:01:51.006 | DEBUG    | __main__:<module>:313 - Training step 8420: loss = 3.0441 | 3020.27ms | Tokens/s = 173,589.8
2025-01-17 14:02:21.200 | DEBUG    | __main__:<module>:313 - Training step 8430: loss = 3.4815 | 3020.09ms | Tokens/s = 173,600.3
2025-01-17 14:02:51.408 | DEBUG    | __main__:<module>:313 - Training step 8440: loss = 3.0681 | 3022.47ms | Tokens/s = 173,463.6
2025-01-17 14:03:21.622 | DEBUG    | __main__:<module>:313 - Training step 8450: loss = 3.4618 | 3021.80ms | Tokens/s = 173,501.8
2025-01-17 14:03:51.850 | DEBUG    | __main__:<module>:313 - Training step 8460: loss = 3.2896 | 3024.03ms | Tokens/s = 173,374.1
2025-01-17 14:04:22.087 | DEBUG    | __main__:<module>:313 - Training step 8470: loss = 3.4359 | 3022.42ms | Tokens/s = 173,466.2
2025-01-17 14:04:52.325 | DEBUG    | __main__:<module>:313 - Training step 8480: loss = 3.2690 | 3024.19ms | Tokens/s = 173,364.8
2025-01-17 14:05:22.568 | DEBUG    | __main__:<module>:313 - Training step 8490: loss = 3.1360 | 3022.13ms | Tokens/s = 173,482.7
2025-01-17 14:05:52.789 | DEBUG    | __main__:<module>:313 - Training step 8500: loss = 3.2502 | 3020.21ms | Tokens/s = 173,593.4
2025-01-17 14:06:22.993 | DEBUG    | __main__:<module>:313 - Training step 8510: loss = 3.2184 | 3020.22ms | Tokens/s = 173,592.4
2025-01-17 14:06:53.215 | DEBUG    | __main__:<module>:313 - Training step 8520: loss = 3.3313 | 3021.89ms | Tokens/s = 173,496.8
2025-01-17 14:07:23.426 | DEBUG    | __main__:<module>:313 - Training step 8530: loss = 3.3027 | 3019.71ms | Tokens/s = 173,621.7
2025-01-17 14:07:53.631 | DEBUG    | __main__:<module>:313 - Training step 8540: loss = 3.3044 | 3023.29ms | Tokens/s = 173,416.2
2025-01-17 14:08:23.855 | DEBUG    | __main__:<module>:313 - Training step 8550: loss = 3.4865 | 3021.20ms | Tokens/s = 173,536.3
2025-01-17 14:08:54.062 | DEBUG    | __main__:<module>:313 - Training step 8560: loss = 3.1268 | 3018.28ms | Tokens/s = 173,704.2
2025-01-17 14:09:24.249 | DEBUG    | __main__:<module>:313 - Training step 8570: loss = 3.2903 | 3017.65ms | Tokens/s = 173,740.6
2025-01-17 14:09:54.426 | DEBUG    | __main__:<module>:313 - Training step 8580: loss = 3.2342 | 3019.73ms | Tokens/s = 173,621.1
2025-01-17 14:10:24.623 | DEBUG    | __main__:<module>:313 - Training step 8590: loss = 3.3209 | 3018.15ms | Tokens/s = 173,711.8
2025-01-17 14:10:54.847 | DEBUG    | __main__:<module>:313 - Training step 8600: loss = 3.4023 | 3023.63ms | Tokens/s = 173,397.1
2025-01-17 14:11:25.085 | DEBUG    | __main__:<module>:313 - Training step 8610: loss = 3.2894 | 3025.15ms | Tokens/s = 173,310.0
2025-01-17 14:11:55.323 | DEBUG    | __main__:<module>:313 - Training step 8620: loss = 3.4037 | 3023.34ms | Tokens/s = 173,413.6
2025-01-17 14:12:25.535 | DEBUG    | __main__:<module>:313 - Training step 8630: loss = 3.4119 | 3021.15ms | Tokens/s = 173,539.0
2025-01-17 14:12:55.763 | DEBUG    | __main__:<module>:313 - Training step 8640: loss = 3.2999 | 3023.09ms | Tokens/s = 173,427.9
2025-01-17 14:13:25.975 | DEBUG    | __main__:<module>:313 - Training step 8650: loss = 3.3173 | 3021.19ms | Tokens/s = 173,536.6
2025-01-17 14:13:56.195 | DEBUG    | __main__:<module>:313 - Training step 8660: loss = 3.2094 | 3022.61ms | Tokens/s = 173,455.5
2025-01-17 14:14:26.431 | DEBUG    | __main__:<module>:313 - Training step 8670: loss = 3.2642 | 3022.95ms | Tokens/s = 173,435.6
2025-01-17 14:14:56.681 | DEBUG    | __main__:<module>:313 - Training step 8680: loss = 3.2702 | 3027.32ms | Tokens/s = 173,185.7
2025-01-17 14:15:26.928 | DEBUG    | __main__:<module>:313 - Training step 8690: loss = 3.1741 | 3024.61ms | Tokens/s = 173,340.6
2025-01-17 14:15:57.144 | DEBUG    | __main__:<module>:313 - Training step 8700: loss = 3.4785 | 3019.20ms | Tokens/s = 173,651.0
2025-01-17 14:16:27.335 | DEBUG    | __main__:<module>:313 - Training step 8710: loss = 3.3445 | 3017.83ms | Tokens/s = 173,730.2
2025-01-17 14:16:57.530 | DEBUG    | __main__:<module>:313 - Training step 8720: loss = 3.4579 | 3021.93ms | Tokens/s = 173,494.7
2025-01-17 14:17:27.749 | DEBUG    | __main__:<module>:313 - Training step 8730: loss = 3.2995 | 3021.95ms | Tokens/s = 173,493.2
2025-01-17 14:17:57.989 | DEBUG    | __main__:<module>:313 - Training step 8740: loss = 3.0789 | 3024.73ms | Tokens/s = 173,333.6
2025-01-17 14:18:28.217 | DEBUG    | __main__:<module>:313 - Training step 8750: loss = 3.3252 | 3022.22ms | Tokens/s = 173,477.7
2025-01-17 14:18:58.418 | DEBUG    | __main__:<module>:313 - Training step 8760: loss = 3.1855 | 3018.55ms | Tokens/s = 173,688.6
2025-01-17 14:19:28.630 | DEBUG    | __main__:<module>:313 - Training step 8770: loss = 3.4316 | 3022.27ms | Tokens/s = 173,475.1
2025-01-17 14:19:58.861 | DEBUG    | __main__:<module>:313 - Training step 8780: loss = 3.3895 | 3022.00ms | Tokens/s = 173,490.5
2025-01-17 14:20:29.064 | DEBUG    | __main__:<module>:313 - Training step 8790: loss = 3.2350 | 3020.29ms | Tokens/s = 173,588.4
2025-01-17 14:20:59.273 | DEBUG    | __main__:<module>:313 - Training step 8800: loss = 3.3553 | 3019.90ms | Tokens/s = 173,610.8
2025-01-17 14:21:29.520 | DEBUG    | __main__:<module>:313 - Training step 8810: loss = 3.3138 | 3026.09ms | Tokens/s = 173,255.8
2025-01-17 14:21:59.758 | DEBUG    | __main__:<module>:313 - Training step 8820: loss = 3.3059 | 3023.55ms | Tokens/s = 173,401.3
2025-01-17 14:22:29.964 | DEBUG    | __main__:<module>:313 - Training step 8830: loss = 3.2895 | 3020.61ms | Tokens/s = 173,570.4
2025-01-17 14:23:00.181 | DEBUG    | __main__:<module>:313 - Training step 8840: loss = 3.5154 | 3025.55ms | Tokens/s = 173,286.9
2025-01-17 14:23:30.418 | DEBUG    | __main__:<module>:313 - Training step 8850: loss = 3.2929 | 3024.61ms | Tokens/s = 173,340.5
2025-01-17 14:24:00.648 | DEBUG    | __main__:<module>:313 - Training step 8860: loss = 3.4109 | 3023.23ms | Tokens/s = 173,419.6
2025-01-17 14:24:30.893 | DEBUG    | __main__:<module>:313 - Training step 8870: loss = 3.2131 | 3023.19ms | Tokens/s = 173,422.1
2025-01-17 14:25:01.119 | DEBUG    | __main__:<module>:313 - Training step 8880: loss = 3.3446 | 3020.06ms | Tokens/s = 173,602.0
2025-01-17 14:25:31.357 | DEBUG    | __main__:<module>:313 - Training step 8890: loss = 3.4615 | 3024.82ms | Tokens/s = 173,328.6
2025-01-17 14:26:01.581 | DEBUG    | __main__:<module>:313 - Training step 8900: loss = 3.2368 | 3018.71ms | Tokens/s = 173,679.3
2025-01-17 14:26:31.784 | DEBUG    | __main__:<module>:313 - Training step 8910: loss = 3.2649 | 3018.73ms | Tokens/s = 173,678.4
2025-01-17 14:27:01.994 | DEBUG    | __main__:<module>:313 - Training step 8920: loss = 3.4320 | 3019.85ms | Tokens/s = 173,613.9
2025-01-17 14:27:32.219 | DEBUG    | __main__:<module>:313 - Training step 8930: loss = 3.3353 | 3021.98ms | Tokens/s = 173,491.7
2025-01-17 14:28:02.453 | DEBUG    | __main__:<module>:313 - Training step 8940: loss = 3.3108 | 3022.63ms | Tokens/s = 173,454.5
2025-01-17 14:28:32.684 | DEBUG    | __main__:<module>:313 - Training step 8950: loss = 3.4152 | 3023.69ms | Tokens/s = 173,393.7
2025-01-17 14:29:02.913 | DEBUG    | __main__:<module>:313 - Training step 8960: loss = 3.3769 | 3020.05ms | Tokens/s = 173,602.6
2025-01-17 14:29:33.114 | DEBUG    | __main__:<module>:313 - Training step 8970: loss = 3.3381 | 3022.83ms | Tokens/s = 173,442.9
2025-01-17 14:30:03.335 | DEBUG    | __main__:<module>:313 - Training step 8980: loss = 3.4763 | 3019.78ms | Tokens/s = 173,617.8
2025-01-17 14:30:33.531 | DEBUG    | __main__:<module>:313 - Training step 8990: loss = 3.2143 | 3019.19ms | Tokens/s = 173,652.1
2025-01-17 14:31:07.178 | INFO     | __main__:<module>:265 - Step 9,000/20,000 loss: 3.3333 (T) 3.3645 (V) | lr=6.7e-03
2025-01-17 14:31:10.203 | DEBUG    | __main__:<module>:313 - Training step 9000: loss = 3.2145 | 9479.96ms | Tokens/s = 55,304.9
2025-01-17 14:31:40.419 | DEBUG    | __main__:<module>:313 - Training step 9010: loss = 3.5687 | 3021.46ms | Tokens/s = 173,521.5
2025-01-17 14:32:10.655 | DEBUG    | __main__:<module>:313 - Training step 9020: loss = 3.1341 | 3025.38ms | Tokens/s = 173,296.8
2025-01-17 14:32:40.907 | DEBUG    | __main__:<module>:313 - Training step 9030: loss = 3.4102 | 3025.87ms | Tokens/s = 173,268.7
2025-01-17 14:33:11.130 | DEBUG    | __main__:<module>:313 - Training step 9040: loss = 3.0903 | 3020.20ms | Tokens/s = 173,593.5
2025-01-17 14:33:41.335 | DEBUG    | __main__:<module>:313 - Training step 9050: loss = 3.2885 | 3019.01ms | Tokens/s = 173,662.2
2025-01-17 14:34:11.537 | DEBUG    | __main__:<module>:313 - Training step 9060: loss = 3.3905 | 3021.15ms | Tokens/s = 173,539.1
2025-01-17 14:34:41.764 | DEBUG    | __main__:<module>:313 - Training step 9070: loss = 3.2342 | 3023.96ms | Tokens/s = 173,377.8
2025-01-17 14:35:11.984 | DEBUG    | __main__:<module>:313 - Training step 9080: loss = 3.2164 | 3020.36ms | Tokens/s = 173,584.3
2025-01-17 14:35:42.182 | DEBUG    | __main__:<module>:313 - Training step 9090: loss = 3.2242 | 3019.69ms | Tokens/s = 173,623.0
2025-01-17 14:36:12.402 | DEBUG    | __main__:<module>:313 - Training step 9100: loss = 3.4960 | 3022.85ms | Tokens/s = 173,441.6
2025-01-17 14:36:42.641 | DEBUG    | __main__:<module>:313 - Training step 9110: loss = 3.4465 | 3023.64ms | Tokens/s = 173,396.4
2025-01-17 14:37:12.872 | DEBUG    | __main__:<module>:313 - Training step 9120: loss = 3.5645 | 3020.74ms | Tokens/s = 173,562.8
2025-01-17 14:37:43.080 | DEBUG    | __main__:<module>:313 - Training step 9130: loss = 3.2900 | 3021.82ms | Tokens/s = 173,500.5
2025-01-17 14:38:13.319 | DEBUG    | __main__:<module>:313 - Training step 9140: loss = 3.1796 | 3025.83ms | Tokens/s = 173,270.6
2025-01-17 14:38:43.562 | DEBUG    | __main__:<module>:313 - Training step 9150: loss = 3.3412 | 3024.61ms | Tokens/s = 173,340.5
2025-01-17 14:39:13.766 | DEBUG    | __main__:<module>:313 - Training step 9160: loss = 3.3672 | 3020.92ms | Tokens/s = 173,552.6
2025-01-17 14:39:43.964 | DEBUG    | __main__:<module>:313 - Training step 9170: loss = 3.2950 | 3018.90ms | Tokens/s = 173,668.7
2025-01-17 14:40:14.192 | DEBUG    | __main__:<module>:313 - Training step 9180: loss = 3.2767 | 3022.73ms | Tokens/s = 173,448.5
2025-01-17 14:40:44.440 | DEBUG    | __main__:<module>:313 - Training step 9190: loss = 3.4161 | 3026.29ms | Tokens/s = 173,244.5
2025-01-17 14:41:14.685 | DEBUG    | __main__:<module>:313 - Training step 9200: loss = 3.3098 | 3023.58ms | Tokens/s = 173,399.8
2025-01-17 14:41:44.895 | DEBUG    | __main__:<module>:313 - Training step 9210: loss = 3.3231 | 3021.55ms | Tokens/s = 173,516.5
2025-01-17 14:42:15.102 | DEBUG    | __main__:<module>:313 - Training step 9220: loss = 3.4486 | 3022.50ms | Tokens/s = 173,461.7
2025-01-17 14:42:45.327 | DEBUG    | __main__:<module>:313 - Training step 9230: loss = 3.4432 | 3021.63ms | Tokens/s = 173,511.5
2025-01-17 14:43:15.541 | DEBUG    | __main__:<module>:313 - Training step 9240: loss = 3.2341 | 3022.26ms | Tokens/s = 173,475.7
2025-01-17 14:43:45.765 | DEBUG    | __main__:<module>:313 - Training step 9250: loss = 3.1550 | 3020.88ms | Tokens/s = 173,554.5
2025-01-17 14:44:15.967 | DEBUG    | __main__:<module>:313 - Training step 9260: loss = 3.3708 | 3017.75ms | Tokens/s = 173,734.7
2025-01-17 14:44:46.155 | DEBUG    | __main__:<module>:313 - Training step 9270: loss = 3.2121 | 3021.11ms | Tokens/s = 173,541.8
2025-01-17 14:45:16.367 | DEBUG    | __main__:<module>:313 - Training step 9280: loss = 3.1736 | 3021.76ms | Tokens/s = 173,504.3
2025-01-17 14:45:46.602 | DEBUG    | __main__:<module>:313 - Training step 9290: loss = 3.4054 | 3024.46ms | Tokens/s = 173,349.3
2025-01-17 14:46:16.829 | DEBUG    | __main__:<module>:313 - Training step 9300: loss = 3.4214 | 3019.82ms | Tokens/s = 173,615.9
2025-01-17 14:46:47.052 | DEBUG    | __main__:<module>:313 - Training step 9310: loss = 3.2677 | 3023.75ms | Tokens/s = 173,390.0
2025-01-17 14:47:17.266 | DEBUG    | __main__:<module>:313 - Training step 9320: loss = 3.3406 | 3020.10ms | Tokens/s = 173,599.7
2025-01-17 14:47:47.463 | DEBUG    | __main__:<module>:313 - Training step 9330: loss = 3.1957 | 3019.06ms | Tokens/s = 173,659.5
2025-01-17 14:48:17.679 | DEBUG    | __main__:<module>:313 - Training step 9340: loss = 3.0943 | 3023.48ms | Tokens/s = 173,405.6
2025-01-17 14:48:47.922 | DEBUG    | __main__:<module>:313 - Training step 9350: loss = 3.1801 | 3024.33ms | Tokens/s = 173,356.9
2025-01-17 14:49:18.170 | DEBUG    | __main__:<module>:313 - Training step 9360: loss = 3.2951 | 3023.47ms | Tokens/s = 173,406.3
2025-01-17 14:49:48.393 | DEBUG    | __main__:<module>:313 - Training step 9370: loss = 3.1204 | 3021.21ms | Tokens/s = 173,535.6
2025-01-17 14:50:18.586 | DEBUG    | __main__:<module>:313 - Training step 9380: loss = 3.3602 | 3018.39ms | Tokens/s = 173,697.7
2025-01-17 14:50:48.787 | DEBUG    | __main__:<module>:313 - Training step 9390: loss = 3.2748 | 3021.33ms | Tokens/s = 173,529.0
2025-01-17 14:51:19.018 | DEBUG    | __main__:<module>:313 - Training step 9400: loss = 3.3907 | 3021.81ms | Tokens/s = 173,501.6
2025-01-17 14:51:49.242 | DEBUG    | __main__:<module>:313 - Training step 9410: loss = 3.2418 | 3023.45ms | Tokens/s = 173,407.2
2025-01-17 14:52:19.462 | DEBUG    | __main__:<module>:313 - Training step 9420: loss = 3.6869 | 3018.55ms | Tokens/s = 173,688.5
2025-01-17 14:52:49.654 | DEBUG    | __main__:<module>:313 - Training step 9430: loss = 3.3197 | 3016.50ms | Tokens/s = 173,806.8
2025-01-17 14:53:19.851 | DEBUG    | __main__:<module>:313 - Training step 9440: loss = 3.3447 | 3020.68ms | Tokens/s = 173,566.0
2025-01-17 14:53:50.046 | DEBUG    | __main__:<module>:313 - Training step 9450: loss = 3.4049 | 3017.48ms | Tokens/s = 173,750.5
2025-01-17 14:54:20.222 | DEBUG    | __main__:<module>:313 - Training step 9460: loss = 3.3901 | 3018.72ms | Tokens/s = 173,678.7
2025-01-17 14:54:50.387 | DEBUG    | __main__:<module>:313 - Training step 9470: loss = 3.1397 | 3015.92ms | Tokens/s = 173,839.9
2025-01-17 14:55:20.581 | DEBUG    | __main__:<module>:313 - Training step 9480: loss = 3.2076 | 3020.58ms | Tokens/s = 173,571.7
2025-01-17 14:55:50.796 | DEBUG    | __main__:<module>:313 - Training step 9490: loss = 3.3822 | 3020.69ms | Tokens/s = 173,565.8
2025-01-17 14:56:20.996 | DEBUG    | __main__:<module>:313 - Training step 9500: loss = 3.3395 | 3016.54ms | Tokens/s = 173,804.5
2025-01-17 14:56:51.174 | DEBUG    | __main__:<module>:313 - Training step 9510: loss = 3.2514 | 3013.81ms | Tokens/s = 173,961.9
2025-01-17 14:57:21.380 | DEBUG    | __main__:<module>:313 - Training step 9520: loss = 3.3100 | 3022.83ms | Tokens/s = 173,443.1
2025-01-17 14:57:51.613 | DEBUG    | __main__:<module>:313 - Training step 9530: loss = 3.2395 | 3023.12ms | Tokens/s = 173,425.9
2025-01-17 14:58:21.853 | DEBUG    | __main__:<module>:313 - Training step 9540: loss = 3.2855 | 3025.22ms | Tokens/s = 173,305.7
2025-01-17 14:58:52.106 | DEBUG    | __main__:<module>:313 - Training step 9550: loss = 3.4291 | 3026.22ms | Tokens/s = 173,248.6
2025-01-17 14:59:22.363 | DEBUG    | __main__:<module>:313 - Training step 9560: loss = 3.1752 | 3025.58ms | Tokens/s = 173,285.2
2025-01-17 14:59:52.588 | DEBUG    | __main__:<module>:313 - Training step 9570: loss = 3.3108 | 3022.43ms | Tokens/s = 173,465.9
2025-01-17 15:00:22.779 | DEBUG    | __main__:<module>:313 - Training step 9580: loss = 3.2802 | 3019.08ms | Tokens/s = 173,658.1
2025-01-17 15:00:52.969 | DEBUG    | __main__:<module>:313 - Training step 9590: loss = 3.3094 | 3022.46ms | Tokens/s = 173,464.0
2025-01-17 15:01:23.195 | DEBUG    | __main__:<module>:313 - Training step 9600: loss = 3.3596 | 3021.39ms | Tokens/s = 173,525.5
2025-01-17 15:01:53.430 | DEBUG    | __main__:<module>:313 - Training step 9610: loss = 3.3735 | 3021.09ms | Tokens/s = 173,542.5
2025-01-17 15:02:23.630 | DEBUG    | __main__:<module>:313 - Training step 9620: loss = 3.2327 | 3019.18ms | Tokens/s = 173,652.4
2025-01-17 15:02:53.848 | DEBUG    | __main__:<module>:313 - Training step 9630: loss = 3.3847 | 3023.61ms | Tokens/s = 173,397.9
2025-01-17 15:03:24.078 | DEBUG    | __main__:<module>:313 - Training step 9640: loss = 3.2078 | 3022.33ms | Tokens/s = 173,471.3
2025-01-17 15:03:54.289 | DEBUG    | __main__:<module>:313 - Training step 9650: loss = 3.3889 | 3018.68ms | Tokens/s = 173,681.3
2025-01-17 15:04:24.481 | DEBUG    | __main__:<module>:313 - Training step 9660: loss = 3.3791 | 3017.22ms | Tokens/s = 173,765.3
2025-01-17 15:04:54.688 | DEBUG    | __main__:<module>:313 - Training step 9670: loss = 3.2469 | 3022.16ms | Tokens/s = 173,481.3
2025-01-17 15:05:24.921 | DEBUG    | __main__:<module>:313 - Training step 9680: loss = 3.3139 | 3025.29ms | Tokens/s = 173,301.7
2025-01-17 15:05:55.173 | DEBUG    | __main__:<module>:313 - Training step 9690: loss = 3.1310 | 3026.59ms | Tokens/s = 173,227.2
2025-01-17 15:06:25.404 | DEBUG    | __main__:<module>:313 - Training step 9700: loss = 3.4205 | 3019.97ms | Tokens/s = 173,607.0
2025-01-17 15:06:55.621 | DEBUG    | __main__:<module>:313 - Training step 9710: loss = 3.5475 | 3021.75ms | Tokens/s = 173,504.9
2025-01-17 15:07:25.823 | DEBUG    | __main__:<module>:313 - Training step 9720: loss = 3.2267 | 3018.87ms | Tokens/s = 173,670.5
2025-01-17 15:07:56.010 | DEBUG    | __main__:<module>:313 - Training step 9730: loss = 3.3448 | 3019.26ms | Tokens/s = 173,647.7
2025-01-17 15:08:26.218 | DEBUG    | __main__:<module>:313 - Training step 9740: loss = 3.3050 | 3021.06ms | Tokens/s = 173,544.4
2025-01-17 15:08:56.443 | DEBUG    | __main__:<module>:313 - Training step 9750: loss = 3.4562 | 3023.17ms | Tokens/s = 173,423.4
2025-01-17 15:09:26.682 | DEBUG    | __main__:<module>:313 - Training step 9760: loss = 3.2151 | 3023.30ms | Tokens/s = 173,416.1
2025-01-17 15:09:56.902 | DEBUG    | __main__:<module>:313 - Training step 9770: loss = 3.4560 | 3021.93ms | Tokens/s = 173,494.5
2025-01-17 15:10:27.097 | DEBUG    | __main__:<module>:313 - Training step 9780: loss = 3.3419 | 3019.44ms | Tokens/s = 173,637.3
2025-01-17 15:10:57.307 | DEBUG    | __main__:<module>:313 - Training step 9790: loss = 3.3561 | 3020.87ms | Tokens/s = 173,555.3
2025-01-17 15:11:27.545 | DEBUG    | __main__:<module>:313 - Training step 9800: loss = 3.2428 | 3022.96ms | Tokens/s = 173,435.3
2025-01-17 15:11:57.794 | DEBUG    | __main__:<module>:313 - Training step 9810: loss = 3.5088 | 3023.49ms | Tokens/s = 173,404.9
2025-01-17 15:12:28.010 | DEBUG    | __main__:<module>:313 - Training step 9820: loss = 3.3217 | 3019.44ms | Tokens/s = 173,637.6
2025-01-17 15:12:58.221 | DEBUG    | __main__:<module>:313 - Training step 9830: loss = 3.3308 | 3023.37ms | Tokens/s = 173,411.6
2025-01-17 15:13:28.450 | DEBUG    | __main__:<module>:313 - Training step 9840: loss = 3.3431 | 3022.43ms | Tokens/s = 173,465.6
2025-01-17 15:13:58.662 | DEBUG    | __main__:<module>:313 - Training step 9850: loss = 3.3460 | 3018.62ms | Tokens/s = 173,684.5
2025-01-17 15:14:28.860 | DEBUG    | __main__:<module>:313 - Training step 9860: loss = 3.3572 | 3019.96ms | Tokens/s = 173,607.4
2025-01-17 15:14:59.082 | DEBUG    | __main__:<module>:313 - Training step 9870: loss = 3.3289 | 3022.27ms | Tokens/s = 173,475.2
2025-01-17 15:15:29.310 | DEBUG    | __main__:<module>:313 - Training step 9880: loss = 3.3879 | 3020.41ms | Tokens/s = 173,581.8
2025-01-17 15:15:59.551 | DEBUG    | __main__:<module>:313 - Training step 9890: loss = 3.2860 | 3022.46ms | Tokens/s = 173,463.8
2025-01-17 15:16:29.787 | DEBUG    | __main__:<module>:313 - Training step 9900: loss = 3.1228 | 3020.75ms | Tokens/s = 173,562.4
2025-01-17 15:17:00.006 | DEBUG    | __main__:<module>:313 - Training step 9910: loss = 3.4568 | 3022.67ms | Tokens/s = 173,452.2
2025-01-17 15:17:30.251 | DEBUG    | __main__:<module>:313 - Training step 9920: loss = 3.3840 | 3024.62ms | Tokens/s = 173,340.1
2025-01-17 15:18:00.489 | DEBUG    | __main__:<module>:313 - Training step 9930: loss = 3.2105 | 3022.08ms | Tokens/s = 173,485.7
2025-01-17 15:18:30.693 | DEBUG    | __main__:<module>:313 - Training step 9940: loss = 3.2687 | 3019.85ms | Tokens/s = 173,614.0
2025-01-17 15:19:00.881 | DEBUG    | __main__:<module>:313 - Training step 9950: loss = 3.3624 | 3016.65ms | Tokens/s = 173,798.3
2025-01-17 15:19:31.071 | DEBUG    | __main__:<module>:313 - Training step 9960: loss = 3.2156 | 3020.81ms | Tokens/s = 173,559.0
2025-01-17 15:20:01.287 | DEBUG    | __main__:<module>:313 - Training step 9970: loss = 3.5315 | 3021.38ms | Tokens/s = 173,526.0
2025-01-17 15:20:31.519 | DEBUG    | __main__:<module>:313 - Training step 9980: loss = 3.2437 | 3023.24ms | Tokens/s = 173,419.4
2025-01-17 15:21:01.756 | DEBUG    | __main__:<module>:313 - Training step 9990: loss = 3.3004 | 3021.48ms | Tokens/s = 173,520.4
2025-01-17 15:21:35.389 | INFO     | __main__:<module>:265 - Step 10,000/20,000 loss: 3.3092 (T) 3.3195 (V) | lr=5.9e-03
2025-01-17 15:21:35.390 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 15:21:48.838 | DEBUG    | __main__:<module>:313 - Training step 10000: loss = 3.4220 | 19898.17ms | Tokens/s = 26,348.6
2025-01-17 15:22:18.920 | DEBUG    | __main__:<module>:313 - Training step 10010: loss = 3.2551 | 3013.43ms | Tokens/s = 173,983.8
2025-01-17 15:22:49.097 | DEBUG    | __main__:<module>:313 - Training step 10020: loss = 3.3949 | 3019.98ms | Tokens/s = 173,606.3
2025-01-17 15:23:19.313 | DEBUG    | __main__:<module>:313 - Training step 10030: loss = 3.3964 | 3022.58ms | Tokens/s = 173,456.9
2025-01-17 15:23:49.545 | DEBUG    | __main__:<module>:313 - Training step 10040: loss = 3.1629 | 3023.31ms | Tokens/s = 173,415.1
2025-01-17 15:24:19.785 | DEBUG    | __main__:<module>:313 - Training step 10050: loss = 3.4950 | 3024.34ms | Tokens/s = 173,356.2
2025-01-17 15:24:50.038 | DEBUG    | __main__:<module>:313 - Training step 10060: loss = 3.3163 | 3024.30ms | Tokens/s = 173,358.2
2025-01-17 15:25:20.275 | DEBUG    | __main__:<module>:313 - Training step 10070: loss = 3.3472 | 3023.38ms | Tokens/s = 173,411.2
2025-01-17 15:25:50.490 | DEBUG    | __main__:<module>:313 - Training step 10080: loss = 3.2535 | 3021.46ms | Tokens/s = 173,521.5
2025-01-17 15:26:20.705 | DEBUG    | __main__:<module>:313 - Training step 10090: loss = 3.3464 | 3023.17ms | Tokens/s = 173,423.1
2025-01-17 15:26:50.942 | DEBUG    | __main__:<module>:313 - Training step 10100: loss = 3.1736 | 3023.83ms | Tokens/s = 173,385.2
2025-01-17 15:27:21.181 | DEBUG    | __main__:<module>:313 - Training step 10110: loss = 3.1682 | 3022.09ms | Tokens/s = 173,485.4
2025-01-17 15:27:51.381 | DEBUG    | __main__:<module>:313 - Training step 10120: loss = 3.3250 | 3020.51ms | Tokens/s = 173,575.9
2025-01-17 15:28:21.565 | DEBUG    | __main__:<module>:313 - Training step 10130: loss = 3.2294 | 3019.94ms | Tokens/s = 173,609.0
2025-01-17 15:28:51.757 | DEBUG    | __main__:<module>:313 - Training step 10140: loss = 3.1731 | 3020.21ms | Tokens/s = 173,593.2
2025-01-17 15:29:21.980 | DEBUG    | __main__:<module>:313 - Training step 10150: loss = 3.3802 | 3022.59ms | Tokens/s = 173,456.5
2025-01-17 15:29:52.221 | DEBUG    | __main__:<module>:313 - Training step 10160: loss = 3.2845 | 3024.63ms | Tokens/s = 173,339.7
2025-01-17 15:30:22.477 | DEBUG    | __main__:<module>:313 - Training step 10170: loss = 3.3426 | 3025.26ms | Tokens/s = 173,303.5
2025-01-17 15:30:52.720 | DEBUG    | __main__:<module>:313 - Training step 10180: loss = 3.1107 | 3022.87ms | Tokens/s = 173,440.6
2025-01-17 15:31:22.937 | DEBUG    | __main__:<module>:313 - Training step 10190: loss = 3.3089 | 3022.08ms | Tokens/s = 173,486.0
2025-01-17 15:31:53.137 | DEBUG    | __main__:<module>:313 - Training step 10200: loss = 3.4021 | 3019.08ms | Tokens/s = 173,658.0
2025-01-17 15:32:23.355 | DEBUG    | __main__:<module>:313 - Training step 10210: loss = 3.2178 | 3022.67ms | Tokens/s = 173,452.1
2025-01-17 15:32:53.594 | DEBUG    | __main__:<module>:313 - Training step 10220: loss = 3.3455 | 3025.84ms | Tokens/s = 173,270.3
2025-01-17 15:33:23.845 | DEBUG    | __main__:<module>:313 - Training step 10230: loss = 3.5034 | 3022.45ms | Tokens/s = 173,464.7
2025-01-17 15:33:54.057 | DEBUG    | __main__:<module>:313 - Training step 10240: loss = 3.1862 | 3019.51ms | Tokens/s = 173,633.7
2025-01-17 15:34:24.267 | DEBUG    | __main__:<module>:313 - Training step 10250: loss = 3.3391 | 3023.63ms | Tokens/s = 173,397.1
2025-01-17 15:34:54.487 | DEBUG    | __main__:<module>:313 - Training step 10260: loss = 3.2155 | 3022.05ms | Tokens/s = 173,487.8
2025-01-17 15:35:24.683 | DEBUG    | __main__:<module>:313 - Training step 10270: loss = 3.4350 | 3017.99ms | Tokens/s = 173,721.1
2025-01-17 15:35:54.885 | DEBUG    | __main__:<module>:313 - Training step 10280: loss = 3.4764 | 3020.17ms | Tokens/s = 173,595.6
2025-01-17 15:36:25.112 | DEBUG    | __main__:<module>:313 - Training step 10290: loss = 3.4013 | 3023.70ms | Tokens/s = 173,392.8
2025-01-17 15:36:55.358 | DEBUG    | __main__:<module>:313 - Training step 10300: loss = 3.3914 | 3022.57ms | Tokens/s = 173,457.5
2025-01-17 15:37:25.587 | DEBUG    | __main__:<module>:313 - Training step 10310: loss = 3.3131 | 3020.74ms | Tokens/s = 173,563.0
2025-01-17 15:37:55.789 | DEBUG    | __main__:<module>:313 - Training step 10320: loss = 3.3300 | 3020.66ms | Tokens/s = 173,567.2
2025-01-17 15:38:26.007 | DEBUG    | __main__:<module>:313 - Training step 10330: loss = 3.2625 | 3020.96ms | Tokens/s = 173,550.4
2025-01-17 15:38:56.235 | DEBUG    | __main__:<module>:313 - Training step 10340: loss = 3.0837 | 3023.26ms | Tokens/s = 173,418.3
2025-01-17 15:39:26.479 | DEBUG    | __main__:<module>:313 - Training step 10350: loss = 3.2257 | 3023.27ms | Tokens/s = 173,417.5
2025-01-17 15:39:56.712 | DEBUG    | __main__:<module>:313 - Training step 10360: loss = 3.4678 | 3022.30ms | Tokens/s = 173,473.2
2025-01-17 15:40:26.918 | DEBUG    | __main__:<module>:313 - Training step 10370: loss = 3.4153 | 3021.64ms | Tokens/s = 173,511.1
2025-01-17 15:40:57.146 | DEBUG    | __main__:<module>:313 - Training step 10380: loss = 3.2187 | 3024.73ms | Tokens/s = 173,333.7
2025-01-17 15:41:27.393 | DEBUG    | __main__:<module>:313 - Training step 10390: loss = 3.2406 | 3025.52ms | Tokens/s = 173,288.3
2025-01-17 15:41:57.635 | DEBUG    | __main__:<module>:313 - Training step 10400: loss = 3.3061 | 3022.40ms | Tokens/s = 173,467.3
2025-01-17 15:42:27.830 | DEBUG    | __main__:<module>:313 - Training step 10410: loss = 3.2328 | 3019.45ms | Tokens/s = 173,637.0
2025-01-17 15:42:58.016 | DEBUG    | __main__:<module>:313 - Training step 10420: loss = 3.3858 | 3020.12ms | Tokens/s = 173,598.4
2025-01-17 15:43:28.218 | DEBUG    | __main__:<module>:313 - Training step 10430: loss = 3.4063 | 3020.86ms | Tokens/s = 173,556.2
2025-01-17 15:43:58.453 | DEBUG    | __main__:<module>:313 - Training step 10440: loss = 3.4114 | 3020.78ms | Tokens/s = 173,560.7
2025-01-17 15:44:28.660 | DEBUG    | __main__:<module>:313 - Training step 10450: loss = 3.2559 | 3020.65ms | Tokens/s = 173,568.0
2025-01-17 15:44:58.871 | DEBUG    | __main__:<module>:313 - Training step 10460: loss = 3.0256 | 3022.90ms | Tokens/s = 173,438.6
2025-01-17 15:45:29.082 | DEBUG    | __main__:<module>:313 - Training step 10470: loss = 3.4833 | 3022.65ms | Tokens/s = 173,453.1
2025-01-17 15:45:59.321 | DEBUG    | __main__:<module>:313 - Training step 10480: loss = 3.2667 | 3024.39ms | Tokens/s = 173,353.5
2025-01-17 15:46:29.563 | DEBUG    | __main__:<module>:313 - Training step 10490: loss = 3.3268 | 3024.06ms | Tokens/s = 173,372.3
2025-01-17 15:46:59.776 | DEBUG    | __main__:<module>:313 - Training step 10500: loss = 3.4690 | 3020.42ms | Tokens/s = 173,581.2
2025-01-17 15:47:29.977 | DEBUG    | __main__:<module>:313 - Training step 10510: loss = 3.2737 | 3023.87ms | Tokens/s = 173,382.9
2025-01-17 15:48:00.217 | DEBUG    | __main__:<module>:313 - Training step 10520: loss = 3.3169 | 3025.48ms | Tokens/s = 173,290.9
2025-01-17 15:48:30.468 | DEBUG    | __main__:<module>:313 - Training step 10530: loss = 3.2060 | 3026.29ms | Tokens/s = 173,244.3
2025-01-17 15:49:00.694 | DEBUG    | __main__:<module>:313 - Training step 10540: loss = 3.4554 | 3020.41ms | Tokens/s = 173,581.7
2025-01-17 15:49:30.931 | DEBUG    | __main__:<module>:313 - Training step 10550: loss = 3.2830 | 3023.43ms | Tokens/s = 173,408.4
2025-01-17 15:50:01.183 | DEBUG    | __main__:<module>:313 - Training step 10560: loss = 3.4238 | 3025.46ms | Tokens/s = 173,291.9
2025-01-17 15:50:31.405 | DEBUG    | __main__:<module>:313 - Training step 10570: loss = 3.1099 | 3021.67ms | Tokens/s = 173,509.1
2025-01-17 15:51:01.638 | DEBUG    | __main__:<module>:313 - Training step 10580: loss = 3.1956 | 3024.30ms | Tokens/s = 173,358.7
2025-01-17 15:51:31.876 | DEBUG    | __main__:<module>:313 - Training step 10590: loss = 3.2266 | 3023.19ms | Tokens/s = 173,421.9
2025-01-17 15:52:02.084 | DEBUG    | __main__:<module>:313 - Training step 10600: loss = 3.4561 | 3018.33ms | Tokens/s = 173,701.3
2025-01-17 15:52:32.267 | DEBUG    | __main__:<module>:313 - Training step 10610: loss = 3.3565 | 3018.35ms | Tokens/s = 173,700.0
2025-01-17 15:53:02.457 | DEBUG    | __main__:<module>:313 - Training step 10620: loss = 3.2058 | 3018.66ms | Tokens/s = 173,682.1
2025-01-17 15:53:32.661 | DEBUG    | __main__:<module>:313 - Training step 10630: loss = 3.4299 | 3021.62ms | Tokens/s = 173,512.1
2025-01-17 15:54:02.886 | DEBUG    | __main__:<module>:313 - Training step 10640: loss = 3.1648 | 3021.97ms | Tokens/s = 173,492.1
2025-01-17 15:54:33.100 | DEBUG    | __main__:<module>:313 - Training step 10650: loss = 3.3015 | 3022.09ms | Tokens/s = 173,485.0
2025-01-17 15:55:03.321 | DEBUG    | __main__:<module>:313 - Training step 10660: loss = 3.4022 | 3022.19ms | Tokens/s = 173,479.8
2025-01-17 15:55:33.546 | DEBUG    | __main__:<module>:313 - Training step 10670: loss = 3.4599 | 3023.38ms | Tokens/s = 173,411.4
2025-01-17 15:56:03.773 | DEBUG    | __main__:<module>:313 - Training step 10680: loss = 3.2958 | 3024.37ms | Tokens/s = 173,354.4
2025-01-17 15:56:34.005 | DEBUG    | __main__:<module>:313 - Training step 10690: loss = 3.3377 | 3023.39ms | Tokens/s = 173,410.9
2025-01-17 15:57:04.236 | DEBUG    | __main__:<module>:313 - Training step 10700: loss = 3.2716 | 3021.42ms | Tokens/s = 173,523.7
2025-01-17 15:57:34.462 | DEBUG    | __main__:<module>:313 - Training step 10710: loss = 3.2899 | 3020.39ms | Tokens/s = 173,582.8
2025-01-17 15:58:04.660 | DEBUG    | __main__:<module>:313 - Training step 10720: loss = 3.1746 | 3019.04ms | Tokens/s = 173,660.4
2025-01-17 15:58:34.869 | DEBUG    | __main__:<module>:313 - Training step 10730: loss = 3.2246 | 3021.93ms | Tokens/s = 173,494.4
2025-01-17 15:59:05.083 | DEBUG    | __main__:<module>:313 - Training step 10740: loss = 3.2498 | 3023.31ms | Tokens/s = 173,415.1
2025-01-17 15:59:35.313 | DEBUG    | __main__:<module>:313 - Training step 10750: loss = 3.1844 | 3022.73ms | Tokens/s = 173,448.3
2025-01-17 16:00:05.545 | DEBUG    | __main__:<module>:313 - Training step 10760: loss = 3.2565 | 3023.20ms | Tokens/s = 173,421.7
2025-01-17 16:00:35.781 | DEBUG    | __main__:<module>:313 - Training step 10770: loss = 3.1716 | 3022.80ms | Tokens/s = 173,444.4
2025-01-17 16:01:06.014 | DEBUG    | __main__:<module>:313 - Training step 10780: loss = 3.1267 | 3022.32ms | Tokens/s = 173,472.2
2025-01-17 16:01:36.255 | DEBUG    | __main__:<module>:313 - Training step 10790: loss = 3.1892 | 3023.71ms | Tokens/s = 173,392.4
2025-01-17 16:02:06.479 | DEBUG    | __main__:<module>:313 - Training step 10800: loss = 3.2743 | 3019.30ms | Tokens/s = 173,645.4
2025-01-17 16:02:36.685 | DEBUG    | __main__:<module>:313 - Training step 10810: loss = 3.2136 | 3021.30ms | Tokens/s = 173,530.5
2025-01-17 16:03:06.904 | DEBUG    | __main__:<module>:313 - Training step 10820: loss = 3.2697 | 3022.29ms | Tokens/s = 173,473.8
2025-01-17 16:03:37.116 | DEBUG    | __main__:<module>:313 - Training step 10830: loss = 3.3282 | 3020.75ms | Tokens/s = 173,562.1
2025-01-17 16:04:07.303 | DEBUG    | __main__:<module>:313 - Training step 10840: loss = 3.2056 | 3017.44ms | Tokens/s = 173,752.4
2025-01-17 16:04:37.495 | DEBUG    | __main__:<module>:313 - Training step 10850: loss = 3.2949 | 3019.38ms | Tokens/s = 173,640.9
2025-01-17 16:05:07.706 | DEBUG    | __main__:<module>:313 - Training step 10860: loss = 3.1973 | 3021.18ms | Tokens/s = 173,537.6
2025-01-17 16:05:37.918 | DEBUG    | __main__:<module>:313 - Training step 10870: loss = 3.2054 | 3022.39ms | Tokens/s = 173,468.3
2025-01-17 16:06:08.145 | DEBUG    | __main__:<module>:313 - Training step 10880: loss = 3.2864 | 3022.51ms | Tokens/s = 173,460.9
2025-01-17 16:06:38.373 | DEBUG    | __main__:<module>:313 - Training step 10890: loss = 3.2751 | 3024.45ms | Tokens/s = 173,350.1
2025-01-17 16:07:08.614 | DEBUG    | __main__:<module>:313 - Training step 10900: loss = 3.0911 | 3021.71ms | Tokens/s = 173,507.0
2025-01-17 16:07:38.853 | DEBUG    | __main__:<module>:313 - Training step 10910: loss = 3.2704 | 3024.17ms | Tokens/s = 173,365.9
2025-01-17 16:08:09.055 | DEBUG    | __main__:<module>:313 - Training step 10920: loss = 3.1864 | 3019.85ms | Tokens/s = 173,613.7
2025-01-17 16:08:39.240 | DEBUG    | __main__:<module>:313 - Training step 10930: loss = 3.1847 | 3019.74ms | Tokens/s = 173,620.2
2025-01-17 16:09:09.442 | DEBUG    | __main__:<module>:313 - Training step 10940: loss = 3.3311 | 3020.06ms | Tokens/s = 173,602.0
2025-01-17 16:09:39.656 | DEBUG    | __main__:<module>:313 - Training step 10950: loss = 3.2168 | 3021.39ms | Tokens/s = 173,525.3
2025-01-17 16:10:09.871 | DEBUG    | __main__:<module>:313 - Training step 10960: loss = 3.3071 | 3022.17ms | Tokens/s = 173,480.9
2025-01-17 16:10:40.093 | DEBUG    | __main__:<module>:313 - Training step 10970: loss = 3.2823 | 3020.79ms | Tokens/s = 173,559.9
2025-01-17 16:11:10.315 | DEBUG    | __main__:<module>:313 - Training step 10980: loss = 3.2244 | 3023.37ms | Tokens/s = 173,411.7
2025-01-17 16:11:40.535 | DEBUG    | __main__:<module>:313 - Training step 10990: loss = 3.2148 | 3020.75ms | Tokens/s = 173,561.9
2025-01-17 16:12:14.197 | INFO     | __main__:<module>:265 - Step 11,000/20,000 loss: 3.2760 (T) 3.2600 (V) | lr=5.0e-03
2025-01-17 16:12:14.198 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 16:12:27.713 | DEBUG    | __main__:<module>:313 - Training step 11000: loss = 3.1962 | 19979.55ms | Tokens/s = 26,241.2
2025-01-17 16:12:57.791 | DEBUG    | __main__:<module>:313 - Training step 11010: loss = 3.2481 | 3013.34ms | Tokens/s = 173,988.9
2025-01-17 16:13:27.942 | DEBUG    | __main__:<module>:313 - Training step 11020: loss = 3.2914 | 3017.39ms | Tokens/s = 173,755.6
2025-01-17 16:13:58.132 | DEBUG    | __main__:<module>:313 - Training step 11030: loss = 3.3522 | 3021.25ms | Tokens/s = 173,533.3
2025-01-17 16:14:28.325 | DEBUG    | __main__:<module>:313 - Training step 11040: loss = 3.2947 | 3018.88ms | Tokens/s = 173,669.8
2025-01-17 16:14:58.528 | DEBUG    | __main__:<module>:313 - Training step 11050: loss = 3.4125 | 3021.92ms | Tokens/s = 173,495.0
2025-01-17 16:15:28.734 | DEBUG    | __main__:<module>:313 - Training step 11060: loss = 3.2743 | 3021.90ms | Tokens/s = 173,495.9
2025-01-17 16:15:58.948 | DEBUG    | __main__:<module>:313 - Training step 11070: loss = 3.2508 | 3021.42ms | Tokens/s = 173,524.0
2025-01-17 16:16:29.167 | DEBUG    | __main__:<module>:313 - Training step 11080: loss = 3.1833 | 3020.55ms | Tokens/s = 173,573.7
2025-01-17 16:16:59.392 | DEBUG    | __main__:<module>:313 - Training step 11090: loss = 3.4298 | 3023.15ms | Tokens/s = 173,424.3
2025-01-17 16:17:29.628 | DEBUG    | __main__:<module>:313 - Training step 11100: loss = 3.1590 | 3022.94ms | Tokens/s = 173,436.3
2025-01-17 16:17:59.862 | DEBUG    | __main__:<module>:313 - Training step 11110: loss = 3.2317 | 3023.61ms | Tokens/s = 173,398.3
2025-01-17 16:18:30.094 | DEBUG    | __main__:<module>:313 - Training step 11120: loss = 3.3534 | 3022.75ms | Tokens/s = 173,447.2
2025-01-17 16:19:00.315 | DEBUG    | __main__:<module>:313 - Training step 11130: loss = 3.2959 | 3022.34ms | Tokens/s = 173,470.6
2025-01-17 16:19:30.534 | DEBUG    | __main__:<module>:313 - Training step 11140: loss = 3.1502 | 3023.44ms | Tokens/s = 173,407.6
2025-01-17 16:20:00.760 | DEBUG    | __main__:<module>:313 - Training step 11150: loss = 3.3644 | 3021.69ms | Tokens/s = 173,508.3
2025-01-17 16:20:30.991 | DEBUG    | __main__:<module>:313 - Training step 11160: loss = 3.3857 | 3021.86ms | Tokens/s = 173,498.5
2025-01-17 16:21:01.224 | DEBUG    | __main__:<module>:313 - Training step 11170: loss = 3.2233 | 3022.91ms | Tokens/s = 173,438.0
2025-01-17 16:21:31.436 | DEBUG    | __main__:<module>:313 - Training step 11180: loss = 3.1704 | 3018.96ms | Tokens/s = 173,665.1
2025-01-17 16:22:01.632 | DEBUG    | __main__:<module>:313 - Training step 11190: loss = 3.4319 | 3019.09ms | Tokens/s = 173,657.7
2025-01-17 16:22:31.845 | DEBUG    | __main__:<module>:313 - Training step 11200: loss = 3.2797 | 3022.79ms | Tokens/s = 173,445.1
2025-01-17 16:23:02.077 | DEBUG    | __main__:<module>:313 - Training step 11210: loss = 3.2558 | 3023.00ms | Tokens/s = 173,432.8
2025-01-17 16:23:32.323 | DEBUG    | __main__:<module>:313 - Training step 11220: loss = 3.1326 | 3026.11ms | Tokens/s = 173,254.8
2025-01-17 16:24:02.558 | DEBUG    | __main__:<module>:313 - Training step 11230: loss = 3.2801 | 3021.61ms | Tokens/s = 173,512.8
2025-01-17 16:24:32.770 | DEBUG    | __main__:<module>:313 - Training step 11240: loss = 3.1692 | 3018.46ms | Tokens/s = 173,693.7
2025-01-17 16:25:02.963 | DEBUG    | __main__:<module>:313 - Training step 11250: loss = 3.2394 | 3018.49ms | Tokens/s = 173,691.9
2025-01-17 16:25:33.141 | DEBUG    | __main__:<module>:313 - Training step 11260: loss = 3.1419 | 3017.23ms | Tokens/s = 173,764.5
2025-01-17 16:26:03.335 | DEBUG    | __main__:<module>:313 - Training step 11270: loss = 3.3048 | 3021.52ms | Tokens/s = 173,518.1
2025-01-17 16:26:33.563 | DEBUG    | __main__:<module>:313 - Training step 11280: loss = 3.3669 | 3024.30ms | Tokens/s = 173,358.7
2025-01-17 16:27:03.816 | DEBUG    | __main__:<module>:313 - Training step 11290: loss = 2.9816 | 3023.53ms | Tokens/s = 173,402.7
2025-01-17 16:27:34.045 | DEBUG    | __main__:<module>:313 - Training step 11300: loss = 3.2069 | 3023.28ms | Tokens/s = 173,417.2
2025-01-17 16:28:04.299 | DEBUG    | __main__:<module>:313 - Training step 11310: loss = 3.3422 | 3025.06ms | Tokens/s = 173,314.7
2025-01-17 16:28:34.542 | DEBUG    | __main__:<module>:313 - Training step 11320: loss = 2.9511 | 3022.53ms | Tokens/s = 173,460.0
2025-01-17 16:29:04.761 | DEBUG    | __main__:<module>:313 - Training step 11330: loss = 3.3397 | 3019.92ms | Tokens/s = 173,609.8
2025-01-17 16:29:34.982 | DEBUG    | __main__:<module>:313 - Training step 11340: loss = 3.1481 | 3023.06ms | Tokens/s = 173,429.5
2025-01-17 16:30:05.233 | DEBUG    | __main__:<module>:313 - Training step 11350: loss = 3.1246 | 3026.63ms | Tokens/s = 173,225.3
2025-01-17 16:30:35.508 | DEBUG    | __main__:<module>:313 - Training step 11360: loss = 3.2625 | 3026.46ms | Tokens/s = 173,234.6
2025-01-17 16:31:05.754 | DEBUG    | __main__:<module>:313 - Training step 11370: loss = 3.3024 | 3022.17ms | Tokens/s = 173,480.9
2025-01-17 16:31:35.974 | DEBUG    | __main__:<module>:313 - Training step 11380: loss = 3.2248 | 3020.12ms | Tokens/s = 173,598.5
2025-01-17 16:32:06.169 | DEBUG    | __main__:<module>:313 - Training step 11390: loss = 3.1219 | 3021.68ms | Tokens/s = 173,508.9
2025-01-17 16:32:36.387 | DEBUG    | __main__:<module>:313 - Training step 11400: loss = 3.2134 | 3019.76ms | Tokens/s = 173,619.0
2025-01-17 16:33:06.587 | DEBUG    | __main__:<module>:313 - Training step 11410: loss = 3.2863 | 3019.81ms | Tokens/s = 173,616.0
2025-01-17 16:33:36.783 | DEBUG    | __main__:<module>:313 - Training step 11420: loss = 3.2130 | 3018.36ms | Tokens/s = 173,699.8
2025-01-17 16:34:06.965 | DEBUG    | __main__:<module>:313 - Training step 11430: loss = 3.3880 | 3019.81ms | Tokens/s = 173,616.2
2025-01-17 16:34:37.180 | DEBUG    | __main__:<module>:313 - Training step 11440: loss = 3.1723 | 3023.84ms | Tokens/s = 173,384.9
2025-01-17 16:35:07.416 | DEBUG    | __main__:<module>:313 - Training step 11450: loss = 3.2022 | 3023.99ms | Tokens/s = 173,376.3
2025-01-17 16:35:37.668 | DEBUG    | __main__:<module>:313 - Training step 11460: loss = 3.1864 | 3023.88ms | Tokens/s = 173,382.7
2025-01-17 16:36:07.899 | DEBUG    | __main__:<module>:313 - Training step 11470: loss = 3.1205 | 3022.13ms | Tokens/s = 173,482.9
2025-01-17 16:36:38.112 | DEBUG    | __main__:<module>:313 - Training step 11480: loss = 3.4467 | 3021.01ms | Tokens/s = 173,547.4
2025-01-17 16:37:08.318 | DEBUG    | __main__:<module>:313 - Training step 11490: loss = 3.4279 | 3021.22ms | Tokens/s = 173,535.0
2025-01-17 16:37:38.511 | DEBUG    | __main__:<module>:313 - Training step 11500: loss = 3.2702 | 3017.09ms | Tokens/s = 173,773.0
2025-01-17 16:38:08.708 | DEBUG    | __main__:<module>:313 - Training step 11510: loss = 3.3074 | 3020.93ms | Tokens/s = 173,552.0
2025-01-17 16:38:38.939 | DEBUG    | __main__:<module>:313 - Training step 11520: loss = 3.1330 | 3024.18ms | Tokens/s = 173,365.5
2025-01-17 16:39:09.188 | DEBUG    | __main__:<module>:313 - Training step 11530: loss = 3.1505 | 3024.70ms | Tokens/s = 173,335.5
2025-01-17 16:39:39.414 | DEBUG    | __main__:<module>:313 - Training step 11540: loss = 3.1513 | 3023.13ms | Tokens/s = 173,425.4
2025-01-17 16:40:09.629 | DEBUG    | __main__:<module>:313 - Training step 11550: loss = 3.3222 | 3021.11ms | Tokens/s = 173,541.7
2025-01-17 16:40:39.856 | DEBUG    | __main__:<module>:313 - Training step 11560: loss = 3.3129 | 3022.90ms | Tokens/s = 173,438.8
2025-01-17 16:41:10.073 | DEBUG    | __main__:<module>:313 - Training step 11570: loss = 3.2367 | 3020.35ms | Tokens/s = 173,585.0
2025-01-17 16:41:40.298 | DEBUG    | __main__:<module>:313 - Training step 11580: loss = 3.2306 | 3022.89ms | Tokens/s = 173,439.4
2025-01-17 16:42:10.544 | DEBUG    | __main__:<module>:313 - Training step 11590: loss = 3.2362 | 3022.37ms | Tokens/s = 173,469.3
2025-01-17 16:42:40.759 | DEBUG    | __main__:<module>:313 - Training step 11600: loss = 3.1946 | 3019.51ms | Tokens/s = 173,633.7
2025-01-17 16:43:10.989 | DEBUG    | __main__:<module>:313 - Training step 11610: loss = 3.3745 | 3025.38ms | Tokens/s = 173,296.5
2025-01-17 16:43:41.253 | DEBUG    | __main__:<module>:313 - Training step 11620: loss = 3.2529 | 3028.44ms | Tokens/s = 173,121.7
2025-01-17 16:44:11.515 | DEBUG    | __main__:<module>:313 - Training step 11630: loss = 3.2536 | 3027.67ms | Tokens/s = 173,165.8
2025-01-17 16:44:41.786 | DEBUG    | __main__:<module>:313 - Training step 11640: loss = 3.2759 | 3026.85ms | Tokens/s = 173,212.6
2025-01-17 16:45:12.027 | DEBUG    | __main__:<module>:313 - Training step 11650: loss = 3.2769 | 3022.54ms | Tokens/s = 173,459.6
2025-01-17 16:45:42.253 | DEBUG    | __main__:<module>:313 - Training step 11660: loss = 3.2083 | 3024.57ms | Tokens/s = 173,342.7
2025-01-17 16:46:12.467 | DEBUG    | __main__:<module>:313 - Training step 11670: loss = 3.2592 | 3022.85ms | Tokens/s = 173,441.7
2025-01-17 16:46:42.707 | DEBUG    | __main__:<module>:313 - Training step 11680: loss = 3.2623 | 3024.76ms | Tokens/s = 173,332.1
2025-01-17 16:47:12.969 | DEBUG    | __main__:<module>:313 - Training step 11690: loss = 3.3227 | 3025.89ms | Tokens/s = 173,267.4
2025-01-17 16:47:43.208 | DEBUG    | __main__:<module>:313 - Training step 11700: loss = 3.1092 | 3020.61ms | Tokens/s = 173,570.1
2025-01-17 16:48:13.429 | DEBUG    | __main__:<module>:313 - Training step 11710: loss = 3.2611 | 3022.18ms | Tokens/s = 173,480.2
2025-01-17 16:48:43.635 | DEBUG    | __main__:<module>:313 - Training step 11720: loss = 3.3476 | 3024.41ms | Tokens/s = 173,351.9
2025-01-17 16:49:13.855 | DEBUG    | __main__:<module>:313 - Training step 11730: loss = 3.3451 | 3022.05ms | Tokens/s = 173,487.3
2025-01-17 16:49:44.076 | DEBUG    | __main__:<module>:313 - Training step 11740: loss = 3.2200 | 3021.90ms | Tokens/s = 173,496.3
2025-01-17 16:50:14.281 | DEBUG    | __main__:<module>:313 - Training step 11750: loss = 3.3283 | 3018.62ms | Tokens/s = 173,684.6
2025-01-17 16:50:44.483 | DEBUG    | __main__:<module>:313 - Training step 11760: loss = 3.1910 | 3021.42ms | Tokens/s = 173,524.0
2025-01-17 16:51:14.708 | DEBUG    | __main__:<module>:313 - Training step 11770: loss = 3.2789 | 3024.55ms | Tokens/s = 173,344.3
2025-01-17 16:51:44.970 | DEBUG    | __main__:<module>:313 - Training step 11780: loss = 3.5145 | 3027.34ms | Tokens/s = 173,184.4
2025-01-17 16:52:15.227 | DEBUG    | __main__:<module>:313 - Training step 11790: loss = 3.2944 | 3023.51ms | Tokens/s = 173,403.5
2025-01-17 16:52:45.452 | DEBUG    | __main__:<module>:313 - Training step 11800: loss = 3.2701 | 3021.40ms | Tokens/s = 173,524.8
2025-01-17 16:53:15.660 | DEBUG    | __main__:<module>:313 - Training step 11810: loss = 3.1990 | 3020.21ms | Tokens/s = 173,593.1
2025-01-17 16:53:45.871 | DEBUG    | __main__:<module>:313 - Training step 11820: loss = 3.5296 | 3019.78ms | Tokens/s = 173,618.2
2025-01-17 16:54:16.119 | DEBUG    | __main__:<module>:313 - Training step 11830: loss = 3.1249 | 3025.79ms | Tokens/s = 173,273.0
2025-01-17 16:54:46.362 | DEBUG    | __main__:<module>:313 - Training step 11840: loss = 3.1711 | 3022.08ms | Tokens/s = 173,486.0
2025-01-17 16:55:16.579 | DEBUG    | __main__:<module>:313 - Training step 11850: loss = 3.2087 | 3020.23ms | Tokens/s = 173,591.9
2025-01-17 16:55:46.792 | DEBUG    | __main__:<module>:313 - Training step 11860: loss = 3.1399 | 3021.72ms | Tokens/s = 173,506.3
2025-01-17 16:56:17.030 | DEBUG    | __main__:<module>:313 - Training step 11870: loss = 3.2621 | 3025.84ms | Tokens/s = 173,270.3
2025-01-17 16:56:47.294 | DEBUG    | __main__:<module>:313 - Training step 11880: loss = 3.2547 | 3025.69ms | Tokens/s = 173,278.5
2025-01-17 16:57:17.534 | DEBUG    | __main__:<module>:313 - Training step 11890: loss = 3.1234 | 3024.23ms | Tokens/s = 173,362.7
2025-01-17 16:57:47.750 | DEBUG    | __main__:<module>:313 - Training step 11900: loss = 3.3533 | 3018.92ms | Tokens/s = 173,667.5
2025-01-17 16:58:17.975 | DEBUG    | __main__:<module>:313 - Training step 11910: loss = 3.2971 | 3027.10ms | Tokens/s = 173,198.3
2025-01-17 16:58:48.232 | DEBUG    | __main__:<module>:313 - Training step 11920: loss = 2.8898 | 3023.47ms | Tokens/s = 173,406.1
2025-01-17 16:59:18.468 | DEBUG    | __main__:<module>:313 - Training step 11930: loss = 3.2336 | 3024.20ms | Tokens/s = 173,364.3
2025-01-17 16:59:48.721 | DEBUG    | __main__:<module>:313 - Training step 11940: loss = 3.1733 | 3025.44ms | Tokens/s = 173,293.3
2025-01-17 17:00:18.957 | DEBUG    | __main__:<module>:313 - Training step 11950: loss = 3.2467 | 3024.21ms | Tokens/s = 173,363.8
2025-01-17 17:00:49.172 | DEBUG    | __main__:<module>:313 - Training step 11960: loss = 3.1885 | 3019.12ms | Tokens/s = 173,655.7
2025-01-17 17:01:19.376 | DEBUG    | __main__:<module>:313 - Training step 11970: loss = 3.2161 | 3021.54ms | Tokens/s = 173,517.1
2025-01-17 17:01:49.583 | DEBUG    | __main__:<module>:313 - Training step 11980: loss = 3.4524 | 3021.86ms | Tokens/s = 173,498.2
2025-01-17 17:02:19.831 | DEBUG    | __main__:<module>:313 - Training step 11990: loss = 3.1435 | 3026.27ms | Tokens/s = 173,245.8
2025-01-17 17:02:53.493 | INFO     | __main__:<module>:265 - Step 12,000/20,000 loss: 3.2381 (T) 3.2463 (V) | lr=4.1e-03
2025-01-17 17:02:53.494 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 17:03:06.970 | DEBUG    | __main__:<module>:313 - Training step 12000: loss = 3.2773 | 19928.14ms | Tokens/s = 26,308.9
2025-01-17 17:03:37.067 | DEBUG    | __main__:<module>:313 - Training step 12010: loss = 3.0898 | 3017.24ms | Tokens/s = 173,763.9
2025-01-17 17:04:07.263 | DEBUG    | __main__:<module>:313 - Training step 12020: loss = 3.1642 | 3022.98ms | Tokens/s = 173,434.4
2025-01-17 17:04:37.491 | DEBUG    | __main__:<module>:313 - Training step 12030: loss = 3.2421 | 3021.90ms | Tokens/s = 173,495.9
2025-01-17 17:05:07.705 | DEBUG    | __main__:<module>:313 - Training step 12040: loss = 3.2989 | 3018.52ms | Tokens/s = 173,690.4
2025-01-17 17:05:37.912 | DEBUG    | __main__:<module>:313 - Training step 12050: loss = 3.3274 | 3020.16ms | Tokens/s = 173,596.1
2025-01-17 17:06:08.119 | DEBUG    | __main__:<module>:313 - Training step 12060: loss = 3.1228 | 3022.46ms | Tokens/s = 173,464.0
2025-01-17 17:06:38.360 | DEBUG    | __main__:<module>:313 - Training step 12070: loss = 3.1480 | 3024.60ms | Tokens/s = 173,341.1
2025-01-17 17:07:08.622 | DEBUG    | __main__:<module>:313 - Training step 12080: loss = 3.2622 | 3025.90ms | Tokens/s = 173,266.7
2025-01-17 17:07:38.865 | DEBUG    | __main__:<module>:313 - Training step 12090: loss = 3.1611 | 3021.81ms | Tokens/s = 173,501.2
2025-01-17 17:08:09.084 | DEBUG    | __main__:<module>:313 - Training step 12100: loss = 3.1120 | 3022.07ms | Tokens/s = 173,486.2
2025-01-17 17:08:39.302 | DEBUG    | __main__:<module>:313 - Training step 12110: loss = 3.2092 | 3022.91ms | Tokens/s = 173,438.2
2025-01-17 17:09:09.555 | DEBUG    | __main__:<module>:313 - Training step 12120: loss = 3.2384 | 3025.12ms | Tokens/s = 173,311.3
2025-01-17 17:09:39.792 | DEBUG    | __main__:<module>:313 - Training step 12130: loss = 3.2679 | 3022.74ms | Tokens/s = 173,447.9
2025-01-17 17:10:10.005 | DEBUG    | __main__:<module>:313 - Training step 12140: loss = 3.2101 | 3023.06ms | Tokens/s = 173,429.4
2025-01-17 17:10:40.245 | DEBUG    | __main__:<module>:313 - Training step 12150: loss = 3.3792 | 3024.39ms | Tokens/s = 173,353.3
2025-01-17 17:11:10.509 | DEBUG    | __main__:<module>:313 - Training step 12160: loss = 3.4250 | 3028.23ms | Tokens/s = 173,133.7
2025-01-17 17:11:40.782 | DEBUG    | __main__:<module>:313 - Training step 12170: loss = 3.1296 | 3026.78ms | Tokens/s = 173,216.5
2025-01-17 17:12:11.025 | DEBUG    | __main__:<module>:313 - Training step 12180: loss = 3.4760 | 3021.61ms | Tokens/s = 173,512.6
2025-01-17 17:12:41.252 | DEBUG    | __main__:<module>:313 - Training step 12190: loss = 3.3010 | 3021.36ms | Tokens/s = 173,526.9
2025-01-17 17:13:11.475 | DEBUG    | __main__:<module>:313 - Training step 12200: loss = 3.2287 | 3022.57ms | Tokens/s = 173,457.6
2025-01-17 17:13:41.736 | DEBUG    | __main__:<module>:313 - Training step 12210: loss = 3.2286 | 3025.75ms | Tokens/s = 173,275.4
2025-01-17 17:14:11.966 | DEBUG    | __main__:<module>:313 - Training step 12220: loss = 3.3094 | 3022.89ms | Tokens/s = 173,439.3
2025-01-17 17:14:42.183 | DEBUG    | __main__:<module>:313 - Training step 12230: loss = 3.1423 | 3022.56ms | Tokens/s = 173,458.1
2025-01-17 17:15:12.386 | DEBUG    | __main__:<module>:313 - Training step 12240: loss = 3.0366 | 3020.27ms | Tokens/s = 173,589.8
2025-01-17 17:15:42.630 | DEBUG    | __main__:<module>:313 - Training step 12250: loss = 3.0998 | 3024.45ms | Tokens/s = 173,350.0
2025-01-17 17:16:12.881 | DEBUG    | __main__:<module>:313 - Training step 12260: loss = 3.2589 | 3022.93ms | Tokens/s = 173,437.0
2025-01-17 17:16:43.108 | DEBUG    | __main__:<module>:313 - Training step 12270: loss = 3.0935 | 3022.05ms | Tokens/s = 173,487.3
2025-01-17 17:17:13.324 | DEBUG    | __main__:<module>:313 - Training step 12280: loss = 3.2791 | 3020.95ms | Tokens/s = 173,551.0
2025-01-17 17:17:43.528 | DEBUG    | __main__:<module>:313 - Training step 12290: loss = 3.2032 | 3020.98ms | Tokens/s = 173,548.9
2025-01-17 17:18:13.761 | DEBUG    | __main__:<module>:313 - Training step 12300: loss = 3.2539 | 3023.89ms | Tokens/s = 173,382.2
2025-01-17 17:18:44.010 | DEBUG    | __main__:<module>:313 - Training step 12310: loss = 3.2442 | 3024.17ms | Tokens/s = 173,365.7
2025-01-17 17:19:14.241 | DEBUG    | __main__:<module>:313 - Training step 12320: loss = 3.3514 | 3023.35ms | Tokens/s = 173,413.0
2025-01-17 17:19:44.447 | DEBUG    | __main__:<module>:313 - Training step 12330: loss = 3.2046 | 3018.27ms | Tokens/s = 173,705.1
2025-01-17 17:20:14.655 | DEBUG    | __main__:<module>:313 - Training step 12340: loss = 3.0662 | 3021.16ms | Tokens/s = 173,538.4
2025-01-17 17:20:44.896 | DEBUG    | __main__:<module>:313 - Training step 12350: loss = 3.3217 | 3022.95ms | Tokens/s = 173,435.9
2025-01-17 17:21:15.118 | DEBUG    | __main__:<module>:313 - Training step 12360: loss = 3.2098 | 3021.33ms | Tokens/s = 173,528.9
2025-01-17 17:21:45.332 | DEBUG    | __main__:<module>:313 - Training step 12370: loss = 3.1637 | 3023.90ms | Tokens/s = 173,381.2
2025-01-17 17:22:15.577 | DEBUG    | __main__:<module>:313 - Training step 12380: loss = 3.3615 | 3025.10ms | Tokens/s = 173,312.8
2025-01-17 17:22:45.825 | DEBUG    | __main__:<module>:313 - Training step 12390: loss = 3.3556 | 3020.70ms | Tokens/s = 173,564.8
2025-01-17 17:23:16.045 | DEBUG    | __main__:<module>:313 - Training step 12400: loss = 3.2686 | 3020.43ms | Tokens/s = 173,580.5
2025-01-17 17:23:46.266 | DEBUG    | __main__:<module>:313 - Training step 12410: loss = 3.1492 | 3023.31ms | Tokens/s = 173,415.1
2025-01-17 17:24:16.511 | DEBUG    | __main__:<module>:313 - Training step 12420: loss = 3.1321 | 3026.83ms | Tokens/s = 173,213.6
2025-01-17 17:24:46.748 | DEBUG    | __main__:<module>:313 - Training step 12430: loss = 3.2483 | 3020.50ms | Tokens/s = 173,576.7
2025-01-17 17:25:16.961 | DEBUG    | __main__:<module>:313 - Training step 12440: loss = 3.1895 | 3020.97ms | Tokens/s = 173,549.8
2025-01-17 17:25:47.169 | DEBUG    | __main__:<module>:313 - Training step 12450: loss = 3.1125 | 3018.68ms | Tokens/s = 173,681.2
2025-01-17 17:26:17.369 | DEBUG    | __main__:<module>:313 - Training step 12460: loss = 3.2171 | 3020.72ms | Tokens/s = 173,564.2
2025-01-17 17:26:47.571 | DEBUG    | __main__:<module>:313 - Training step 12470: loss = 2.9779 | 3023.97ms | Tokens/s = 173,377.3
2025-01-17 17:27:17.800 | DEBUG    | __main__:<module>:313 - Training step 12480: loss = 3.2680 | 3023.35ms | Tokens/s = 173,413.1
2025-01-17 17:27:48.041 | DEBUG    | __main__:<module>:313 - Training step 12490: loss = 3.3012 | 3023.63ms | Tokens/s = 173,396.9
2025-01-17 17:28:18.263 | DEBUG    | __main__:<module>:313 - Training step 12500: loss = 3.2146 | 3021.13ms | Tokens/s = 173,540.1
2025-01-17 17:28:48.472 | DEBUG    | __main__:<module>:313 - Training step 12510: loss = 3.1855 | 3021.79ms | Tokens/s = 173,502.5
2025-01-17 17:29:18.697 | DEBUG    | __main__:<module>:313 - Training step 12520: loss = 3.1681 | 3024.07ms | Tokens/s = 173,371.8
2025-01-17 17:29:48.955 | DEBUG    | __main__:<module>:313 - Training step 12530: loss = 3.2210 | 3025.62ms | Tokens/s = 173,283.0
2025-01-17 17:30:19.210 | DEBUG    | __main__:<module>:313 - Training step 12540: loss = 3.1981 | 3024.31ms | Tokens/s = 173,357.9
2025-01-17 17:30:49.445 | DEBUG    | __main__:<module>:313 - Training step 12550: loss = 3.3471 | 3023.73ms | Tokens/s = 173,391.0
2025-01-17 17:31:19.673 | DEBUG    | __main__:<module>:313 - Training step 12560: loss = 3.2379 | 3022.75ms | Tokens/s = 173,447.3
2025-01-17 17:31:49.889 | DEBUG    | __main__:<module>:313 - Training step 12570: loss = 3.2029 | 3021.60ms | Tokens/s = 173,513.5
2025-01-17 17:32:20.128 | DEBUG    | __main__:<module>:313 - Training step 12580: loss = 3.2486 | 3025.53ms | Tokens/s = 173,288.0
2025-01-17 17:32:50.392 | DEBUG    | __main__:<module>:313 - Training step 12590: loss = 3.2124 | 3024.97ms | Tokens/s = 173,320.0
2025-01-17 17:33:20.631 | DEBUG    | __main__:<module>:313 - Training step 12600: loss = 3.1618 | 3020.00ms | Tokens/s = 173,605.1
2025-01-17 17:33:50.850 | DEBUG    | __main__:<module>:313 - Training step 12610: loss = 3.1670 | 3020.88ms | Tokens/s = 173,554.6
2025-01-17 17:34:21.058 | DEBUG    | __main__:<module>:313 - Training step 12620: loss = 3.1698 | 3021.73ms | Tokens/s = 173,505.9
2025-01-17 17:34:51.266 | DEBUG    | __main__:<module>:313 - Training step 12630: loss = 3.3225 | 3021.62ms | Tokens/s = 173,512.4
2025-01-17 17:35:21.464 | DEBUG    | __main__:<module>:313 - Training step 12640: loss = 2.9524 | 3019.49ms | Tokens/s = 173,634.4
2025-01-17 17:35:51.654 | DEBUG    | __main__:<module>:313 - Training step 12650: loss = 3.2243 | 3017.20ms | Tokens/s = 173,766.3
2025-01-17 17:36:21.850 | DEBUG    | __main__:<module>:313 - Training step 12660: loss = 3.2397 | 3019.37ms | Tokens/s = 173,641.7
2025-01-17 17:36:52.072 | DEBUG    | __main__:<module>:313 - Training step 12670: loss = 3.2172 | 3025.87ms | Tokens/s = 173,268.4
2025-01-17 17:37:22.310 | DEBUG    | __main__:<module>:313 - Training step 12680: loss = 3.0859 | 3020.79ms | Tokens/s = 173,560.0
2025-01-17 17:37:52.532 | DEBUG    | __main__:<module>:313 - Training step 12690: loss = 3.2008 | 3021.99ms | Tokens/s = 173,491.2
2025-01-17 17:38:22.785 | DEBUG    | __main__:<module>:313 - Training step 12700: loss = 3.2912 | 3023.97ms | Tokens/s = 173,377.2
2025-01-17 17:38:53.028 | DEBUG    | __main__:<module>:313 - Training step 12710: loss = 3.3423 | 3022.44ms | Tokens/s = 173,465.0
2025-01-17 17:39:23.258 | DEBUG    | __main__:<module>:313 - Training step 12720: loss = 3.2248 | 3022.19ms | Tokens/s = 173,479.7
2025-01-17 17:39:53.486 | DEBUG    | __main__:<module>:313 - Training step 12730: loss = 3.1754 | 3024.38ms | Tokens/s = 173,353.6
2025-01-17 17:40:23.740 | DEBUG    | __main__:<module>:313 - Training step 12740: loss = 3.2285 | 3024.44ms | Tokens/s = 173,350.2
2025-01-17 17:40:53.980 | DEBUG    | __main__:<module>:313 - Training step 12750: loss = 3.3291 | 3024.37ms | Tokens/s = 173,354.4
2025-01-17 17:41:24.230 | DEBUG    | __main__:<module>:313 - Training step 12760: loss = 3.2257 | 3022.70ms | Tokens/s = 173,450.3
2025-01-17 17:41:54.470 | DEBUG    | __main__:<module>:313 - Training step 12770: loss = 3.2127 | 3023.92ms | Tokens/s = 173,380.3
2025-01-17 17:42:24.696 | DEBUG    | __main__:<module>:313 - Training step 12780: loss = 3.2443 | 3020.38ms | Tokens/s = 173,583.2
2025-01-17 17:42:54.902 | DEBUG    | __main__:<module>:313 - Training step 12790: loss = 3.1932 | 3022.15ms | Tokens/s = 173,482.0
2025-01-17 17:43:25.095 | DEBUG    | __main__:<module>:313 - Training step 12800: loss = 3.1068 | 3019.01ms | Tokens/s = 173,662.3
2025-01-17 17:43:55.294 | DEBUG    | __main__:<module>:313 - Training step 12810: loss = 3.1897 | 3022.12ms | Tokens/s = 173,483.7
2025-01-17 17:44:25.518 | DEBUG    | __main__:<module>:313 - Training step 12820: loss = 3.2018 | 3025.07ms | Tokens/s = 173,314.6
2025-01-17 17:44:55.777 | DEBUG    | __main__:<module>:313 - Training step 12830: loss = 3.0809 | 3024.91ms | Tokens/s = 173,323.6
2025-01-17 17:45:26.022 | DEBUG    | __main__:<module>:313 - Training step 12840: loss = 3.2377 | 3025.05ms | Tokens/s = 173,315.5
2025-01-17 17:45:56.237 | DEBUG    | __main__:<module>:313 - Training step 12850: loss = 3.1209 | 3020.62ms | Tokens/s = 173,569.9
2025-01-17 17:46:26.439 | DEBUG    | __main__:<module>:313 - Training step 12860: loss = 3.2485 | 3021.18ms | Tokens/s = 173,537.7
2025-01-17 17:46:56.672 | DEBUG    | __main__:<module>:313 - Training step 12870: loss = 3.2578 | 3023.26ms | Tokens/s = 173,418.0
2025-01-17 17:47:26.933 | DEBUG    | __main__:<module>:313 - Training step 12880: loss = 3.2438 | 3026.42ms | Tokens/s = 173,237.3
2025-01-17 17:47:57.172 | DEBUG    | __main__:<module>:313 - Training step 12890: loss = 3.2476 | 3024.26ms | Tokens/s = 173,360.5
2025-01-17 17:48:27.438 | DEBUG    | __main__:<module>:313 - Training step 12900: loss = 3.1016 | 3026.30ms | Tokens/s = 173,244.1
2025-01-17 17:48:57.693 | DEBUG    | __main__:<module>:313 - Training step 12910: loss = 3.1846 | 3026.67ms | Tokens/s = 173,222.8
2025-01-17 17:49:27.926 | DEBUG    | __main__:<module>:313 - Training step 12920: loss = 3.1402 | 3022.00ms | Tokens/s = 173,490.5
2025-01-17 17:49:58.140 | DEBUG    | __main__:<module>:313 - Training step 12930: loss = 3.3140 | 3018.18ms | Tokens/s = 173,710.1
2025-01-17 17:50:28.339 | DEBUG    | __main__:<module>:313 - Training step 12940: loss = 3.0752 | 3019.49ms | Tokens/s = 173,634.7
2025-01-17 17:50:58.543 | DEBUG    | __main__:<module>:313 - Training step 12950: loss = 3.2367 | 3021.42ms | Tokens/s = 173,523.5
2025-01-17 17:51:28.759 | DEBUG    | __main__:<module>:313 - Training step 12960: loss = 3.1250 | 3021.89ms | Tokens/s = 173,496.8
2025-01-17 17:51:59.015 | DEBUG    | __main__:<module>:313 - Training step 12970: loss = 3.2245 | 3026.37ms | Tokens/s = 173,239.6
2025-01-17 17:52:29.283 | DEBUG    | __main__:<module>:313 - Training step 12980: loss = 3.1803 | 3025.59ms | Tokens/s = 173,284.6
2025-01-17 17:52:59.530 | DEBUG    | __main__:<module>:313 - Training step 12990: loss = 3.3426 | 3023.43ms | Tokens/s = 173,408.4
2025-01-17 17:53:33.193 | INFO     | __main__:<module>:265 - Step 13,000/20,000 loss: 3.2085 (T) 3.2041 (V) | lr=3.3e-03
2025-01-17 17:53:33.194 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 17:53:46.589 | DEBUG    | __main__:<module>:313 - Training step 13000: loss = 3.2761 | 19851.46ms | Tokens/s = 26,410.6
2025-01-17 17:54:16.685 | DEBUG    | __main__:<module>:313 - Training step 13010: loss = 3.1050 | 3012.13ms | Tokens/s = 174,058.8
2025-01-17 17:54:46.873 | DEBUG    | __main__:<module>:313 - Training step 13020: loss = 3.3044 | 3023.05ms | Tokens/s = 173,430.2
2025-01-17 17:55:17.110 | DEBUG    | __main__:<module>:313 - Training step 13030: loss = 3.0939 | 3025.41ms | Tokens/s = 173,294.9
2025-01-17 17:55:47.370 | DEBUG    | __main__:<module>:313 - Training step 13040: loss = 3.2728 | 3025.92ms | Tokens/s = 173,265.6
2025-01-17 17:56:17.621 | DEBUG    | __main__:<module>:313 - Training step 13050: loss = 3.1973 | 3024.46ms | Tokens/s = 173,349.4
2025-01-17 17:56:47.845 | DEBUG    | __main__:<module>:313 - Training step 13060: loss = 3.3128 | 3020.90ms | Tokens/s = 173,553.6
2025-01-17 17:57:18.069 | DEBUG    | __main__:<module>:313 - Training step 13070: loss = 2.9943 | 3021.22ms | Tokens/s = 173,535.3
2025-01-17 17:57:48.282 | DEBUG    | __main__:<module>:313 - Training step 13080: loss = 3.2533 | 3023.01ms | Tokens/s = 173,432.5
2025-01-17 17:58:18.488 | DEBUG    | __main__:<module>:313 - Training step 13090: loss = 3.1494 | 3022.12ms | Tokens/s = 173,483.6
2025-01-17 17:58:48.739 | DEBUG    | __main__:<module>:313 - Training step 13100: loss = 3.1896 | 3024.73ms | Tokens/s = 173,333.7
2025-01-17 17:59:19.004 | DEBUG    | __main__:<module>:313 - Training step 13110: loss = 3.2722 | 3024.96ms | Tokens/s = 173,320.4
2025-01-17 17:59:49.257 | DEBUG    | __main__:<module>:313 - Training step 13120: loss = 3.3013 | 3023.69ms | Tokens/s = 173,393.2
2025-01-17 18:00:19.489 | DEBUG    | __main__:<module>:313 - Training step 13130: loss = 3.0261 | 3023.70ms | Tokens/s = 173,393.0
2025-01-17 18:00:49.702 | DEBUG    | __main__:<module>:313 - Training step 13140: loss = 3.3706 | 3020.78ms | Tokens/s = 173,560.3
2025-01-17 18:01:19.926 | DEBUG    | __main__:<module>:313 - Training step 13150: loss = 3.2946 | 3024.25ms | Tokens/s = 173,361.4
2025-01-17 18:01:50.162 | DEBUG    | __main__:<module>:313 - Training step 13160: loss = 3.1719 | 3021.77ms | Tokens/s = 173,503.3
2025-01-17 18:02:20.374 | DEBUG    | __main__:<module>:313 - Training step 13170: loss = 3.3423 | 3021.55ms | Tokens/s = 173,516.3
2025-01-17 18:02:50.582 | DEBUG    | __main__:<module>:313 - Training step 13180: loss = 3.2360 | 3021.71ms | Tokens/s = 173,506.8
2025-01-17 18:03:20.828 | DEBUG    | __main__:<module>:313 - Training step 13190: loss = 3.2542 | 3024.94ms | Tokens/s = 173,321.8
2025-01-17 18:03:51.054 | DEBUG    | __main__:<module>:313 - Training step 13200: loss = 3.2725 | 3019.31ms | Tokens/s = 173,644.8
2025-01-17 18:04:21.275 | DEBUG    | __main__:<module>:313 - Training step 13210: loss = 3.2320 | 3023.50ms | Tokens/s = 173,404.6
2025-01-17 18:04:51.520 | DEBUG    | __main__:<module>:313 - Training step 13220: loss = 3.1497 | 3024.80ms | Tokens/s = 173,329.7
2025-01-17 18:05:21.753 | DEBUG    | __main__:<module>:313 - Training step 13230: loss = 3.1985 | 3020.13ms | Tokens/s = 173,597.7
2025-01-17 18:05:51.971 | DEBUG    | __main__:<module>:313 - Training step 13240: loss = 3.3018 | 3023.04ms | Tokens/s = 173,430.9
2025-01-17 18:06:22.185 | DEBUG    | __main__:<module>:313 - Training step 13250: loss = 3.2825 | 3021.47ms | Tokens/s = 173,520.8
2025-01-17 18:06:52.432 | DEBUG    | __main__:<module>:313 - Training step 13260: loss = 3.1648 | 3026.66ms | Tokens/s = 173,223.0
2025-01-17 18:07:22.680 | DEBUG    | __main__:<module>:313 - Training step 13270: loss = 3.1697 | 3025.88ms | Tokens/s = 173,268.2
2025-01-17 18:07:52.929 | DEBUG    | __main__:<module>:313 - Training step 13280: loss = 3.2654 | 3023.56ms | Tokens/s = 173,400.6
2025-01-17 18:08:23.149 | DEBUG    | __main__:<module>:313 - Training step 13290: loss = 3.2013 | 3019.89ms | Tokens/s = 173,611.4
2025-01-17 18:08:53.361 | DEBUG    | __main__:<module>:313 - Training step 13300: loss = 3.1966 | 3018.23ms | Tokens/s = 173,707.3
2025-01-17 18:09:23.573 | DEBUG    | __main__:<module>:313 - Training step 13310: loss = 3.2494 | 3018.12ms | Tokens/s = 173,713.4
2025-01-17 18:09:53.779 | DEBUG    | __main__:<module>:313 - Training step 13320: loss = 3.2918 | 3021.07ms | Tokens/s = 173,543.9
2025-01-17 18:10:23.972 | DEBUG    | __main__:<module>:313 - Training step 13330: loss = 2.9679 | 3017.28ms | Tokens/s = 173,761.9
2025-01-17 18:10:54.185 | DEBUG    | __main__:<module>:313 - Training step 13340: loss = 3.3872 | 3022.65ms | Tokens/s = 173,453.0
2025-01-17 18:11:24.427 | DEBUG    | __main__:<module>:313 - Training step 13350: loss = 3.2692 | 3026.56ms | Tokens/s = 173,229.0
2025-01-17 18:11:54.696 | DEBUG    | __main__:<module>:313 - Training step 13360: loss = 3.2091 | 3026.97ms | Tokens/s = 173,205.6
2025-01-17 18:12:24.959 | DEBUG    | __main__:<module>:313 - Training step 13370: loss = 3.2802 | 3026.84ms | Tokens/s = 173,212.8
2025-01-17 18:12:55.220 | DEBUG    | __main__:<module>:313 - Training step 13380: loss = 3.1958 | 3025.58ms | Tokens/s = 173,285.2
2025-01-17 18:13:25.466 | DEBUG    | __main__:<module>:313 - Training step 13390: loss = 3.1059 | 3023.60ms | Tokens/s = 173,398.4
2025-01-17 18:13:55.708 | DEBUG    | __main__:<module>:313 - Training step 13400: loss = 3.2892 | 3022.39ms | Tokens/s = 173,467.9
2025-01-17 18:14:25.943 | DEBUG    | __main__:<module>:313 - Training step 13410: loss = 3.1811 | 3023.23ms | Tokens/s = 173,420.1
2025-01-17 18:14:56.174 | DEBUG    | __main__:<module>:313 - Training step 13420: loss = 3.1057 | 3019.85ms | Tokens/s = 173,613.8
2025-01-17 18:15:26.408 | DEBUG    | __main__:<module>:313 - Training step 13430: loss = 3.2460 | 3025.68ms | Tokens/s = 173,279.1
2025-01-17 18:15:56.664 | DEBUG    | __main__:<module>:313 - Training step 13440: loss = 3.0553 | 3026.40ms | Tokens/s = 173,238.0
2025-01-17 18:16:26.897 | DEBUG    | __main__:<module>:313 - Training step 13450: loss = 3.2931 | 3024.20ms | Tokens/s = 173,363.9
2025-01-17 18:16:57.121 | DEBUG    | __main__:<module>:313 - Training step 13460: loss = 3.3647 | 3023.85ms | Tokens/s = 173,384.5
2025-01-17 18:17:27.360 | DEBUG    | __main__:<module>:313 - Training step 13470: loss = 3.1339 | 3023.21ms | Tokens/s = 173,421.0
2025-01-17 18:17:57.582 | DEBUG    | __main__:<module>:313 - Training step 13480: loss = 2.9357 | 3021.47ms | Tokens/s = 173,521.1
2025-01-17 18:18:27.798 | DEBUG    | __main__:<module>:313 - Training step 13490: loss = 3.1858 | 3023.11ms | Tokens/s = 173,426.8
2025-01-17 18:18:58.040 | DEBUG    | __main__:<module>:313 - Training step 13500: loss = 3.0254 | 3022.65ms | Tokens/s = 173,453.0
2025-01-17 18:19:28.255 | DEBUG    | __main__:<module>:313 - Training step 13510: loss = 3.2562 | 3022.33ms | Tokens/s = 173,471.2
2025-01-17 18:19:58.458 | DEBUG    | __main__:<module>:313 - Training step 13520: loss = 3.2364 | 3020.85ms | Tokens/s = 173,556.5
2025-01-17 18:20:28.641 | DEBUG    | __main__:<module>:313 - Training step 13530: loss = 3.1630 | 3016.87ms | Tokens/s = 173,785.5
2025-01-17 18:20:58.848 | DEBUG    | __main__:<module>:313 - Training step 13540: loss = 3.2098 | 3023.77ms | Tokens/s = 173,389.0
2025-01-17 18:21:29.083 | DEBUG    | __main__:<module>:313 - Training step 13550: loss = 3.0048 | 3025.20ms | Tokens/s = 173,306.7
2025-01-17 18:21:59.339 | DEBUG    | __main__:<module>:313 - Training step 13560: loss = 3.1791 | 3024.93ms | Tokens/s = 173,322.6
2025-01-17 18:22:29.588 | DEBUG    | __main__:<module>:313 - Training step 13570: loss = 3.1414 | 3026.65ms | Tokens/s = 173,224.1
2025-01-17 18:22:59.830 | DEBUG    | __main__:<module>:313 - Training step 13580: loss = 3.3354 | 3026.02ms | Tokens/s = 173,260.0
2025-01-17 18:23:30.052 | DEBUG    | __main__:<module>:313 - Training step 13590: loss = 3.1740 | 3021.23ms | Tokens/s = 173,534.6
2025-01-17 18:24:00.277 | DEBUG    | __main__:<module>:313 - Training step 13600: loss = 3.2307 | 3021.98ms | Tokens/s = 173,491.7
2025-01-17 18:24:30.495 | DEBUG    | __main__:<module>:313 - Training step 13610: loss = 2.9605 | 3022.04ms | Tokens/s = 173,488.3
2025-01-17 18:25:00.705 | DEBUG    | __main__:<module>:313 - Training step 13620: loss = 3.1611 | 3018.87ms | Tokens/s = 173,670.5
2025-01-17 18:25:30.913 | DEBUG    | __main__:<module>:313 - Training step 13630: loss = 3.2365 | 3020.42ms | Tokens/s = 173,581.4
2025-01-17 18:26:01.133 | DEBUG    | __main__:<module>:313 - Training step 13640: loss = 3.0629 | 3023.99ms | Tokens/s = 173,376.2
2025-01-17 18:26:31.394 | DEBUG    | __main__:<module>:313 - Training step 13650: loss = 3.1841 | 3026.82ms | Tokens/s = 173,214.2
2025-01-17 18:27:01.655 | DEBUG    | __main__:<module>:313 - Training step 13660: loss = 3.2345 | 3026.27ms | Tokens/s = 173,245.5
2025-01-17 18:27:31.914 | DEBUG    | __main__:<module>:313 - Training step 13670: loss = 3.2505 | 3024.33ms | Tokens/s = 173,356.6
2025-01-17 18:28:02.141 | DEBUG    | __main__:<module>:313 - Training step 13680: loss = 3.2026 | 3022.72ms | Tokens/s = 173,449.2
2025-01-17 18:28:32.361 | DEBUG    | __main__:<module>:313 - Training step 13690: loss = 3.2996 | 3021.73ms | Tokens/s = 173,506.1
2025-01-17 18:29:02.594 | DEBUG    | __main__:<module>:313 - Training step 13700: loss = 3.1111 | 3023.66ms | Tokens/s = 173,394.9
2025-01-17 18:29:32.856 | DEBUG    | __main__:<module>:313 - Training step 13710: loss = 3.0786 | 3027.60ms | Tokens/s = 173,169.8
2025-01-17 18:30:03.100 | DEBUG    | __main__:<module>:313 - Training step 13720: loss = 3.0873 | 3023.83ms | Tokens/s = 173,385.7
2025-01-17 18:30:33.318 | DEBUG    | __main__:<module>:313 - Training step 13730: loss = 3.2893 | 3021.16ms | Tokens/s = 173,538.7
2025-01-17 18:31:03.532 | DEBUG    | __main__:<module>:313 - Training step 13740: loss = 3.2106 | 3022.33ms | Tokens/s = 173,471.2
2025-01-17 18:31:33.749 | DEBUG    | __main__:<module>:313 - Training step 13750: loss = 3.1127 | 3024.25ms | Tokens/s = 173,361.1
2025-01-17 18:32:03.997 | DEBUG    | __main__:<module>:313 - Training step 13760: loss = 3.2610 | 3025.49ms | Tokens/s = 173,290.2
2025-01-17 18:32:34.239 | DEBUG    | __main__:<module>:313 - Training step 13770: loss = 3.3011 | 3023.06ms | Tokens/s = 173,429.7
2025-01-17 18:33:04.471 | DEBUG    | __main__:<module>:313 - Training step 13780: loss = 3.2662 | 3020.75ms | Tokens/s = 173,562.0
2025-01-17 18:33:34.711 | DEBUG    | __main__:<module>:313 - Training step 13790: loss = 3.1719 | 3025.54ms | Tokens/s = 173,287.4
2025-01-17 18:34:04.959 | DEBUG    | __main__:<module>:313 - Training step 13800: loss = 3.2130 | 3025.92ms | Tokens/s = 173,265.5
2025-01-17 18:34:35.196 | DEBUG    | __main__:<module>:313 - Training step 13810: loss = 3.1985 | 3020.88ms | Tokens/s = 173,554.5
2025-01-17 18:35:05.416 | DEBUG    | __main__:<module>:313 - Training step 13820: loss = 3.2291 | 3020.82ms | Tokens/s = 173,558.1
2025-01-17 18:35:35.624 | DEBUG    | __main__:<module>:313 - Training step 13830: loss = 3.0059 | 3018.90ms | Tokens/s = 173,668.6
2025-01-17 18:36:05.840 | DEBUG    | __main__:<module>:313 - Training step 13840: loss = 3.1020 | 3023.05ms | Tokens/s = 173,430.1
2025-01-17 18:36:36.094 | DEBUG    | __main__:<module>:313 - Training step 13850: loss = 3.1584 | 3024.55ms | Tokens/s = 173,344.1
2025-01-17 18:37:06.337 | DEBUG    | __main__:<module>:313 - Training step 13860: loss = 3.0799 | 3023.67ms | Tokens/s = 173,394.6
2025-01-17 18:37:36.551 | DEBUG    | __main__:<module>:313 - Training step 13870: loss = 3.1202 | 3020.27ms | Tokens/s = 173,589.7
2025-01-17 18:38:06.746 | DEBUG    | __main__:<module>:313 - Training step 13880: loss = 3.1558 | 3020.21ms | Tokens/s = 173,593.1
2025-01-17 18:38:36.957 | DEBUG    | __main__:<module>:313 - Training step 13890: loss = 3.1175 | 3023.03ms | Tokens/s = 173,431.5
2025-01-17 18:39:07.205 | DEBUG    | __main__:<module>:313 - Training step 13900: loss = 3.1319 | 3026.13ms | Tokens/s = 173,253.6
2025-01-17 18:39:37.466 | DEBUG    | __main__:<module>:313 - Training step 13910: loss = 3.2664 | 3024.67ms | Tokens/s = 173,337.0
2025-01-17 18:40:07.704 | DEBUG    | __main__:<module>:313 - Training step 13920: loss = 2.9892 | 3021.08ms | Tokens/s = 173,543.1
2025-01-17 18:40:37.927 | DEBUG    | __main__:<module>:313 - Training step 13930: loss = 3.2376 | 3024.19ms | Tokens/s = 173,364.5
2025-01-17 18:41:08.188 | DEBUG    | __main__:<module>:313 - Training step 13940: loss = 3.2048 | 3027.13ms | Tokens/s = 173,196.2
2025-01-17 18:41:38.436 | DEBUG    | __main__:<module>:313 - Training step 13950: loss = 3.0707 | 3023.16ms | Tokens/s = 173,424.0
2025-01-17 18:42:08.694 | DEBUG    | __main__:<module>:313 - Training step 13960: loss = 3.2512 | 3024.19ms | Tokens/s = 173,364.8
2025-01-17 18:42:38.944 | DEBUG    | __main__:<module>:313 - Training step 13970: loss = 3.2043 | 3023.38ms | Tokens/s = 173,411.2
2025-01-17 18:43:09.172 | DEBUG    | __main__:<module>:313 - Training step 13980: loss = 3.0660 | 3020.98ms | Tokens/s = 173,548.8
2025-01-17 18:43:39.419 | DEBUG    | __main__:<module>:313 - Training step 13990: loss = 3.0450 | 3025.20ms | Tokens/s = 173,307.0
2025-01-17 18:44:13.112 | INFO     | __main__:<module>:265 - Step 14,000/20,000 loss: 3.1567 (T) 3.1884 (V) | lr=2.5e-03
2025-01-17 18:44:13.114 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 18:44:26.467 | DEBUG    | __main__:<module>:313 - Training step 14000: loss = 2.9165 | 19819.10ms | Tokens/s = 26,453.7
2025-01-17 18:44:56.572 | DEBUG    | __main__:<module>:313 - Training step 14010: loss = 3.2549 | 3015.66ms | Tokens/s = 173,855.4
2025-01-17 18:45:26.772 | DEBUG    | __main__:<module>:313 - Training step 14020: loss = 3.0709 | 3021.44ms | Tokens/s = 173,522.3
2025-01-17 18:45:57.013 | DEBUG    | __main__:<module>:313 - Training step 14030: loss = 3.0857 | 3025.50ms | Tokens/s = 173,289.7
2025-01-17 18:46:27.270 | DEBUG    | __main__:<module>:313 - Training step 14040: loss = 3.0094 | 3023.11ms | Tokens/s = 173,426.8
2025-01-17 18:46:57.499 | DEBUG    | __main__:<module>:313 - Training step 14050: loss = 3.2041 | 3021.67ms | Tokens/s = 173,509.3
2025-01-17 18:47:27.720 | DEBUG    | __main__:<module>:313 - Training step 14060: loss = 3.2771 | 3025.41ms | Tokens/s = 173,294.7
2025-01-17 18:47:57.961 | DEBUG    | __main__:<module>:313 - Training step 14070: loss = 3.1558 | 3024.04ms | Tokens/s = 173,373.3
2025-01-17 18:48:28.190 | DEBUG    | __main__:<module>:313 - Training step 14080: loss = 3.1577 | 3024.16ms | Tokens/s = 173,366.3
2025-01-17 18:48:58.444 | DEBUG    | __main__:<module>:313 - Training step 14090: loss = 3.0996 | 3026.24ms | Tokens/s = 173,247.2
2025-01-17 18:49:28.686 | DEBUG    | __main__:<module>:313 - Training step 14100: loss = 3.0226 | 3022.57ms | Tokens/s = 173,457.9
2025-01-17 18:49:58.912 | DEBUG    | __main__:<module>:313 - Training step 14110: loss = 3.1999 | 3020.81ms | Tokens/s = 173,558.5
2025-01-17 18:50:29.127 | DEBUG    | __main__:<module>:313 - Training step 14120: loss = 2.9940 | 3020.92ms | Tokens/s = 173,552.6
2025-01-17 18:50:59.364 | DEBUG    | __main__:<module>:313 - Training step 14130: loss = 3.1860 | 3025.03ms | Tokens/s = 173,316.8
2025-01-17 18:51:29.625 | DEBUG    | __main__:<module>:313 - Training step 14140: loss = 3.1320 | 3024.12ms | Tokens/s = 173,368.7
2025-01-17 18:51:59.892 | DEBUG    | __main__:<module>:313 - Training step 14150: loss = 3.4334 | 3025.32ms | Tokens/s = 173,299.9
2025-01-17 18:52:30.131 | DEBUG    | __main__:<module>:313 - Training step 14160: loss = 3.2996 | 3022.86ms | Tokens/s = 173,441.0
2025-01-17 18:53:00.349 | DEBUG    | __main__:<module>:313 - Training step 14170: loss = 3.2934 | 3020.37ms | Tokens/s = 173,583.8
2025-01-17 18:53:30.564 | DEBUG    | __main__:<module>:313 - Training step 14180: loss = 3.1409 | 3019.74ms | Tokens/s = 173,620.2
2025-01-17 18:54:00.772 | DEBUG    | __main__:<module>:313 - Training step 14190: loss = 3.2286 | 3021.09ms | Tokens/s = 173,542.9
2025-01-17 18:54:30.973 | DEBUG    | __main__:<module>:313 - Training step 14200: loss = 3.2160 | 3017.88ms | Tokens/s = 173,727.2
2025-01-17 18:55:01.192 | DEBUG    | __main__:<module>:313 - Training step 14210: loss = 3.0344 | 3021.50ms | Tokens/s = 173,519.0
2025-01-17 18:55:31.424 | DEBUG    | __main__:<module>:313 - Training step 14220: loss = 3.1077 | 3022.30ms | Tokens/s = 173,473.4
2025-01-17 18:56:01.665 | DEBUG    | __main__:<module>:313 - Training step 14230: loss = 3.0900 | 3023.60ms | Tokens/s = 173,398.7
2025-01-17 18:56:31.909 | DEBUG    | __main__:<module>:313 - Training step 14240: loss = 3.1016 | 3022.55ms | Tokens/s = 173,458.7
2025-01-17 18:57:02.157 | DEBUG    | __main__:<module>:313 - Training step 14250: loss = 3.0620 | 3025.00ms | Tokens/s = 173,318.2
2025-01-17 18:57:32.383 | DEBUG    | __main__:<module>:313 - Training step 14260: loss = 3.0771 | 3020.96ms | Tokens/s = 173,550.2
2025-01-17 18:58:02.596 | DEBUG    | __main__:<module>:313 - Training step 14270: loss = 3.1574 | 3020.25ms | Tokens/s = 173,590.7
2025-01-17 18:58:32.828 | DEBUG    | __main__:<module>:313 - Training step 14280: loss = 3.2691 | 3025.09ms | Tokens/s = 173,313.2
2025-01-17 18:59:03.074 | DEBUG    | __main__:<module>:313 - Training step 14290: loss = 3.1656 | 3023.99ms | Tokens/s = 173,376.3
2025-01-17 18:59:33.299 | DEBUG    | __main__:<module>:313 - Training step 14300: loss = 3.2479 | 3021.55ms | Tokens/s = 173,516.1
2025-01-17 19:00:03.536 | DEBUG    | __main__:<module>:313 - Training step 14310: loss = 3.0826 | 3022.68ms | Tokens/s = 173,451.2
2025-01-17 19:00:33.742 | DEBUG    | __main__:<module>:313 - Training step 14320: loss = 3.2170 | 3020.04ms | Tokens/s = 173,602.8
2025-01-17 19:01:03.930 | DEBUG    | __main__:<module>:313 - Training step 14330: loss = 3.0865 | 3017.59ms | Tokens/s = 173,743.8
2025-01-17 19:01:34.134 | DEBUG    | __main__:<module>:313 - Training step 14340: loss = 3.1770 | 3021.98ms | Tokens/s = 173,491.7
2025-01-17 19:02:04.367 | DEBUG    | __main__:<module>:313 - Training step 14350: loss = 3.2175 | 3022.03ms | Tokens/s = 173,488.5
2025-01-17 19:02:34.611 | DEBUG    | __main__:<module>:313 - Training step 14360: loss = 3.0803 | 3023.75ms | Tokens/s = 173,390.1
2025-01-17 19:03:04.848 | DEBUG    | __main__:<module>:313 - Training step 14370: loss = 2.9785 | 3021.59ms | Tokens/s = 173,513.8
2025-01-17 19:03:35.048 | DEBUG    | __main__:<module>:313 - Training step 14380: loss = 3.0753 | 3020.20ms | Tokens/s = 173,594.0
2025-01-17 19:04:05.255 | DEBUG    | __main__:<module>:313 - Training step 14390: loss = 3.5214 | 3022.43ms | Tokens/s = 173,465.6
2025-01-17 19:04:35.483 | DEBUG    | __main__:<module>:313 - Training step 14400: loss = 3.1992 | 3021.37ms | Tokens/s = 173,526.8
2025-01-17 19:05:05.723 | DEBUG    | __main__:<module>:313 - Training step 14410: loss = 3.3206 | 3024.87ms | Tokens/s = 173,326.0
2025-01-17 19:05:35.980 | DEBUG    | __main__:<module>:313 - Training step 14420: loss = 3.1892 | 3023.15ms | Tokens/s = 173,424.7
2025-01-17 19:06:06.191 | DEBUG    | __main__:<module>:313 - Training step 14430: loss = 3.1603 | 3019.28ms | Tokens/s = 173,646.9
2025-01-17 19:06:36.386 | DEBUG    | __main__:<module>:313 - Training step 14440: loss = 3.0765 | 3019.47ms | Tokens/s = 173,635.8
2025-01-17 19:07:06.599 | DEBUG    | __main__:<module>:313 - Training step 14450: loss = 3.1106 | 3020.81ms | Tokens/s = 173,558.9
2025-01-17 19:07:36.821 | DEBUG    | __main__:<module>:313 - Training step 14460: loss = 3.0813 | 3022.41ms | Tokens/s = 173,466.9
2025-01-17 19:08:07.052 | DEBUG    | __main__:<module>:313 - Training step 14470: loss = 3.0958 | 3023.89ms | Tokens/s = 173,382.1
2025-01-17 19:08:37.282 | DEBUG    | __main__:<module>:313 - Training step 14480: loss = 3.2848 | 3022.54ms | Tokens/s = 173,459.3
2025-01-17 19:09:07.496 | DEBUG    | __main__:<module>:313 - Training step 14490: loss = 3.0466 | 3018.79ms | Tokens/s = 173,675.1
2025-01-17 19:09:37.686 | DEBUG    | __main__:<module>:313 - Training step 14500: loss = 3.1637 | 3018.65ms | Tokens/s = 173,682.7
2025-01-17 19:10:07.893 | DEBUG    | __main__:<module>:313 - Training step 14510: loss = 3.2331 | 3020.68ms | Tokens/s = 173,566.4
2025-01-17 19:10:38.125 | DEBUG    | __main__:<module>:313 - Training step 14520: loss = 3.3253 | 3022.79ms | Tokens/s = 173,445.2
2025-01-17 19:11:08.378 | DEBUG    | __main__:<module>:313 - Training step 14530: loss = 3.1168 | 3025.07ms | Tokens/s = 173,314.2
2025-01-17 19:11:38.634 | DEBUG    | __main__:<module>:313 - Training step 14540: loss = 3.0387 | 3028.18ms | Tokens/s = 173,136.1
2025-01-17 19:12:08.903 | DEBUG    | __main__:<module>:313 - Training step 14550: loss = 3.2040 | 3024.73ms | Tokens/s = 173,333.7
2025-01-17 19:12:39.133 | DEBUG    | __main__:<module>:313 - Training step 14560: loss = 3.2589 | 3021.92ms | Tokens/s = 173,494.8
2025-01-17 19:13:09.341 | DEBUG    | __main__:<module>:313 - Training step 14570: loss = 3.2144 | 3022.57ms | Tokens/s = 173,457.5
2025-01-17 19:13:39.567 | DEBUG    | __main__:<module>:313 - Training step 14580: loss = 3.1326 | 3022.91ms | Tokens/s = 173,438.2
2025-01-17 19:14:09.787 | DEBUG    | __main__:<module>:313 - Training step 14590: loss = 3.1732 | 3022.50ms | Tokens/s = 173,461.8
2025-01-17 19:14:40.024 | DEBUG    | __main__:<module>:313 - Training step 14600: loss = 3.2035 | 3022.00ms | Tokens/s = 173,490.6
2025-01-17 19:15:10.232 | DEBUG    | __main__:<module>:313 - Training step 14610: loss = 3.1624 | 3019.42ms | Tokens/s = 173,638.7
2025-01-17 19:15:40.448 | DEBUG    | __main__:<module>:313 - Training step 14620: loss = 3.2662 | 3023.42ms | Tokens/s = 173,409.0
2025-01-17 19:16:10.683 | DEBUG    | __main__:<module>:313 - Training step 14630: loss = 3.0316 | 3022.61ms | Tokens/s = 173,455.6
2025-01-17 19:16:40.928 | DEBUG    | __main__:<module>:313 - Training step 14640: loss = 3.1358 | 3024.38ms | Tokens/s = 173,353.6
2025-01-17 19:17:11.181 | DEBUG    | __main__:<module>:313 - Training step 14650: loss = 3.2232 | 3022.98ms | Tokens/s = 173,434.0
2025-01-17 19:17:41.391 | DEBUG    | __main__:<module>:313 - Training step 14660: loss = 3.1538 | 3019.39ms | Tokens/s = 173,640.1
2025-01-17 19:18:11.584 | DEBUG    | __main__:<module>:313 - Training step 14670: loss = 3.0546 | 3017.92ms | Tokens/s = 173,725.2
2025-01-17 19:18:41.795 | DEBUG    | __main__:<module>:313 - Training step 14680: loss = 3.0293 | 3021.25ms | Tokens/s = 173,533.6
2025-01-17 19:19:12.020 | DEBUG    | __main__:<module>:313 - Training step 14690: loss = 3.2195 | 3023.20ms | Tokens/s = 173,421.8
2025-01-17 19:19:42.248 | DEBUG    | __main__:<module>:313 - Training step 14700: loss = 3.1599 | 3020.23ms | Tokens/s = 173,591.9
2025-01-17 19:20:12.492 | DEBUG    | __main__:<module>:313 - Training step 14710: loss = 3.0838 | 3025.32ms | Tokens/s = 173,300.2
2025-01-17 19:20:42.732 | DEBUG    | __main__:<module>:313 - Training step 14720: loss = 3.1077 | 3022.84ms | Tokens/s = 173,442.4
2025-01-17 19:21:12.983 | DEBUG    | __main__:<module>:313 - Training step 14730: loss = 3.0046 | 3028.37ms | Tokens/s = 173,125.3
2025-01-17 19:21:43.237 | DEBUG    | __main__:<module>:313 - Training step 14740: loss = 3.1121 | 3023.43ms | Tokens/s = 173,408.1
2025-01-17 19:22:13.459 | DEBUG    | __main__:<module>:313 - Training step 14750: loss = 3.0480 | 3022.25ms | Tokens/s = 173,476.3
2025-01-17 19:22:43.689 | DEBUG    | __main__:<module>:313 - Training step 14760: loss = 3.2409 | 3022.70ms | Tokens/s = 173,450.4
2025-01-17 19:23:13.887 | DEBUG    | __main__:<module>:313 - Training step 14770: loss = 3.1640 | 3018.72ms | Tokens/s = 173,679.1
2025-01-17 19:23:44.093 | DEBUG    | __main__:<module>:313 - Training step 14780: loss = 3.2951 | 3022.83ms | Tokens/s = 173,443.0
2025-01-17 19:24:14.310 | DEBUG    | __main__:<module>:313 - Training step 14790: loss = 3.1435 | 3024.00ms | Tokens/s = 173,375.5
2025-01-17 19:24:44.549 | DEBUG    | __main__:<module>:313 - Training step 14800: loss = 3.0429 | 3023.33ms | Tokens/s = 173,414.3
2025-01-17 19:25:14.798 | DEBUG    | __main__:<module>:313 - Training step 14810: loss = 3.2207 | 3023.41ms | Tokens/s = 173,409.4
2025-01-17 19:25:45.042 | DEBUG    | __main__:<module>:313 - Training step 14820: loss = 3.1008 | 3022.47ms | Tokens/s = 173,463.4
2025-01-17 19:26:15.241 | DEBUG    | __main__:<module>:313 - Training step 14830: loss = 3.1079 | 3018.51ms | Tokens/s = 173,691.0
2025-01-17 19:26:45.446 | DEBUG    | __main__:<module>:313 - Training step 14840: loss = 3.1608 | 3020.17ms | Tokens/s = 173,595.4
2025-01-17 19:27:15.656 | DEBUG    | __main__:<module>:313 - Training step 14850: loss = 3.2283 | 3020.08ms | Tokens/s = 173,600.7
2025-01-17 19:27:45.872 | DEBUG    | __main__:<module>:313 - Training step 14860: loss = 3.2479 | 3024.05ms | Tokens/s = 173,372.5
2025-01-17 19:28:16.108 | DEBUG    | __main__:<module>:313 - Training step 14870: loss = 3.1397 | 3024.48ms | Tokens/s = 173,348.2
2025-01-17 19:28:46.350 | DEBUG    | __main__:<module>:313 - Training step 14880: loss = 3.1189 | 3025.39ms | Tokens/s = 173,295.8
2025-01-17 19:29:16.571 | DEBUG    | __main__:<module>:313 - Training step 14890: loss = 3.0182 | 3020.92ms | Tokens/s = 173,552.3
2025-01-17 19:29:46.762 | DEBUG    | __main__:<module>:313 - Training step 14900: loss = 3.3810 | 3019.21ms | Tokens/s = 173,650.7
2025-01-17 19:30:16.972 | DEBUG    | __main__:<module>:313 - Training step 14910: loss = 3.0711 | 3023.47ms | Tokens/s = 173,405.9
2025-01-17 19:30:47.207 | DEBUG    | __main__:<module>:313 - Training step 14920: loss = 3.0994 | 3021.93ms | Tokens/s = 173,494.7
2025-01-17 19:31:17.452 | DEBUG    | __main__:<module>:313 - Training step 14930: loss = 3.0832 | 3024.39ms | Tokens/s = 173,353.3
2025-01-17 19:31:47.687 | DEBUG    | __main__:<module>:313 - Training step 14940: loss = 3.1162 | 3022.53ms | Tokens/s = 173,459.7
2025-01-17 19:32:17.935 | DEBUG    | __main__:<module>:313 - Training step 14950: loss = 2.9463 | 3025.03ms | Tokens/s = 173,316.8
2025-01-17 19:32:48.194 | DEBUG    | __main__:<module>:313 - Training step 14960: loss = 3.1620 | 3027.17ms | Tokens/s = 173,194.0
2025-01-17 19:33:18.455 | DEBUG    | __main__:<module>:313 - Training step 14970: loss = 3.1163 | 3023.77ms | Tokens/s = 173,388.9
2025-01-17 19:33:48.683 | DEBUG    | __main__:<module>:313 - Training step 14980: loss = 3.1951 | 3022.52ms | Tokens/s = 173,460.6
2025-01-17 19:34:18.893 | DEBUG    | __main__:<module>:313 - Training step 14990: loss = 3.1558 | 3021.39ms | Tokens/s = 173,525.4
2025-01-17 19:34:52.537 | INFO     | __main__:<module>:265 - Step 15,000/20,000 loss: 3.1315 (T) 3.1302 (V) | lr=1.8e-03
2025-01-17 19:34:52.538 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 19:35:06.118 | DEBUG    | __main__:<module>:313 - Training step 15000: loss = 3.0597 | 20031.35ms | Tokens/s = 26,173.4
2025-01-17 19:35:36.206 | DEBUG    | __main__:<module>:313 - Training step 15010: loss = 3.1474 | 3012.96ms | Tokens/s = 174,010.9
2025-01-17 19:36:06.379 | DEBUG    | __main__:<module>:313 - Training step 15020: loss = 3.1889 | 3020.02ms | Tokens/s = 173,604.4
2025-01-17 19:36:36.578 | DEBUG    | __main__:<module>:313 - Training step 15030: loss = 3.1077 | 3021.44ms | Tokens/s = 173,522.3
2025-01-17 19:37:06.800 | DEBUG    | __main__:<module>:313 - Training step 15040: loss = 3.1286 | 3024.48ms | Tokens/s = 173,348.0
2025-01-17 19:37:37.036 | DEBUG    | __main__:<module>:313 - Training step 15050: loss = 3.0865 | 3023.48ms | Tokens/s = 173,405.4
2025-01-17 19:38:07.263 | DEBUG    | __main__:<module>:313 - Training step 15060: loss = 3.0415 | 3023.80ms | Tokens/s = 173,387.4
2025-01-17 19:38:37.486 | DEBUG    | __main__:<module>:313 - Training step 15070: loss = 3.0905 | 3024.15ms | Tokens/s = 173,367.0
2025-01-17 19:39:07.718 | DEBUG    | __main__:<module>:313 - Training step 15080: loss = 3.1135 | 3021.60ms | Tokens/s = 173,513.6
2025-01-17 19:39:37.930 | DEBUG    | __main__:<module>:313 - Training step 15090: loss = 3.0417 | 3020.58ms | Tokens/s = 173,571.8
2025-01-17 19:40:08.161 | DEBUG    | __main__:<module>:313 - Training step 15100: loss = 3.1109 | 3023.23ms | Tokens/s = 173,419.9
2025-01-17 19:40:38.411 | DEBUG    | __main__:<module>:313 - Training step 15110: loss = 2.9878 | 3026.60ms | Tokens/s = 173,226.8
2025-01-17 19:41:08.675 | DEBUG    | __main__:<module>:313 - Training step 15120: loss = 3.2451 | 3026.06ms | Tokens/s = 173,257.5
2025-01-17 19:41:38.909 | DEBUG    | __main__:<module>:313 - Training step 15130: loss = 3.1168 | 3020.94ms | Tokens/s = 173,551.4
2025-01-17 19:42:09.120 | DEBUG    | __main__:<module>:313 - Training step 15140: loss = 3.0308 | 3020.69ms | Tokens/s = 173,565.5
2025-01-17 19:42:39.347 | DEBUG    | __main__:<module>:313 - Training step 15150: loss = 2.8858 | 3024.67ms | Tokens/s = 173,337.5
2025-01-17 19:43:09.585 | DEBUG    | __main__:<module>:313 - Training step 15160: loss = 3.0931 | 3026.51ms | Tokens/s = 173,232.1
2025-01-17 19:43:39.833 | DEBUG    | __main__:<module>:313 - Training step 15170: loss = 2.9847 | 3025.55ms | Tokens/s = 173,286.8
2025-01-17 19:44:10.097 | DEBUG    | __main__:<module>:313 - Training step 15180: loss = 3.1798 | 3026.33ms | Tokens/s = 173,242.4
2025-01-17 19:44:40.356 | DEBUG    | __main__:<module>:313 - Training step 15190: loss = 3.1418 | 3024.04ms | Tokens/s = 173,373.3
2025-01-17 19:45:10.583 | DEBUG    | __main__:<module>:313 - Training step 15200: loss = 3.2472 | 3019.90ms | Tokens/s = 173,611.2
2025-01-17 19:45:40.780 | DEBUG    | __main__:<module>:313 - Training step 15210: loss = 2.9275 | 3019.14ms | Tokens/s = 173,654.5
2025-01-17 19:46:10.988 | DEBUG    | __main__:<module>:313 - Training step 15220: loss = 3.0593 | 3023.40ms | Tokens/s = 173,410.1
2025-01-17 19:46:41.221 | DEBUG    | __main__:<module>:313 - Training step 15230: loss = 3.0981 | 3023.47ms | Tokens/s = 173,406.2
2025-01-17 19:47:11.465 | DEBUG    | __main__:<module>:313 - Training step 15240: loss = 3.1794 | 3025.73ms | Tokens/s = 173,276.3
2025-01-17 19:47:41.705 | DEBUG    | __main__:<module>:313 - Training step 15250: loss = 3.2387 | 3021.44ms | Tokens/s = 173,522.7
2025-01-17 19:48:11.913 | DEBUG    | __main__:<module>:313 - Training step 15260: loss = 3.0660 | 3016.54ms | Tokens/s = 173,804.4
2025-01-17 19:48:42.096 | DEBUG    | __main__:<module>:313 - Training step 15270: loss = 3.0736 | 3019.28ms | Tokens/s = 173,646.4
2025-01-17 19:49:12.280 | DEBUG    | __main__:<module>:313 - Training step 15280: loss = 3.0317 | 3019.68ms | Tokens/s = 173,623.5
2025-01-17 19:49:42.497 | DEBUG    | __main__:<module>:313 - Training step 15290: loss = 2.9746 | 3020.11ms | Tokens/s = 173,599.0
2025-01-17 19:50:12.722 | DEBUG    | __main__:<module>:313 - Training step 15300: loss = 3.0951 | 3023.73ms | Tokens/s = 173,391.1
2025-01-17 19:50:42.936 | DEBUG    | __main__:<module>:313 - Training step 15310: loss = 3.0948 | 3021.26ms | Tokens/s = 173,532.7
2025-01-17 19:51:13.135 | DEBUG    | __main__:<module>:313 - Training step 15320: loss = 2.9801 | 3018.80ms | Tokens/s = 173,674.5
2025-01-17 19:51:43.360 | DEBUG    | __main__:<module>:313 - Training step 15330: loss = 3.1897 | 3024.55ms | Tokens/s = 173,344.4
2025-01-17 19:52:13.601 | DEBUG    | __main__:<module>:313 - Training step 15340: loss = 3.1611 | 3023.66ms | Tokens/s = 173,395.0
2025-01-17 19:52:43.830 | DEBUG    | __main__:<module>:313 - Training step 15350: loss = 3.1523 | 3022.23ms | Tokens/s = 173,477.1
2025-01-17 19:53:14.019 | DEBUG    | __main__:<module>:313 - Training step 15360: loss = 3.0329 | 3016.51ms | Tokens/s = 173,806.3
2025-01-17 19:53:44.224 | DEBUG    | __main__:<module>:313 - Training step 15370: loss = 3.1213 | 3019.78ms | Tokens/s = 173,618.2
2025-01-17 19:54:14.442 | DEBUG    | __main__:<module>:313 - Training step 15380: loss = 3.0399 | 3022.48ms | Tokens/s = 173,462.9
2025-01-17 19:54:44.671 | DEBUG    | __main__:<module>:313 - Training step 15390: loss = 3.1403 | 3024.01ms | Tokens/s = 173,374.9
2025-01-17 19:55:14.924 | DEBUG    | __main__:<module>:313 - Training step 15400: loss = 3.0468 | 3024.43ms | Tokens/s = 173,351.2
2025-01-17 19:55:45.179 | DEBUG    | __main__:<module>:313 - Training step 15410: loss = 3.0185 | 3025.21ms | Tokens/s = 173,306.1
2025-01-17 19:56:15.406 | DEBUG    | __main__:<module>:313 - Training step 15420: loss = 2.9102 | 3023.64ms | Tokens/s = 173,396.5
2025-01-17 19:56:45.653 | DEBUG    | __main__:<module>:313 - Training step 15430: loss = 3.1056 | 3027.54ms | Tokens/s = 173,173.2
2025-01-17 19:57:15.885 | DEBUG    | __main__:<module>:313 - Training step 15440: loss = 3.1895 | 3021.67ms | Tokens/s = 173,509.2
2025-01-17 19:57:46.101 | DEBUG    | __main__:<module>:313 - Training step 15450: loss = 3.1921 | 3023.17ms | Tokens/s = 173,423.2
2025-01-17 19:58:16.340 | DEBUG    | __main__:<module>:313 - Training step 15460: loss = 3.1156 | 3022.73ms | Tokens/s = 173,448.3
2025-01-17 19:58:46.560 | DEBUG    | __main__:<module>:313 - Training step 15470: loss = 3.1317 | 3021.83ms | Tokens/s = 173,500.0
2025-01-17 19:59:16.758 | DEBUG    | __main__:<module>:313 - Training step 15480: loss = 3.0952 | 3022.47ms | Tokens/s = 173,463.6
2025-01-17 19:59:46.995 | DEBUG    | __main__:<module>:313 - Training step 15490: loss = 3.1467 | 3023.72ms | Tokens/s = 173,391.6
2025-01-17 20:00:17.252 | DEBUG    | __main__:<module>:313 - Training step 15500: loss = 3.1894 | 3023.50ms | Tokens/s = 173,404.2
2025-01-17 20:00:47.498 | DEBUG    | __main__:<module>:313 - Training step 15510: loss = 3.0948 | 3023.21ms | Tokens/s = 173,420.9
2025-01-17 20:01:17.751 | DEBUG    | __main__:<module>:313 - Training step 15520: loss = 3.1738 | 3024.90ms | Tokens/s = 173,324.1
2025-01-17 20:01:47.994 | DEBUG    | __main__:<module>:313 - Training step 15530: loss = 2.9901 | 3021.86ms | Tokens/s = 173,498.5
2025-01-17 20:02:18.215 | DEBUG    | __main__:<module>:313 - Training step 15540: loss = 3.2965 | 3022.42ms | Tokens/s = 173,466.0
2025-01-17 20:02:48.433 | DEBUG    | __main__:<module>:313 - Training step 15550: loss = 3.1119 | 3022.72ms | Tokens/s = 173,449.3
2025-01-17 20:03:18.680 | DEBUG    | __main__:<module>:313 - Training step 15560: loss = 3.2556 | 3025.07ms | Tokens/s = 173,314.1
2025-01-17 20:03:48.952 | DEBUG    | __main__:<module>:313 - Training step 15570: loss = 3.1625 | 3027.32ms | Tokens/s = 173,185.3
2025-01-17 20:04:19.191 | DEBUG    | __main__:<module>:313 - Training step 15580: loss = 2.9407 | 3024.80ms | Tokens/s = 173,329.9
2025-01-17 20:04:49.438 | DEBUG    | __main__:<module>:313 - Training step 15590: loss = 3.0067 | 3025.26ms | Tokens/s = 173,303.3
2025-01-17 20:05:19.715 | DEBUG    | __main__:<module>:313 - Training step 15600: loss = 2.9197 | 3025.41ms | Tokens/s = 173,294.8
2025-01-17 20:05:49.964 | DEBUG    | __main__:<module>:313 - Training step 15610: loss = 2.9123 | 3023.83ms | Tokens/s = 173,385.6
2025-01-17 20:06:20.187 | DEBUG    | __main__:<module>:313 - Training step 15620: loss = 3.1238 | 3020.06ms | Tokens/s = 173,601.6
2025-01-17 20:06:50.389 | DEBUG    | __main__:<module>:313 - Training step 15630: loss = 2.9260 | 3017.40ms | Tokens/s = 173,754.8
2025-01-17 20:07:20.612 | DEBUG    | __main__:<module>:313 - Training step 15640: loss = 3.1030 | 3022.59ms | Tokens/s = 173,456.6
2025-01-17 20:07:50.876 | DEBUG    | __main__:<module>:313 - Training step 15650: loss = 3.1069 | 3027.96ms | Tokens/s = 173,149.1
2025-01-17 20:08:21.143 | DEBUG    | __main__:<module>:313 - Training step 15660: loss = 3.1048 | 3027.38ms | Tokens/s = 173,182.3
2025-01-17 20:08:51.374 | DEBUG    | __main__:<module>:313 - Training step 15670: loss = 3.0612 | 3022.35ms | Tokens/s = 173,470.3
2025-01-17 20:09:21.577 | DEBUG    | __main__:<module>:313 - Training step 15680: loss = 2.9280 | 3019.06ms | Tokens/s = 173,659.5
2025-01-17 20:09:51.793 | DEBUG    | __main__:<module>:313 - Training step 15690: loss = 3.0720 | 3022.51ms | Tokens/s = 173,461.4
2025-01-17 20:10:22.010 | DEBUG    | __main__:<module>:313 - Training step 15700: loss = 2.9579 | 3018.49ms | Tokens/s = 173,692.1
2025-01-17 20:10:52.241 | DEBUG    | __main__:<module>:313 - Training step 15710: loss = 2.9702 | 3024.72ms | Tokens/s = 173,334.3
2025-01-17 20:11:22.481 | DEBUG    | __main__:<module>:313 - Training step 15720: loss = 3.0577 | 3022.54ms | Tokens/s = 173,459.6
2025-01-17 20:11:52.732 | DEBUG    | __main__:<module>:313 - Training step 15730: loss = 3.0351 | 3024.61ms | Tokens/s = 173,340.5
2025-01-17 20:12:22.961 | DEBUG    | __main__:<module>:313 - Training step 15740: loss = 3.1330 | 3021.53ms | Tokens/s = 173,517.7
2025-01-17 20:12:53.168 | DEBUG    | __main__:<module>:313 - Training step 15750: loss = 3.0391 | 3021.03ms | Tokens/s = 173,546.0
2025-01-17 20:13:23.391 | DEBUG    | __main__:<module>:313 - Training step 15760: loss = 3.0000 | 3023.42ms | Tokens/s = 173,409.0
2025-01-17 20:13:53.631 | DEBUG    | __main__:<module>:313 - Training step 15770: loss = 3.0885 | 3025.70ms | Tokens/s = 173,278.3
2025-01-17 20:14:23.876 | DEBUG    | __main__:<module>:313 - Training step 15780: loss = 3.1416 | 3022.71ms | Tokens/s = 173,449.6
2025-01-17 20:14:54.083 | DEBUG    | __main__:<module>:313 - Training step 15790: loss = 3.0458 | 3019.30ms | Tokens/s = 173,645.6
2025-01-17 20:15:24.300 | DEBUG    | __main__:<module>:313 - Training step 15800: loss = 3.0215 | 3022.84ms | Tokens/s = 173,442.0
2025-01-17 20:15:54.540 | DEBUG    | __main__:<module>:313 - Training step 15810: loss = 3.0352 | 3024.24ms | Tokens/s = 173,361.8
2025-01-17 20:16:24.794 | DEBUG    | __main__:<module>:313 - Training step 15820: loss = 3.0095 | 3024.95ms | Tokens/s = 173,321.3
2025-01-17 20:16:55.016 | DEBUG    | __main__:<module>:313 - Training step 15830: loss = 3.1184 | 3020.34ms | Tokens/s = 173,585.5
2025-01-17 20:17:25.216 | DEBUG    | __main__:<module>:313 - Training step 15840: loss = 3.2001 | 3021.84ms | Tokens/s = 173,499.7
2025-01-17 20:17:55.420 | DEBUG    | __main__:<module>:313 - Training step 15850: loss = 3.0231 | 3020.77ms | Tokens/s = 173,560.9
2025-01-17 20:18:25.648 | DEBUG    | __main__:<module>:313 - Training step 15860: loss = 3.2530 | 3024.27ms | Tokens/s = 173,360.1
2025-01-17 20:18:55.894 | DEBUG    | __main__:<module>:313 - Training step 15870: loss = 3.1372 | 3024.61ms | Tokens/s = 173,340.5
2025-01-17 20:19:26.155 | DEBUG    | __main__:<module>:313 - Training step 15880: loss = 2.9260 | 3025.02ms | Tokens/s = 173,317.1
2025-01-17 20:19:56.416 | DEBUG    | __main__:<module>:313 - Training step 15890: loss = 2.9639 | 3025.54ms | Tokens/s = 173,287.3
2025-01-17 20:20:26.682 | DEBUG    | __main__:<module>:313 - Training step 15900: loss = 3.2404 | 3023.53ms | Tokens/s = 173,402.8
2025-01-17 20:20:56.918 | DEBUG    | __main__:<module>:313 - Training step 15910: loss = 3.0157 | 3023.48ms | Tokens/s = 173,405.2
2025-01-17 20:21:27.120 | DEBUG    | __main__:<module>:313 - Training step 15920: loss = 3.0433 | 3015.70ms | Tokens/s = 173,852.8
2025-01-17 20:21:57.326 | DEBUG    | __main__:<module>:313 - Training step 15930: loss = 3.2215 | 3021.88ms | Tokens/s = 173,497.5
2025-01-17 20:22:27.553 | DEBUG    | __main__:<module>:313 - Training step 15940: loss = 3.1292 | 3020.18ms | Tokens/s = 173,594.7
2025-01-17 20:22:57.789 | DEBUG    | __main__:<module>:313 - Training step 15950: loss = 2.8999 | 3024.65ms | Tokens/s = 173,338.4
2025-01-17 20:23:28.033 | DEBUG    | __main__:<module>:313 - Training step 15960: loss = 3.0732 | 3025.04ms | Tokens/s = 173,315.9
2025-01-17 20:23:58.284 | DEBUG    | __main__:<module>:313 - Training step 15970: loss = 3.0012 | 3025.69ms | Tokens/s = 173,279.0
2025-01-17 20:24:28.552 | DEBUG    | __main__:<module>:313 - Training step 15980: loss = 3.0748 | 3027.14ms | Tokens/s = 173,195.6
2025-01-17 20:24:58.813 | DEBUG    | __main__:<module>:313 - Training step 15990: loss = 3.0574 | 3024.20ms | Tokens/s = 173,364.1
2025-01-17 20:25:32.467 | INFO     | __main__:<module>:265 - Step 16,000/20,000 loss: 3.0722 (T) 3.0893 (V) | lr=1.2e-03
2025-01-17 20:25:32.469 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 20:25:49.217 | DEBUG    | __main__:<module>:313 - Training step 16000: loss = 3.1821 | 23197.90ms | Tokens/s = 22,600.7
2025-01-17 20:26:19.285 | DEBUG    | __main__:<module>:313 - Training step 16010: loss = 3.1640 | 3009.17ms | Tokens/s = 174,230.1
2025-01-17 20:26:49.449 | DEBUG    | __main__:<module>:313 - Training step 16020: loss = 3.0832 | 3017.34ms | Tokens/s = 173,758.4
2025-01-17 20:27:19.658 | DEBUG    | __main__:<module>:313 - Training step 16030: loss = 3.0340 | 3022.82ms | Tokens/s = 173,443.2
2025-01-17 20:27:49.887 | DEBUG    | __main__:<module>:313 - Training step 16040: loss = 3.0706 | 3022.55ms | Tokens/s = 173,459.0
2025-01-17 20:28:20.143 | DEBUG    | __main__:<module>:313 - Training step 16050: loss = 3.1822 | 3026.42ms | Tokens/s = 173,236.8
2025-01-17 20:28:50.403 | DEBUG    | __main__:<module>:313 - Training step 16060: loss = 3.1327 | 3026.36ms | Tokens/s = 173,240.4
2025-01-17 20:29:20.655 | DEBUG    | __main__:<module>:313 - Training step 16070: loss = 3.0625 | 3023.85ms | Tokens/s = 173,384.3
2025-01-17 20:29:50.878 | DEBUG    | __main__:<module>:313 - Training step 16080: loss = 3.1553 | 3021.86ms | Tokens/s = 173,498.4
2025-01-17 20:30:21.122 | DEBUG    | __main__:<module>:313 - Training step 16090: loss = 3.2486 | 3024.24ms | Tokens/s = 173,362.1
2025-01-17 20:30:51.374 | DEBUG    | __main__:<module>:313 - Training step 16100: loss = 3.0585 | 3023.56ms | Tokens/s = 173,400.6
2025-01-17 20:31:21.625 | DEBUG    | __main__:<module>:313 - Training step 16110: loss = 3.1096 | 3021.90ms | Tokens/s = 173,496.2
2025-01-17 20:31:51.847 | DEBUG    | __main__:<module>:313 - Training step 16120: loss = 3.1231 | 3022.50ms | Tokens/s = 173,461.9
2025-01-17 20:32:22.050 | DEBUG    | __main__:<module>:313 - Training step 16130: loss = 2.9487 | 3021.19ms | Tokens/s = 173,537.1
2025-01-17 20:32:52.251 | DEBUG    | __main__:<module>:313 - Training step 16140: loss = 3.1537 | 3021.27ms | Tokens/s = 173,532.2
2025-01-17 20:33:22.471 | DEBUG    | __main__:<module>:313 - Training step 16150: loss = 2.8790 | 3023.54ms | Tokens/s = 173,402.3
2025-01-17 20:33:52.708 | DEBUG    | __main__:<module>:313 - Training step 16160: loss = 2.8413 | 3023.64ms | Tokens/s = 173,396.1
2025-01-17 20:34:22.923 | DEBUG    | __main__:<module>:313 - Training step 16170: loss = 3.0142 | 3023.12ms | Tokens/s = 173,426.4
2025-01-17 20:34:53.124 | DEBUG    | __main__:<module>:313 - Training step 16180: loss = 2.8576 | 3019.55ms | Tokens/s = 173,631.0
2025-01-17 20:35:23.335 | DEBUG    | __main__:<module>:313 - Training step 16190: loss = 3.1402 | 3025.80ms | Tokens/s = 173,272.6
2025-01-17 20:35:53.577 | DEBUG    | __main__:<module>:313 - Training step 16200: loss = 3.1176 | 3023.91ms | Tokens/s = 173,380.6
2025-01-17 20:36:23.832 | DEBUG    | __main__:<module>:313 - Training step 16210: loss = 3.0512 | 3028.11ms | Tokens/s = 173,140.6
2025-01-17 20:36:54.092 | DEBUG    | __main__:<module>:313 - Training step 16220: loss = 3.0837 | 3026.84ms | Tokens/s = 173,213.0
2025-01-17 20:37:24.361 | DEBUG    | __main__:<module>:313 - Training step 16230: loss = 3.0444 | 3025.98ms | Tokens/s = 173,262.0
2025-01-17 20:37:54.604 | DEBUG    | __main__:<module>:313 - Training step 16240: loss = 3.0009 | 3022.10ms | Tokens/s = 173,484.6
2025-01-17 20:38:24.818 | DEBUG    | __main__:<module>:313 - Training step 16250: loss = 3.1064 | 3022.35ms | Tokens/s = 173,470.2
2025-01-17 20:38:55.051 | DEBUG    | __main__:<module>:313 - Training step 16260: loss = 3.1233 | 3023.89ms | Tokens/s = 173,382.2
2025-01-17 20:39:25.298 | DEBUG    | __main__:<module>:313 - Training step 16270: loss = 2.9808 | 3024.02ms | Tokens/s = 173,374.7
2025-01-17 20:39:55.527 | DEBUG    | __main__:<module>:313 - Training step 16280: loss = 2.9957 | 3020.16ms | Tokens/s = 173,595.8
2025-01-17 20:40:25.733 | DEBUG    | __main__:<module>:313 - Training step 16290: loss = 3.1259 | 3018.92ms | Tokens/s = 173,667.4
2025-01-17 20:40:55.962 | DEBUG    | __main__:<module>:313 - Training step 16300: loss = 3.0172 | 3022.36ms | Tokens/s = 173,470.0
2025-01-17 20:41:26.205 | DEBUG    | __main__:<module>:313 - Training step 16310: loss = 3.1385 | 3025.33ms | Tokens/s = 173,299.3
2025-01-17 20:41:56.467 | DEBUG    | __main__:<module>:313 - Training step 16320: loss = 3.0786 | 3024.25ms | Tokens/s = 173,361.5
2025-01-17 20:42:26.727 | DEBUG    | __main__:<module>:313 - Training step 16330: loss = 3.1128 | 3025.31ms | Tokens/s = 173,300.7
2025-01-17 20:42:56.968 | DEBUG    | __main__:<module>:313 - Training step 16340: loss = 2.9472 | 3023.21ms | Tokens/s = 173,421.1
2025-01-17 20:43:27.184 | DEBUG    | __main__:<module>:313 - Training step 16350: loss = 3.0445 | 3020.19ms | Tokens/s = 173,594.5
2025-01-17 20:43:57.387 | DEBUG    | __main__:<module>:313 - Training step 16360: loss = 3.1937 | 3021.02ms | Tokens/s = 173,546.7
2025-01-17 20:44:27.620 | DEBUG    | __main__:<module>:313 - Training step 16370: loss = 2.8156 | 3023.73ms | Tokens/s = 173,391.1
2025-01-17 20:44:57.872 | DEBUG    | __main__:<module>:313 - Training step 16380: loss = 2.8291 | 3022.05ms | Tokens/s = 173,487.3
2025-01-17 20:45:28.096 | DEBUG    | __main__:<module>:313 - Training step 16390: loss = 3.0453 | 3022.05ms | Tokens/s = 173,487.8
2025-01-17 20:45:58.297 | DEBUG    | __main__:<module>:313 - Training step 16400: loss = 2.9279 | 3019.08ms | Tokens/s = 173,658.3
2025-01-17 20:46:28.512 | DEBUG    | __main__:<module>:313 - Training step 16410: loss = 3.0662 | 3024.58ms | Tokens/s = 173,342.2
2025-01-17 20:46:58.762 | DEBUG    | __main__:<module>:313 - Training step 16420: loss = 2.9536 | 3026.75ms | Tokens/s = 173,218.3
2025-01-17 20:47:29.005 | DEBUG    | __main__:<module>:313 - Training step 16430: loss = 3.2223 | 3023.69ms | Tokens/s = 173,393.5
2025-01-17 20:47:59.223 | DEBUG    | __main__:<module>:313 - Training step 16440: loss = 2.9729 | 3021.77ms | Tokens/s = 173,503.6
2025-01-17 20:48:29.425 | DEBUG    | __main__:<module>:313 - Training step 16450: loss = 3.1076 | 3018.13ms | Tokens/s = 173,712.9
2025-01-17 20:48:59.612 | DEBUG    | __main__:<module>:313 - Training step 16460: loss = 2.9200 | 3020.41ms | Tokens/s = 173,581.5
2025-01-17 20:49:29.842 | DEBUG    | __main__:<module>:313 - Training step 16470: loss = 3.2329 | 3025.67ms | Tokens/s = 173,280.2
2025-01-17 20:50:00.102 | DEBUG    | __main__:<module>:313 - Training step 16480: loss = 2.9935 | 3028.46ms | Tokens/s = 173,120.3
2025-01-17 20:50:30.359 | DEBUG    | __main__:<module>:313 - Training step 16490: loss = 2.9590 | 3024.49ms | Tokens/s = 173,347.4
2025-01-17 20:51:00.577 | DEBUG    | __main__:<module>:313 - Training step 16500: loss = 3.1367 | 3018.57ms | Tokens/s = 173,687.4
2025-01-17 20:51:30.809 | DEBUG    | __main__:<module>:313 - Training step 16510: loss = 2.9587 | 3023.31ms | Tokens/s = 173,415.0
2025-01-17 20:52:01.028 | DEBUG    | __main__:<module>:313 - Training step 16520: loss = 3.0483 | 3020.28ms | Tokens/s = 173,589.4
2025-01-17 20:52:31.225 | DEBUG    | __main__:<module>:313 - Training step 16530: loss = 3.0912 | 3020.34ms | Tokens/s = 173,585.8
2025-01-17 20:53:01.439 | DEBUG    | __main__:<module>:313 - Training step 16540: loss = 2.9649 | 3023.04ms | Tokens/s = 173,431.0
2025-01-17 20:53:31.651 | DEBUG    | __main__:<module>:313 - Training step 16550: loss = 2.8975 | 3022.06ms | Tokens/s = 173,487.0
2025-01-17 20:54:01.850 | DEBUG    | __main__:<module>:313 - Training step 16560: loss = 3.0640 | 3019.56ms | Tokens/s = 173,630.5
2025-01-17 20:54:32.062 | DEBUG    | __main__:<module>:313 - Training step 16570: loss = 3.0343 | 3022.55ms | Tokens/s = 173,458.8
2025-01-17 20:55:02.294 | DEBUG    | __main__:<module>:313 - Training step 16580: loss = 3.0834 | 3024.29ms | Tokens/s = 173,358.9
2025-01-17 20:55:32.553 | DEBUG    | __main__:<module>:313 - Training step 16590: loss = 3.0605 | 3026.68ms | Tokens/s = 173,222.2
2025-01-17 20:56:02.790 | DEBUG    | __main__:<module>:313 - Training step 16600: loss = 3.0410 | 3021.81ms | Tokens/s = 173,501.3
2025-01-17 20:56:33.002 | DEBUG    | __main__:<module>:313 - Training step 16610: loss = 3.0080 | 3020.63ms | Tokens/s = 173,568.8
2025-01-17 20:57:03.218 | DEBUG    | __main__:<module>:313 - Training step 16620: loss = 3.2702 | 3023.30ms | Tokens/s = 173,415.8
2025-01-17 20:57:33.459 | DEBUG    | __main__:<module>:313 - Training step 16630: loss = 3.1511 | 3024.98ms | Tokens/s = 173,319.7
2025-01-17 20:58:03.717 | DEBUG    | __main__:<module>:313 - Training step 16640: loss = 3.0844 | 3026.10ms | Tokens/s = 173,255.3
2025-01-17 20:58:33.981 | DEBUG    | __main__:<module>:313 - Training step 16650: loss = 3.0082 | 3026.73ms | Tokens/s = 173,219.4
2025-01-17 20:59:04.226 | DEBUG    | __main__:<module>:313 - Training step 16660: loss = 3.1035 | 3023.25ms | Tokens/s = 173,419.0
2025-01-17 20:59:34.474 | DEBUG    | __main__:<module>:313 - Training step 16670: loss = 2.8350 | 3025.51ms | Tokens/s = 173,289.1
2025-01-17 21:00:04.732 | DEBUG    | __main__:<module>:313 - Training step 16680: loss = 3.0505 | 3023.75ms | Tokens/s = 173,389.9
2025-01-17 21:00:34.971 | DEBUG    | __main__:<module>:313 - Training step 16690: loss = 3.1027 | 3023.92ms | Tokens/s = 173,380.1
2025-01-17 21:01:05.225 | DEBUG    | __main__:<module>:313 - Training step 16700: loss = 3.0534 | 3025.64ms | Tokens/s = 173,281.7
2025-01-17 21:01:35.492 | DEBUG    | __main__:<module>:313 - Training step 16710: loss = 3.2499 | 3025.34ms | Tokens/s = 173,298.9
2025-01-17 21:02:05.719 | DEBUG    | __main__:<module>:313 - Training step 16720: loss = 2.9799 | 3020.78ms | Tokens/s = 173,560.4
2025-01-17 21:02:35.918 | DEBUG    | __main__:<module>:313 - Training step 16730: loss = 3.0540 | 3020.34ms | Tokens/s = 173,585.6
2025-01-17 21:03:06.135 | DEBUG    | __main__:<module>:313 - Training step 16740: loss = 2.9568 | 3022.31ms | Tokens/s = 173,472.9
2025-01-17 21:03:36.378 | DEBUG    | __main__:<module>:313 - Training step 16750: loss = 3.0342 | 3023.26ms | Tokens/s = 173,418.2
2025-01-17 21:04:06.605 | DEBUG    | __main__:<module>:313 - Training step 16760: loss = 3.0796 | 3021.01ms | Tokens/s = 173,547.4
2025-01-17 21:04:36.838 | DEBUG    | __main__:<module>:313 - Training step 16770: loss = 2.9909 | 3022.69ms | Tokens/s = 173,450.8
2025-01-17 21:05:07.049 | DEBUG    | __main__:<module>:313 - Training step 16780: loss = 2.8696 | 3019.80ms | Tokens/s = 173,616.8
2025-01-17 21:05:37.258 | DEBUG    | __main__:<module>:313 - Training step 16790: loss = 2.9972 | 3022.52ms | Tokens/s = 173,460.5
2025-01-17 21:06:07.502 | DEBUG    | __main__:<module>:313 - Training step 16800: loss = 3.0474 | 3024.65ms | Tokens/s = 173,338.6
2025-01-17 21:06:37.744 | DEBUG    | __main__:<module>:313 - Training step 16810: loss = 2.9196 | 3023.07ms | Tokens/s = 173,429.0
2025-01-17 21:07:07.964 | DEBUG    | __main__:<module>:313 - Training step 16820: loss = 2.9047 | 3019.15ms | Tokens/s = 173,654.0
2025-01-17 21:07:38.167 | DEBUG    | __main__:<module>:313 - Training step 16830: loss = 2.9553 | 3021.10ms | Tokens/s = 173,542.2
2025-01-17 21:08:08.400 | DEBUG    | __main__:<module>:313 - Training step 16840: loss = 3.1716 | 3023.10ms | Tokens/s = 173,427.2
2025-01-17 21:08:38.610 | DEBUG    | __main__:<module>:313 - Training step 16850: loss = 3.0768 | 3019.93ms | Tokens/s = 173,609.3
2025-01-17 21:09:08.807 | DEBUG    | __main__:<module>:313 - Training step 16860: loss = 3.1558 | 3020.93ms | Tokens/s = 173,551.6
2025-01-17 21:09:38.988 | DEBUG    | __main__:<module>:313 - Training step 16870: loss = 3.0084 | 3019.80ms | Tokens/s = 173,616.9
2025-01-17 21:10:09.196 | DEBUG    | __main__:<module>:313 - Training step 16880: loss = 2.9253 | 3024.95ms | Tokens/s = 173,321.0
2025-01-17 21:10:39.425 | DEBUG    | __main__:<module>:313 - Training step 16890: loss = 2.9971 | 3023.71ms | Tokens/s = 173,392.1
2025-01-17 21:11:09.675 | DEBUG    | __main__:<module>:313 - Training step 16900: loss = 2.8962 | 3021.91ms | Tokens/s = 173,495.8
2025-01-17 21:11:39.905 | DEBUG    | __main__:<module>:313 - Training step 16910: loss = 3.2074 | 3022.45ms | Tokens/s = 173,464.5
2025-01-17 21:12:10.106 | DEBUG    | __main__:<module>:313 - Training step 16920: loss = 2.8903 | 3018.95ms | Tokens/s = 173,665.9
2025-01-17 21:12:40.304 | DEBUG    | __main__:<module>:313 - Training step 16930: loss = 3.1293 | 3018.79ms | Tokens/s = 173,674.7
2025-01-17 21:13:10.516 | DEBUG    | __main__:<module>:313 - Training step 16940: loss = 2.9665 | 3022.25ms | Tokens/s = 173,475.9
2025-01-17 21:13:40.760 | DEBUG    | __main__:<module>:313 - Training step 16950: loss = 2.8767 | 3024.91ms | Tokens/s = 173,323.4
2025-01-17 21:14:11.011 | DEBUG    | __main__:<module>:313 - Training step 16960: loss = 3.0033 | 3023.30ms | Tokens/s = 173,415.6
2025-01-17 21:14:41.242 | DEBUG    | __main__:<module>:313 - Training step 16970: loss = 2.9716 | 3022.95ms | Tokens/s = 173,435.9
2025-01-17 21:15:11.479 | DEBUG    | __main__:<module>:313 - Training step 16980: loss = 2.9933 | 3025.38ms | Tokens/s = 173,296.8
2025-01-17 21:15:41.738 | DEBUG    | __main__:<module>:313 - Training step 16990: loss = 3.0462 | 3024.25ms | Tokens/s = 173,361.5
2025-01-17 21:16:15.405 | INFO     | __main__:<module>:265 - Step 17,000/20,000 loss: 3.0424 (T) 3.0352 (V) | lr=6.7e-04
2025-01-17 21:16:15.407 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 21:16:28.725 | DEBUG    | __main__:<module>:313 - Training step 17000: loss = 3.0003 | 19777.62ms | Tokens/s = 26,509.2
2025-01-17 21:16:58.823 | DEBUG    | __main__:<module>:313 - Training step 17010: loss = 3.1490 | 3015.47ms | Tokens/s = 173,866.2
2025-01-17 21:17:29.005 | DEBUG    | __main__:<module>:313 - Training step 17020: loss = 3.0644 | 3022.43ms | Tokens/s = 173,465.5
2025-01-17 21:17:59.221 | DEBUG    | __main__:<module>:313 - Training step 17030: loss = 3.2490 | 3022.17ms | Tokens/s = 173,480.9
2025-01-17 21:18:29.452 | DEBUG    | __main__:<module>:313 - Training step 17040: loss = 3.0271 | 3020.61ms | Tokens/s = 173,570.4
2025-01-17 21:18:59.669 | DEBUG    | __main__:<module>:313 - Training step 17050: loss = 3.2574 | 3021.42ms | Tokens/s = 173,523.9
2025-01-17 21:19:29.894 | DEBUG    | __main__:<module>:313 - Training step 17060: loss = 3.1091 | 3022.45ms | Tokens/s = 173,464.4
2025-01-17 21:20:00.151 | DEBUG    | __main__:<module>:313 - Training step 17070: loss = 2.8871 | 3027.08ms | Tokens/s = 173,199.0
2025-01-17 21:20:30.414 | DEBUG    | __main__:<module>:313 - Training step 17080: loss = 2.9289 | 3027.10ms | Tokens/s = 173,198.1
2025-01-17 21:21:00.667 | DEBUG    | __main__:<module>:313 - Training step 17090: loss = 3.0111 | 3024.38ms | Tokens/s = 173,354.0
2025-01-17 21:21:30.887 | DEBUG    | __main__:<module>:313 - Training step 17100: loss = 3.0082 | 3018.02ms | Tokens/s = 173,719.2
2025-01-17 21:22:01.088 | DEBUG    | __main__:<module>:313 - Training step 17110: loss = 2.9437 | 3019.92ms | Tokens/s = 173,609.8
2025-01-17 21:22:31.290 | DEBUG    | __main__:<module>:313 - Training step 17120: loss = 2.9522 | 3021.38ms | Tokens/s = 173,525.8
2025-01-17 21:23:01.519 | DEBUG    | __main__:<module>:313 - Training step 17130: loss = 2.9124 | 3023.05ms | Tokens/s = 173,430.4
2025-01-17 21:23:31.752 | DEBUG    | __main__:<module>:313 - Training step 17140: loss = 3.1677 | 3021.26ms | Tokens/s = 173,533.1
2025-01-17 21:24:01.959 | DEBUG    | __main__:<module>:313 - Training step 17150: loss = 2.9784 | 3020.87ms | Tokens/s = 173,555.1
2025-01-17 21:24:32.173 | DEBUG    | __main__:<module>:313 - Training step 17160: loss = 2.9617 | 3022.42ms | Tokens/s = 173,466.3
2025-01-17 21:25:02.417 | DEBUG    | __main__:<module>:313 - Training step 17170: loss = 2.9894 | 3023.95ms | Tokens/s = 173,378.4
2025-01-17 21:25:32.650 | DEBUG    | __main__:<module>:313 - Training step 17180: loss = 2.9924 | 3022.24ms | Tokens/s = 173,476.5
2025-01-17 21:26:02.867 | DEBUG    | __main__:<module>:313 - Training step 17190: loss = 2.9820 | 3018.11ms | Tokens/s = 173,713.9
2025-01-17 21:26:33.083 | DEBUG    | __main__:<module>:313 - Training step 17200: loss = 3.1866 | 3021.77ms | Tokens/s = 173,503.5
2025-01-17 21:27:03.332 | DEBUG    | __main__:<module>:313 - Training step 17210: loss = 3.0969 | 3025.41ms | Tokens/s = 173,294.6
2025-01-17 21:27:33.556 | DEBUG    | __main__:<module>:313 - Training step 17220: loss = 3.0451 | 3019.66ms | Tokens/s = 173,624.6
2025-01-17 21:28:03.777 | DEBUG    | __main__:<module>:313 - Training step 17230: loss = 3.1875 | 3022.20ms | Tokens/s = 173,479.0
2025-01-17 21:28:34.031 | DEBUG    | __main__:<module>:313 - Training step 17240: loss = 3.0437 | 3027.33ms | Tokens/s = 173,184.9
2025-01-17 21:29:04.279 | DEBUG    | __main__:<module>:313 - Training step 17250: loss = 2.9163 | 3022.62ms | Tokens/s = 173,455.0
2025-01-17 21:29:34.504 | DEBUG    | __main__:<module>:313 - Training step 17260: loss = 2.9013 | 3021.90ms | Tokens/s = 173,495.9
2025-01-17 21:30:04.743 | DEBUG    | __main__:<module>:313 - Training step 17270: loss = 3.0622 | 3025.88ms | Tokens/s = 173,267.9
2025-01-17 21:30:35.001 | DEBUG    | __main__:<module>:313 - Training step 17280: loss = 2.9721 | 3025.97ms | Tokens/s = 173,263.0
2025-01-17 21:31:05.233 | DEBUG    | __main__:<module>:313 - Training step 17290: loss = 3.0741 | 3022.14ms | Tokens/s = 173,482.3
2025-01-17 21:31:35.451 | DEBUG    | __main__:<module>:313 - Training step 17300: loss = 2.9420 | 3022.42ms | Tokens/s = 173,466.4
2025-01-17 21:32:05.690 | DEBUG    | __main__:<module>:313 - Training step 17310: loss = 2.9518 | 3023.49ms | Tokens/s = 173,404.6
2025-01-17 21:32:35.918 | DEBUG    | __main__:<module>:313 - Training step 17320: loss = 2.9891 | 3022.59ms | Tokens/s = 173,456.7
2025-01-17 21:33:06.130 | DEBUG    | __main__:<module>:313 - Training step 17330: loss = 2.8459 | 3022.65ms | Tokens/s = 173,453.2
2025-01-17 21:33:36.342 | DEBUG    | __main__:<module>:313 - Training step 17340: loss = 2.9433 | 3021.68ms | Tokens/s = 173,508.5
2025-01-17 21:34:06.564 | DEBUG    | __main__:<module>:313 - Training step 17350: loss = 3.0623 | 3021.25ms | Tokens/s = 173,533.4
2025-01-17 21:34:36.757 | DEBUG    | __main__:<module>:313 - Training step 17360: loss = 3.0447 | 3018.01ms | Tokens/s = 173,719.7
2025-01-17 21:35:06.944 | DEBUG    | __main__:<module>:313 - Training step 17370: loss = 3.0351 | 3019.25ms | Tokens/s = 173,648.3
2025-01-17 21:35:37.144 | DEBUG    | __main__:<module>:313 - Training step 17380: loss = 3.0275 | 3021.04ms | Tokens/s = 173,545.6
2025-01-17 21:36:07.370 | DEBUG    | __main__:<module>:313 - Training step 17390: loss = 2.9015 | 3023.94ms | Tokens/s = 173,379.2
2025-01-17 21:36:37.612 | DEBUG    | __main__:<module>:313 - Training step 17400: loss = 2.9225 | 3025.36ms | Tokens/s = 173,297.9
2025-01-17 21:37:07.845 | DEBUG    | __main__:<module>:313 - Training step 17410: loss = 2.8637 | 3021.68ms | Tokens/s = 173,508.8
2025-01-17 21:37:38.049 | DEBUG    | __main__:<module>:313 - Training step 17420: loss = 3.1185 | 3020.80ms | Tokens/s = 173,559.4
2025-01-17 21:38:08.248 | DEBUG    | __main__:<module>:313 - Training step 17430: loss = 2.9844 | 3018.49ms | Tokens/s = 173,691.9
2025-01-17 21:38:38.472 | DEBUG    | __main__:<module>:313 - Training step 17440: loss = 3.1120 | 3021.77ms | Tokens/s = 173,503.8
2025-01-17 21:39:08.697 | DEBUG    | __main__:<module>:313 - Training step 17450: loss = 3.0321 | 3021.93ms | Tokens/s = 173,494.2
2025-01-17 21:39:38.899 | DEBUG    | __main__:<module>:313 - Training step 17460: loss = 2.9436 | 3020.24ms | Tokens/s = 173,591.3
2025-01-17 21:40:09.108 | DEBUG    | __main__:<module>:313 - Training step 17470: loss = 3.1900 | 3022.71ms | Tokens/s = 173,449.8
2025-01-17 21:40:39.339 | DEBUG    | __main__:<module>:313 - Training step 17480: loss = 3.0346 | 3021.74ms | Tokens/s = 173,505.0
2025-01-17 21:41:09.576 | DEBUG    | __main__:<module>:313 - Training step 17490: loss = 2.8655 | 3025.67ms | Tokens/s = 173,279.8
2025-01-17 21:41:39.822 | DEBUG    | __main__:<module>:313 - Training step 17500: loss = 2.8334 | 3023.36ms | Tokens/s = 173,412.3
2025-01-17 21:42:10.043 | DEBUG    | __main__:<module>:313 - Training step 17510: loss = 2.7069 | 3021.21ms | Tokens/s = 173,536.0
2025-01-17 21:42:40.239 | DEBUG    | __main__:<module>:313 - Training step 17520: loss = 2.9897 | 3019.65ms | Tokens/s = 173,625.7
2025-01-17 21:43:10.442 | DEBUG    | __main__:<module>:313 - Training step 17530: loss = 3.0036 | 3020.80ms | Tokens/s = 173,559.4
2025-01-17 21:43:40.673 | DEBUG    | __main__:<module>:313 - Training step 17540: loss = 3.0861 | 3026.71ms | Tokens/s = 173,220.6
2025-01-17 21:44:10.921 | DEBUG    | __main__:<module>:313 - Training step 17550: loss = 3.0932 | 3022.91ms | Tokens/s = 173,437.9
2025-01-17 21:44:41.171 | DEBUG    | __main__:<module>:313 - Training step 17560: loss = 2.8214 | 3025.59ms | Tokens/s = 173,284.3
2025-01-17 21:45:11.399 | DEBUG    | __main__:<module>:313 - Training step 17570: loss = 3.0483 | 3021.49ms | Tokens/s = 173,519.6
2025-01-17 21:45:41.610 | DEBUG    | __main__:<module>:313 - Training step 17580: loss = 3.1949 | 3020.90ms | Tokens/s = 173,553.6
2025-01-17 21:46:11.828 | DEBUG    | __main__:<module>:313 - Training step 17590: loss = 3.0957 | 3023.35ms | Tokens/s = 173,412.9
2025-01-17 21:46:42.072 | DEBUG    | __main__:<module>:313 - Training step 17600: loss = 3.1360 | 3023.16ms | Tokens/s = 173,423.7
2025-01-17 21:47:12.310 | DEBUG    | __main__:<module>:313 - Training step 17610: loss = 2.9606 | 3023.03ms | Tokens/s = 173,431.5
2025-01-17 21:47:42.512 | DEBUG    | __main__:<module>:313 - Training step 17620: loss = 3.1392 | 3019.47ms | Tokens/s = 173,635.6
2025-01-17 21:48:12.735 | DEBUG    | __main__:<module>:313 - Training step 17630: loss = 2.9528 | 3023.67ms | Tokens/s = 173,394.6
2025-01-17 21:48:42.971 | DEBUG    | __main__:<module>:313 - Training step 17640: loss = 3.1880 | 3024.72ms | Tokens/s = 173,334.3
2025-01-17 21:49:13.221 | DEBUG    | __main__:<module>:313 - Training step 17650: loss = 2.9690 | 3024.95ms | Tokens/s = 173,321.0
2025-01-17 21:49:43.472 | DEBUG    | __main__:<module>:313 - Training step 17660: loss = 3.1047 | 3026.48ms | Tokens/s = 173,233.6
2025-01-17 21:50:13.729 | DEBUG    | __main__:<module>:313 - Training step 17670: loss = 3.0332 | 3025.19ms | Tokens/s = 173,307.7
2025-01-17 21:50:43.973 | DEBUG    | __main__:<module>:313 - Training step 17680: loss = 2.9850 | 3022.89ms | Tokens/s = 173,439.2
2025-01-17 21:51:14.181 | DEBUG    | __main__:<module>:313 - Training step 17690: loss = 3.0861 | 3019.57ms | Tokens/s = 173,629.9
2025-01-17 21:51:44.401 | DEBUG    | __main__:<module>:313 - Training step 17700: loss = 2.9424 | 3021.85ms | Tokens/s = 173,499.1
2025-01-17 21:52:14.643 | DEBUG    | __main__:<module>:313 - Training step 17710: loss = 2.8799 | 3025.29ms | Tokens/s = 173,301.6
2025-01-17 21:52:44.897 | DEBUG    | __main__:<module>:313 - Training step 17720: loss = 3.0505 | 3025.32ms | Tokens/s = 173,300.1
2025-01-17 21:53:15.148 | DEBUG    | __main__:<module>:313 - Training step 17730: loss = 3.0241 | 3021.38ms | Tokens/s = 173,526.0
2025-01-17 21:53:45.371 | DEBUG    | __main__:<module>:313 - Training step 17740: loss = 2.9359 | 3019.83ms | Tokens/s = 173,615.0
2025-01-17 21:54:15.568 | DEBUG    | __main__:<module>:313 - Training step 17750: loss = 3.1170 | 3019.80ms | Tokens/s = 173,617.0
2025-01-17 21:54:45.798 | DEBUG    | __main__:<module>:313 - Training step 17760: loss = 3.1648 | 3023.10ms | Tokens/s = 173,427.5
2025-01-17 21:55:16.043 | DEBUG    | __main__:<module>:313 - Training step 17770: loss = 3.0949 | 3024.57ms | Tokens/s = 173,343.2
2025-01-17 21:55:46.302 | DEBUG    | __main__:<module>:313 - Training step 17780: loss = 3.1304 | 3025.07ms | Tokens/s = 173,314.1
2025-01-17 21:56:16.539 | DEBUG    | __main__:<module>:313 - Training step 17790: loss = 3.1076 | 3025.00ms | Tokens/s = 173,318.2
2025-01-17 21:56:46.748 | DEBUG    | __main__:<module>:313 - Training step 17800: loss = 3.1010 | 3019.50ms | Tokens/s = 173,634.2
2025-01-17 21:57:16.976 | DEBUG    | __main__:<module>:313 - Training step 17810: loss = 3.2439 | 3022.83ms | Tokens/s = 173,442.5
2025-01-17 21:57:47.226 | DEBUG    | __main__:<module>:313 - Training step 17820: loss = 3.0666 | 3024.82ms | Tokens/s = 173,328.4
2025-01-17 21:58:17.449 | DEBUG    | __main__:<module>:313 - Training step 17830: loss = 3.0417 | 3020.09ms | Tokens/s = 173,600.3
2025-01-17 21:58:47.649 | DEBUG    | __main__:<module>:313 - Training step 17840: loss = 2.8712 | 3021.28ms | Tokens/s = 173,532.0
2025-01-17 21:59:17.863 | DEBUG    | __main__:<module>:313 - Training step 17850: loss = 3.1664 | 3023.42ms | Tokens/s = 173,408.8
2025-01-17 21:59:48.108 | DEBUG    | __main__:<module>:313 - Training step 17860: loss = 3.0685 | 3025.49ms | Tokens/s = 173,290.5
2025-01-17 22:00:18.373 | DEBUG    | __main__:<module>:313 - Training step 17870: loss = 2.9874 | 3027.47ms | Tokens/s = 173,176.8
2025-01-17 22:00:48.635 | DEBUG    | __main__:<module>:313 - Training step 17880: loss = 2.9702 | 3024.41ms | Tokens/s = 173,352.4
2025-01-17 22:01:18.862 | DEBUG    | __main__:<module>:313 - Training step 17890: loss = 2.8202 | 3021.35ms | Tokens/s = 173,527.7
2025-01-17 22:01:49.064 | DEBUG    | __main__:<module>:313 - Training step 17900: loss = 3.0668 | 3021.01ms | Tokens/s = 173,547.3
2025-01-17 22:02:19.273 | DEBUG    | __main__:<module>:313 - Training step 17910: loss = 3.0538 | 3020.22ms | Tokens/s = 173,592.7
2025-01-17 22:02:49.509 | DEBUG    | __main__:<module>:313 - Training step 17920: loss = 3.0103 | 3022.62ms | Tokens/s = 173,454.9
2025-01-17 22:03:19.747 | DEBUG    | __main__:<module>:313 - Training step 17930: loss = 3.0661 | 3021.93ms | Tokens/s = 173,494.6
2025-01-17 22:03:49.966 | DEBUG    | __main__:<module>:313 - Training step 17940: loss = 2.9361 | 3021.80ms | Tokens/s = 173,501.7
2025-01-17 22:04:20.169 | DEBUG    | __main__:<module>:313 - Training step 17950: loss = 2.9262 | 3019.90ms | Tokens/s = 173,610.9
2025-01-17 22:04:50.391 | DEBUG    | __main__:<module>:313 - Training step 17960: loss = 3.0608 | 3023.89ms | Tokens/s = 173,382.0
2025-01-17 22:05:20.644 | DEBUG    | __main__:<module>:313 - Training step 17970: loss = 3.1189 | 3026.53ms | Tokens/s = 173,230.8
2025-01-17 22:05:50.900 | DEBUG    | __main__:<module>:313 - Training step 17980: loss = 2.9005 | 3024.36ms | Tokens/s = 173,355.0
2025-01-17 22:06:21.138 | DEBUG    | __main__:<module>:313 - Training step 17990: loss = 2.9269 | 3023.19ms | Tokens/s = 173,422.2
2025-01-17 22:06:54.778 | INFO     | __main__:<module>:265 - Step 18,000/20,000 loss: 2.9871 (T) 2.9933 (V) | lr=3.0e-04
2025-01-17 22:06:54.780 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 22:07:08.379 | DEBUG    | __main__:<module>:313 - Training step 18000: loss = 3.0861 | 20052.47ms | Tokens/s = 26,145.8
2025-01-17 22:07:38.472 | DEBUG    | __main__:<module>:313 - Training step 18010: loss = 3.0543 | 3014.01ms | Tokens/s = 173,950.3
2025-01-17 22:08:08.660 | DEBUG    | __main__:<module>:313 - Training step 18020: loss = 2.8595 | 3020.67ms | Tokens/s = 173,566.5
2025-01-17 22:08:38.877 | DEBUG    | __main__:<module>:313 - Training step 18030: loss = 3.0799 | 3023.70ms | Tokens/s = 173,393.0
2025-01-17 22:09:09.113 | DEBUG    | __main__:<module>:313 - Training step 18040: loss = 2.8575 | 3024.78ms | Tokens/s = 173,330.9
2025-01-17 22:09:39.338 | DEBUG    | __main__:<module>:313 - Training step 18050: loss = 3.0210 | 3020.71ms | Tokens/s = 173,564.3
2025-01-17 22:10:09.556 | DEBUG    | __main__:<module>:313 - Training step 18060: loss = 3.0233 | 3022.38ms | Tokens/s = 173,468.5
2025-01-17 22:10:39.765 | DEBUG    | __main__:<module>:313 - Training step 18070: loss = 2.9789 | 3023.70ms | Tokens/s = 173,393.0
2025-01-17 22:11:10.025 | DEBUG    | __main__:<module>:313 - Training step 18080: loss = 2.9792 | 3027.52ms | Tokens/s = 173,174.0
2025-01-17 22:11:40.285 | DEBUG    | __main__:<module>:313 - Training step 18090: loss = 3.1409 | 3027.57ms | Tokens/s = 173,171.0
2025-01-17 22:12:10.557 | DEBUG    | __main__:<module>:313 - Training step 18100: loss = 2.8723 | 3024.20ms | Tokens/s = 173,364.0
2025-01-17 22:12:40.796 | DEBUG    | __main__:<module>:313 - Training step 18110: loss = 2.9257 | 3023.93ms | Tokens/s = 173,379.7
2025-01-17 22:13:11.037 | DEBUG    | __main__:<module>:313 - Training step 18120: loss = 2.8692 | 3022.86ms | Tokens/s = 173,441.3
2025-01-17 22:13:41.254 | DEBUG    | __main__:<module>:313 - Training step 18130: loss = 2.9287 | 3021.71ms | Tokens/s = 173,507.2
2025-01-17 22:14:11.460 | DEBUG    | __main__:<module>:313 - Training step 18140: loss = 3.0893 | 3019.43ms | Tokens/s = 173,638.0
2025-01-17 22:14:41.664 | DEBUG    | __main__:<module>:313 - Training step 18150: loss = 3.0386 | 3023.17ms | Tokens/s = 173,423.3
2025-01-17 22:15:11.895 | DEBUG    | __main__:<module>:313 - Training step 18160: loss = 3.1014 | 3022.90ms | Tokens/s = 173,438.7
2025-01-17 22:15:42.121 | DEBUG    | __main__:<module>:313 - Training step 18170: loss = 2.8852 | 3019.42ms | Tokens/s = 173,638.5
2025-01-17 22:16:12.356 | DEBUG    | __main__:<module>:313 - Training step 18180: loss = 3.0169 | 3026.53ms | Tokens/s = 173,230.8
2025-01-17 22:16:42.613 | DEBUG    | __main__:<module>:313 - Training step 18190: loss = 3.1483 | 3027.69ms | Tokens/s = 173,164.1
2025-01-17 22:17:12.860 | DEBUG    | __main__:<module>:313 - Training step 18200: loss = 2.8685 | 3023.07ms | Tokens/s = 173,428.8
2025-01-17 22:17:43.083 | DEBUG    | __main__:<module>:313 - Training step 18210: loss = 3.0426 | 3022.28ms | Tokens/s = 173,474.1
2025-01-17 22:18:13.293 | DEBUG    | __main__:<module>:313 - Training step 18220: loss = 2.9227 | 3021.89ms | Tokens/s = 173,496.5
2025-01-17 22:18:43.534 | DEBUG    | __main__:<module>:313 - Training step 18230: loss = 3.0577 | 3024.90ms | Tokens/s = 173,324.1
2025-01-17 22:19:13.809 | DEBUG    | __main__:<module>:313 - Training step 18240: loss = 2.7957 | 3027.67ms | Tokens/s = 173,165.3
2025-01-17 22:19:44.072 | DEBUG    | __main__:<module>:313 - Training step 18250: loss = 3.1784 | 3026.11ms | Tokens/s = 173,254.8
2025-01-17 22:20:14.302 | DEBUG    | __main__:<module>:313 - Training step 18260: loss = 2.9538 | 3020.83ms | Tokens/s = 173,557.6
2025-01-17 22:20:44.518 | DEBUG    | __main__:<module>:313 - Training step 18270: loss = 3.1055 | 3026.78ms | Tokens/s = 173,216.6
2025-01-17 22:21:14.753 | DEBUG    | __main__:<module>:313 - Training step 18280: loss = 2.9037 | 3022.26ms | Tokens/s = 173,475.5
2025-01-17 22:21:44.989 | DEBUG    | __main__:<module>:313 - Training step 18290: loss = 3.0182 | 3025.30ms | Tokens/s = 173,301.3
2025-01-17 22:22:15.256 | DEBUG    | __main__:<module>:313 - Training step 18300: loss = 2.7169 | 3024.59ms | Tokens/s = 173,341.6
2025-01-17 22:22:45.528 | DEBUG    | __main__:<module>:313 - Training step 18310: loss = 2.9241 | 3027.57ms | Tokens/s = 173,171.3
2025-01-17 22:23:15.798 | DEBUG    | __main__:<module>:313 - Training step 18320: loss = 3.1468 | 3024.07ms | Tokens/s = 173,371.5
2025-01-17 22:23:46.032 | DEBUG    | __main__:<module>:313 - Training step 18330: loss = 2.9936 | 3022.22ms | Tokens/s = 173,477.9
2025-01-17 22:24:16.271 | DEBUG    | __main__:<module>:313 - Training step 18340: loss = 3.1557 | 3026.03ms | Tokens/s = 173,259.6
2025-01-17 22:24:46.526 | DEBUG    | __main__:<module>:313 - Training step 18350: loss = 3.0029 | 3022.24ms | Tokens/s = 173,476.7
2025-01-17 22:25:16.758 | DEBUG    | __main__:<module>:313 - Training step 18360: loss = 3.0008 | 3023.59ms | Tokens/s = 173,398.9
2025-01-17 22:25:46.972 | DEBUG    | __main__:<module>:313 - Training step 18370: loss = 2.7755 | 3021.79ms | Tokens/s = 173,502.2
2025-01-17 22:26:17.190 | DEBUG    | __main__:<module>:313 - Training step 18380: loss = 2.9475 | 3023.81ms | Tokens/s = 173,386.8
2025-01-17 22:26:47.438 | DEBUG    | __main__:<module>:313 - Training step 18390: loss = 2.8555 | 3024.75ms | Tokens/s = 173,332.7
2025-01-17 22:27:17.657 | DEBUG    | __main__:<module>:313 - Training step 18400: loss = 3.0611 | 3016.14ms | Tokens/s = 173,827.6
2025-01-17 22:27:47.868 | DEBUG    | __main__:<module>:313 - Training step 18410: loss = 3.0662 | 3019.57ms | Tokens/s = 173,630.2
2025-01-17 22:28:18.079 | DEBUG    | __main__:<module>:313 - Training step 18420: loss = 3.0486 | 3022.84ms | Tokens/s = 173,442.1
2025-01-17 22:28:48.326 | DEBUG    | __main__:<module>:313 - Training step 18430: loss = 2.9121 | 3024.59ms | Tokens/s = 173,341.8
2025-01-17 22:29:18.584 | DEBUG    | __main__:<module>:313 - Training step 18440: loss = 3.0023 | 3025.47ms | Tokens/s = 173,291.2
2025-01-17 22:29:48.830 | DEBUG    | __main__:<module>:313 - Training step 18450: loss = 2.9105 | 3025.79ms | Tokens/s = 173,273.4
2025-01-17 22:30:19.094 | DEBUG    | __main__:<module>:313 - Training step 18460: loss = 2.9407 | 3026.23ms | Tokens/s = 173,247.9
2025-01-17 22:30:49.343 | DEBUG    | __main__:<module>:313 - Training step 18470: loss = 3.0893 | 3023.84ms | Tokens/s = 173,385.1
2025-01-17 22:31:19.614 | DEBUG    | __main__:<module>:313 - Training step 18480: loss = 2.9799 | 3028.58ms | Tokens/s = 173,113.7
2025-01-17 22:31:49.882 | DEBUG    | __main__:<module>:313 - Training step 18490: loss = 2.8311 | 3026.46ms | Tokens/s = 173,234.9
2025-01-17 22:32:20.148 | DEBUG    | __main__:<module>:313 - Training step 18500: loss = 2.9283 | 3027.08ms | Tokens/s = 173,199.3
2025-01-17 22:32:50.423 | DEBUG    | __main__:<module>:313 - Training step 18510: loss = 2.7756 | 3026.22ms | Tokens/s = 173,248.4
2025-01-17 22:33:20.671 | DEBUG    | __main__:<module>:313 - Training step 18520: loss = 3.0666 | 3023.31ms | Tokens/s = 173,415.2
2025-01-17 22:33:50.896 | DEBUG    | __main__:<module>:313 - Training step 18530: loss = 2.9332 | 3024.48ms | Tokens/s = 173,348.0
2025-01-17 22:34:21.127 | DEBUG    | __main__:<module>:313 - Training step 18540: loss = 3.0553 | 3023.23ms | Tokens/s = 173,419.5
2025-01-17 22:34:51.396 | DEBUG    | __main__:<module>:313 - Training step 18550: loss = 2.9752 | 3027.06ms | Tokens/s = 173,200.7
2025-01-17 22:35:21.646 | DEBUG    | __main__:<module>:313 - Training step 18560: loss = 2.9216 | 3023.08ms | Tokens/s = 173,428.4
2025-01-17 22:35:51.872 | DEBUG    | __main__:<module>:313 - Training step 18570: loss = 2.9395 | 3021.01ms | Tokens/s = 173,547.3
2025-01-17 22:36:22.089 | DEBUG    | __main__:<module>:313 - Training step 18580: loss = 3.0747 | 3022.38ms | Tokens/s = 173,468.6
2025-01-17 22:36:52.338 | DEBUG    | __main__:<module>:313 - Training step 18590: loss = 2.8995 | 3026.36ms | Tokens/s = 173,240.7
2025-01-17 22:37:22.575 | DEBUG    | __main__:<module>:313 - Training step 18600: loss = 2.9661 | 3022.45ms | Tokens/s = 173,464.5
2025-01-17 22:37:52.793 | DEBUG    | __main__:<module>:313 - Training step 18610: loss = 2.9870 | 3022.28ms | Tokens/s = 173,474.2
2025-01-17 22:38:23.000 | DEBUG    | __main__:<module>:313 - Training step 18620: loss = 2.9601 | 3020.94ms | Tokens/s = 173,551.1
2025-01-17 22:38:53.227 | DEBUG    | __main__:<module>:313 - Training step 18630: loss = 2.8460 | 3023.56ms | Tokens/s = 173,400.7
2025-01-17 22:39:23.477 | DEBUG    | __main__:<module>:313 - Training step 18640: loss = 2.9200 | 3026.80ms | Tokens/s = 173,215.2
2025-01-17 22:39:53.724 | DEBUG    | __main__:<module>:313 - Training step 18650: loss = 2.9855 | 3024.44ms | Tokens/s = 173,350.2
2025-01-17 22:40:23.948 | DEBUG    | __main__:<module>:313 - Training step 18660: loss = 2.9309 | 3021.98ms | Tokens/s = 173,491.4
2025-01-17 22:40:54.164 | DEBUG    | __main__:<module>:313 - Training step 18670: loss = 2.9201 | 3023.65ms | Tokens/s = 173,395.9
2025-01-17 22:41:24.408 | DEBUG    | __main__:<module>:313 - Training step 18680: loss = 2.7444 | 3026.86ms | Tokens/s = 173,211.9
2025-01-17 22:41:54.674 | DEBUG    | __main__:<module>:313 - Training step 18690: loss = 3.0229 | 3026.65ms | Tokens/s = 173,224.0
2025-01-17 22:42:24.934 | DEBUG    | __main__:<module>:313 - Training step 18700: loss = 3.0204 | 3022.86ms | Tokens/s = 173,440.9
2025-01-17 22:42:55.163 | DEBUG    | __main__:<module>:313 - Training step 18710: loss = 2.9950 | 3020.76ms | Tokens/s = 173,561.9
2025-01-17 22:43:25.379 | DEBUG    | __main__:<module>:313 - Training step 18720: loss = 3.0620 | 3023.18ms | Tokens/s = 173,422.4
2025-01-17 22:43:55.610 | DEBUG    | __main__:<module>:313 - Training step 18730: loss = 2.8176 | 3025.69ms | Tokens/s = 173,279.0
2025-01-17 22:44:25.875 | DEBUG    | __main__:<module>:313 - Training step 18740: loss = 2.7425 | 3028.07ms | Tokens/s = 173,142.5
2025-01-17 22:44:56.131 | DEBUG    | __main__:<module>:313 - Training step 18750: loss = 3.0608 | 3024.31ms | Tokens/s = 173,357.9
2025-01-17 22:45:26.372 | DEBUG    | __main__:<module>:313 - Training step 18760: loss = 2.9812 | 3022.90ms | Tokens/s = 173,439.0
2025-01-17 22:45:56.596 | DEBUG    | __main__:<module>:313 - Training step 18770: loss = 3.0515 | 3020.80ms | Tokens/s = 173,559.2
2025-01-17 22:46:26.802 | DEBUG    | __main__:<module>:313 - Training step 18780: loss = 2.9680 | 3020.87ms | Tokens/s = 173,555.0
2025-01-17 22:46:56.999 | DEBUG    | __main__:<module>:313 - Training step 18790: loss = 2.9532 | 3019.11ms | Tokens/s = 173,656.4
2025-01-17 22:47:27.224 | DEBUG    | __main__:<module>:313 - Training step 18800: loss = 2.9973 | 3021.97ms | Tokens/s = 173,492.2
2025-01-17 22:47:57.472 | DEBUG    | __main__:<module>:313 - Training step 18810: loss = 3.0094 | 3025.79ms | Tokens/s = 173,273.3
2025-01-17 22:48:27.730 | DEBUG    | __main__:<module>:313 - Training step 18820: loss = 2.8947 | 3023.31ms | Tokens/s = 173,415.1
2025-01-17 22:48:57.978 | DEBUG    | __main__:<module>:313 - Training step 18830: loss = 3.0458 | 3026.40ms | Tokens/s = 173,238.4
2025-01-17 22:49:28.242 | DEBUG    | __main__:<module>:313 - Training step 18840: loss = 3.0340 | 3025.60ms | Tokens/s = 173,284.1
2025-01-17 22:49:58.520 | DEBUG    | __main__:<module>:313 - Training step 18850: loss = 2.8913 | 3026.76ms | Tokens/s = 173,217.6
2025-01-17 22:50:28.762 | DEBUG    | __main__:<module>:313 - Training step 18860: loss = 2.9775 | 3021.61ms | Tokens/s = 173,512.8
2025-01-17 22:50:58.981 | DEBUG    | __main__:<module>:313 - Training step 18870: loss = 2.9903 | 3020.42ms | Tokens/s = 173,581.3
2025-01-17 22:51:29.192 | DEBUG    | __main__:<module>:313 - Training step 18880: loss = 3.0035 | 3023.24ms | Tokens/s = 173,419.3
2025-01-17 22:51:59.430 | DEBUG    | __main__:<module>:313 - Training step 18890: loss = 2.8403 | 3025.80ms | Tokens/s = 173,272.6
2025-01-17 22:52:29.689 | DEBUG    | __main__:<module>:313 - Training step 18900: loss = 2.9836 | 3024.38ms | Tokens/s = 173,353.9
2025-01-17 22:52:59.920 | DEBUG    | __main__:<module>:313 - Training step 18910: loss = 3.0406 | 3021.71ms | Tokens/s = 173,506.9
2025-01-17 22:53:30.138 | DEBUG    | __main__:<module>:313 - Training step 18920: loss = 3.0714 | 3021.95ms | Tokens/s = 173,493.4
2025-01-17 22:54:00.353 | DEBUG    | __main__:<module>:313 - Training step 18930: loss = 2.9094 | 3022.56ms | Tokens/s = 173,458.1
2025-01-17 22:54:30.586 | DEBUG    | __main__:<module>:313 - Training step 18940: loss = 3.0643 | 3024.45ms | Tokens/s = 173,349.6
2025-01-17 22:55:00.843 | DEBUG    | __main__:<module>:313 - Training step 18950: loss = 2.9279 | 3025.29ms | Tokens/s = 173,301.6
2025-01-17 22:55:31.116 | DEBUG    | __main__:<module>:313 - Training step 18960: loss = 2.8085 | 3026.96ms | Tokens/s = 173,206.2
2025-01-17 22:56:01.359 | DEBUG    | __main__:<module>:313 - Training step 18970: loss = 3.0145 | 3020.67ms | Tokens/s = 173,566.7
2025-01-17 22:56:31.569 | DEBUG    | __main__:<module>:313 - Training step 18980: loss = 2.9292 | 3021.22ms | Tokens/s = 173,535.2
2025-01-17 22:57:01.768 | DEBUG    | __main__:<module>:313 - Training step 18990: loss = 3.1264 | 3020.59ms | Tokens/s = 173,571.1
2025-01-17 22:57:35.421 | INFO     | __main__:<module>:265 - Step 19,000/20,000 loss: 2.9784 (T) 2.9849 (V) | lr=7.6e-05
2025-01-17 22:57:35.423 | INFO     | __main__:<module>:287 - Saving model to /home/v-youransun/repgpt/model... 
2025-01-17 22:57:48.559 | DEBUG    | __main__:<module>:313 - Training step 19000: loss = 2.9319 | 19596.57ms | Tokens/s = 26,754.1
2025-01-17 22:58:18.666 | DEBUG    | __main__:<module>:313 - Training step 19010: loss = 3.1129 | 3013.46ms | Tokens/s = 173,982.3
2025-01-17 22:58:48.850 | DEBUG    | __main__:<module>:313 - Training step 19020: loss = 2.8373 | 3020.17ms | Tokens/s = 173,595.2
2025-01-17 22:59:19.079 | DEBUG    | __main__:<module>:313 - Training step 19030: loss = 3.0065 | 3022.41ms | Tokens/s = 173,467.0
2025-01-17 22:59:49.329 | DEBUG    | __main__:<module>:313 - Training step 19040: loss = 3.1653 | 3027.52ms | Tokens/s = 173,173.9
2025-01-17 23:00:19.595 | DEBUG    | __main__:<module>:313 - Training step 19050: loss = 2.8400 | 3027.51ms | Tokens/s = 173,174.7
2025-01-17 23:00:49.868 | DEBUG    | __main__:<module>:313 - Training step 19060: loss = 3.0631 | 3025.30ms | Tokens/s = 173,301.3
2025-01-17 23:01:20.107 | DEBUG    | __main__:<module>:313 - Training step 19070: loss = 2.8448 | 3022.71ms | Tokens/s = 173,449.4
2025-01-17 23:01:50.325 | DEBUG    | __main__:<module>:313 - Training step 19080: loss = 3.0314 | 3020.91ms | Tokens/s = 173,552.9
2025-01-17 23:02:20.539 | DEBUG    | __main__:<module>:313 - Training step 19090: loss = 3.0290 | 3020.08ms | Tokens/s = 173,600.6
2025-01-17 23:02:50.741 | DEBUG    | __main__:<module>:313 - Training step 19100: loss = 3.1943 | 3019.45ms | Tokens/s = 173,636.7
2025-01-17 23:03:20.943 | DEBUG    | __main__:<module>:313 - Training step 19110: loss = 3.0886 | 3020.78ms | Tokens/s = 173,560.3
2025-01-17 23:03:51.164 | DEBUG    | __main__:<module>:313 - Training step 19120: loss = 3.0506 | 3023.91ms | Tokens/s = 173,381.0
2025-01-17 23:04:21.415 | DEBUG    | __main__:<module>:313 - Training step 19130: loss = 2.9671 | 3025.32ms | Tokens/s = 173,300.1
2025-01-17 23:04:51.657 | DEBUG    | __main__:<module>:313 - Training step 19140: loss = 2.9383 | 3024.02ms | Tokens/s = 173,374.2
2025-01-17 23:05:21.876 | DEBUG    | __main__:<module>:313 - Training step 19150: loss = 2.9523 | 3020.19ms | Tokens/s = 173,594.2
2025-01-17 23:05:52.080 | DEBUG    | __main__:<module>:313 - Training step 19160: loss = 2.8807 | 3021.36ms | Tokens/s = 173,527.3
2025-01-17 23:06:22.299 | DEBUG    | __main__:<module>:313 - Training step 19170: loss = 2.8549 | 3025.79ms | Tokens/s = 173,273.1
2025-01-17 23:06:52.555 | DEBUG    | __main__:<module>:313 - Training step 19180: loss = 2.9970 | 3027.13ms | Tokens/s = 173,196.2
2025-01-17 23:07:22.823 | DEBUG    | __main__:<module>:313 - Training step 19190: loss = 2.8399 | 3026.44ms | Tokens/s = 173,235.8
2025-01-17 23:07:53.082 | DEBUG    | __main__:<module>:313 - Training step 19200: loss = 2.9701 | 3023.94ms | Tokens/s = 173,379.3
2025-01-17 23:08:23.313 | DEBUG    | __main__:<module>:313 - Training step 19210: loss = 2.9455 | 3021.78ms | Tokens/s = 173,503.0
2025-01-17 23:08:53.550 | DEBUG    | __main__:<module>:313 - Training step 19220: loss = 2.9889 | 3022.13ms | Tokens/s = 173,482.9
2025-01-17 23:09:23.782 | DEBUG    | __main__:<module>:313 - Training step 19230: loss = 2.8547 | 3021.98ms | Tokens/s = 173,491.5
2025-01-17 23:09:54.036 | DEBUG    | __main__:<module>:313 - Training step 19240: loss = 2.8952 | 3028.12ms | Tokens/s = 173,139.9
2025-01-17 23:10:24.310 | DEBUG    | __main__:<module>:313 - Training step 19250: loss = 3.0086 | 3027.99ms | Tokens/s = 173,147.0
2025-01-17 23:10:54.557 | DEBUG    | __main__:<module>:313 - Training step 19260: loss = 2.8049 | 3024.31ms | Tokens/s = 173,357.8
2025-01-17 23:11:24.794 | DEBUG    | __main__:<module>:313 - Training step 19270: loss = 3.0633 | 3024.79ms | Tokens/s = 173,330.2
2025-01-17 23:11:55.013 | DEBUG    | __main__:<module>:313 - Training step 19280: loss = 2.9036 | 3022.83ms | Tokens/s = 173,442.9
2025-01-17 23:12:25.210 | DEBUG    | __main__:<module>:313 - Training step 19290: loss = 3.0292 | 3020.12ms | Tokens/s = 173,598.2
2025-01-17 23:12:55.413 | DEBUG    | __main__:<module>:313 - Training step 19300: loss = 2.9376 | 3020.95ms | Tokens/s = 173,550.9
2025-01-17 23:13:25.639 | DEBUG    | __main__:<module>:313 - Training step 19310: loss = 2.8578 | 3021.09ms | Tokens/s = 173,542.5
2025-01-17 23:13:55.860 | DEBUG    | __main__:<module>:313 - Training step 19320: loss = 2.9243 | 3021.15ms | Tokens/s = 173,539.2
2025-01-17 23:14:26.092 | DEBUG    | __main__:<module>:313 - Training step 19330: loss = 3.0150 | 3025.87ms | Tokens/s = 173,268.4
2025-01-17 23:14:56.337 | DEBUG    | __main__:<module>:313 - Training step 19340: loss = 3.0522 | 3021.92ms | Tokens/s = 173,495.2
2025-01-17 23:15:26.557 | DEBUG    | __main__:<module>:313 - Training step 19350: loss = 2.8774 | 3021.59ms | Tokens/s = 173,513.8
2025-01-17 23:15:56.794 | DEBUG    | __main__:<module>:313 - Training step 19360: loss = 3.0100 | 3025.41ms | Tokens/s = 173,294.9
2025-01-17 23:16:27.051 | DEBUG    | __main__:<module>:313 - Training step 19370: loss = 2.9833 | 3028.41ms | Tokens/s = 173,123.4
2025-01-17 23:16:57.331 | DEBUG    | __main__:<module>:313 - Training step 19380: loss = 2.8441 | 3026.52ms | Tokens/s = 173,231.2
2025-01-17 23:17:27.593 | DEBUG    | __main__:<module>:313 - Training step 19390: loss = 2.8513 | 3022.38ms | Tokens/s = 173,468.6
2025-01-17 23:17:57.826 | DEBUG    | __main__:<module>:313 - Training step 19400: loss = 3.0443 | 3021.77ms | Tokens/s = 173,503.8
2025-01-17 23:18:28.044 | DEBUG    | __main__:<module>:313 - Training step 19410: loss = 2.9869 | 3022.67ms | Tokens/s = 173,452.2
2025-01-17 23:18:58.242 | DEBUG    | __main__:<module>:313 - Training step 19420: loss = 2.9521 | 3019.29ms | Tokens/s = 173,646.3
2025-01-17 23:19:28.440 | DEBUG    | __main__:<module>:313 - Training step 19430: loss = 3.1392 | 3019.33ms | Tokens/s = 173,644.0
2025-01-17 23:19:58.671 | DEBUG    | __main__:<module>:313 - Training step 19440: loss = 2.9364 | 3025.84ms | Tokens/s = 173,270.4
2025-01-17 23:20:28.923 | DEBUG    | __main__:<module>:313 - Training step 19450: loss = 3.0649 | 3028.87ms | Tokens/s = 173,096.7
2025-01-17 23:20:59.190 | DEBUG    | __main__:<module>:313 - Training step 19460: loss = 2.9579 | 3026.83ms | Tokens/s = 173,213.5
2025-01-17 23:21:29.430 | DEBUG    | __main__:<module>:313 - Training step 19470: loss = 2.9870 | 3024.34ms | Tokens/s = 173,356.3
2025-01-17 23:21:59.651 | DEBUG    | __main__:<module>:313 - Training step 19480: loss = 3.0460 | 3021.96ms | Tokens/s = 173,492.4
2025-01-17 23:22:29.859 | DEBUG    | __main__:<module>:313 - Training step 19490: loss = 2.7950 | 3020.93ms | Tokens/s = 173,551.9
2025-01-17 23:23:00.101 | DEBUG    | __main__:<module>:313 - Training step 19500: loss = 3.0258 | 3023.98ms | Tokens/s = 173,376.7
2025-01-17 23:23:30.367 | DEBUG    | __main__:<module>:313 - Training step 19510: loss = 2.9617 | 3026.58ms | Tokens/s = 173,227.6
2025-01-17 23:24:00.625 | DEBUG    | __main__:<module>:313 - Training step 19520: loss = 2.8975 | 3024.81ms | Tokens/s = 173,329.2
2025-01-17 23:24:30.849 | DEBUG    | __main__:<module>:313 - Training step 19530: loss = 3.0465 | 3021.91ms | Tokens/s = 173,495.4
2025-01-17 23:25:01.061 | DEBUG    | __main__:<module>:313 - Training step 19540: loss = 3.0715 | 3020.97ms | Tokens/s = 173,549.7
2025-01-17 23:25:31.282 | DEBUG    | __main__:<module>:313 - Training step 19550: loss = 2.9236 | 3024.26ms | Tokens/s = 173,360.6
2025-01-17 23:26:01.538 | DEBUG    | __main__:<module>:313 - Training step 19560: loss = 2.7929 | 3027.48ms | Tokens/s = 173,176.6
2025-01-17 23:26:31.803 | DEBUG    | __main__:<module>:313 - Training step 19570: loss = 2.8943 | 3025.16ms | Tokens/s = 173,309.0
2025-01-17 23:27:02.053 | DEBUG    | __main__:<module>:313 - Training step 19580: loss = 2.9282 | 3025.75ms | Tokens/s = 173,275.3
2025-01-17 23:27:32.328 | DEBUG    | __main__:<module>:313 - Training step 19590: loss = 2.8836 | 3026.44ms | Tokens/s = 173,236.0
2025-01-17 23:28:02.578 | DEBUG    | __main__:<module>:313 - Training step 19600: loss = 3.0037 | 3023.96ms | Tokens/s = 173,378.0
2025-01-17 23:28:32.806 | DEBUG    | __main__:<module>:313 - Training step 19610: loss = 2.9974 | 3022.00ms | Tokens/s = 173,490.5
2025-01-17 23:29:03.023 | DEBUG    | __main__:<module>:313 - Training step 19620: loss = 3.0097 | 3021.03ms | Tokens/s = 173,546.1
2025-01-17 23:29:33.230 | DEBUG    | __main__:<module>:313 - Training step 19630: loss = 3.0233 | 3018.25ms | Tokens/s = 173,706.1
2025-01-17 23:30:03.421 | DEBUG    | __main__:<module>:313 - Training step 19640: loss = 2.9533 | 3020.41ms | Tokens/s = 173,581.5
2025-01-17 23:30:33.637 | DEBUG    | __main__:<module>:313 - Training step 19650: loss = 2.9719 | 3021.91ms | Tokens/s = 173,495.3
2025-01-17 23:31:03.875 | DEBUG    | __main__:<module>:313 - Training step 19660: loss = 2.9603 | 3024.66ms | Tokens/s = 173,338.1
2025-01-17 23:31:34.136 | DEBUG    | __main__:<module>:313 - Training step 19670: loss = 2.9709 | 3027.10ms | Tokens/s = 173,197.9
2025-01-17 23:32:04.371 | DEBUG    | __main__:<module>:313 - Training step 19680: loss = 2.7883 | 3023.59ms | Tokens/s = 173,399.1
2025-01-17 23:32:34.623 | DEBUG    | __main__:<module>:313 - Training step 19690: loss = 2.9037 | 3026.31ms | Tokens/s = 173,243.5
2025-01-17 23:33:04.882 | DEBUG    | __main__:<module>:313 - Training step 19700: loss = 3.1012 | 3025.16ms | Tokens/s = 173,309.1
2025-01-17 23:33:35.113 | DEBUG    | __main__:<module>:313 - Training step 19710: loss = 2.8788 | 3020.70ms | Tokens/s = 173,565.3
2025-01-17 23:34:05.317 | DEBUG    | __main__:<module>:313 - Training step 19720: loss = 3.0378 | 3020.11ms | Tokens/s = 173,599.1
2025-01-17 23:34:35.521 | DEBUG    | __main__:<module>:313 - Training step 19730: loss = 2.7948 | 3020.85ms | Tokens/s = 173,556.5
2025-01-17 23:35:05.755 | DEBUG    | __main__:<module>:313 - Training step 19740: loss = 2.9645 | 3023.71ms | Tokens/s = 173,392.2
2025-01-17 23:35:35.998 | DEBUG    | __main__:<module>:313 - Training step 19750: loss = 3.0827 | 3023.90ms | Tokens/s = 173,381.6
2025-01-17 23:36:06.231 | DEBUG    | __main__:<module>:313 - Training step 19760: loss = 2.9712 | 3024.93ms | Tokens/s = 173,322.6
2025-01-17 23:36:36.475 | DEBUG    | __main__:<module>:313 - Training step 19770: loss = 3.0305 | 3022.34ms | Tokens/s = 173,470.8
2025-01-17 23:37:06.703 | DEBUG    | __main__:<module>:313 - Training step 19780: loss = 2.8245 | 3022.94ms | Tokens/s = 173,436.3
2025-01-17 23:37:36.906 | DEBUG    | __main__:<module>:313 - Training step 19790: loss = 2.9382 | 3021.23ms | Tokens/s = 173,534.9
2025-01-17 23:38:07.134 | DEBUG    | __main__:<module>:313 - Training step 19800: loss = 3.0639 | 3023.32ms | Tokens/s = 173,414.8
2025-01-17 23:38:37.386 | DEBUG    | __main__:<module>:313 - Training step 19810: loss = 3.1153 | 3025.90ms | Tokens/s = 173,266.9
2025-01-17 23:39:07.641 | DEBUG    | __main__:<module>:313 - Training step 19820: loss = 2.9254 | 3025.84ms | Tokens/s = 173,270.4
2025-01-17 23:39:37.889 | DEBUG    | __main__:<module>:313 - Training step 19830: loss = 2.9988 | 3022.97ms | Tokens/s = 173,434.9
2025-01-17 23:40:08.105 | DEBUG    | __main__:<module>:313 - Training step 19840: loss = 2.9136 | 3024.05ms | Tokens/s = 173,372.9
2025-01-17 23:40:38.346 | DEBUG    | __main__:<module>:313 - Training step 19850: loss = 2.9784 | 3026.60ms | Tokens/s = 173,226.7
2025-01-17 23:41:08.578 | DEBUG    | __main__:<module>:313 - Training step 19860: loss = 3.0131 | 3021.86ms | Tokens/s = 173,498.6
2025-01-17 23:41:38.783 | DEBUG    | __main__:<module>:313 - Training step 19870: loss = 2.8759 | 3020.63ms | Tokens/s = 173,569.0
2025-01-17 23:42:09.024 | DEBUG    | __main__:<module>:313 - Training step 19880: loss = 2.9759 | 3022.99ms | Tokens/s = 173,433.7
2025-01-17 23:42:39.279 | DEBUG    | __main__:<module>:313 - Training step 19890: loss = 2.8871 | 3027.78ms | Tokens/s = 173,159.2
2025-01-17 23:43:09.521 | DEBUG    | __main__:<module>:313 - Training step 19900: loss = 2.9033 | 3021.27ms | Tokens/s = 173,532.4
2025-01-17 23:43:39.724 | DEBUG    | __main__:<module>:313 - Training step 19910: loss = 3.0314 | 3019.01ms | Tokens/s = 173,662.0
2025-01-17 23:44:09.919 | DEBUG    | __main__:<module>:313 - Training step 19920: loss = 3.0060 | 3019.48ms | Tokens/s = 173,635.3
2025-01-17 23:44:40.124 | DEBUG    | __main__:<module>:313 - Training step 19930: loss = 3.0325 | 3023.73ms | Tokens/s = 173,391.4
2025-01-17 23:45:10.362 | DEBUG    | __main__:<module>:313 - Training step 19940: loss = 2.7641 | 3024.20ms | Tokens/s = 173,364.2
2025-01-17 23:45:40.610 | DEBUG    | __main__:<module>:313 - Training step 19950: loss = 3.0505 | 3025.29ms | Tokens/s = 173,301.5
2025-01-17 23:46:10.871 | DEBUG    | __main__:<module>:313 - Training step 19960: loss = 3.0829 | 3025.26ms | Tokens/s = 173,303.2
2025-01-17 23:46:41.108 | DEBUG    | __main__:<module>:313 - Training step 19970: loss = 2.9106 | 3022.57ms | Tokens/s = 173,457.7
2025-01-17 23:47:11.329 | DEBUG    | __main__:<module>:313 - Training step 19980: loss = 2.8978 | 3021.34ms | Tokens/s = 173,528.4
2025-01-17 23:47:41.558 | DEBUG    | __main__:<module>:313 - Training step 19990: loss = 2.9078 | 3023.31ms | Tokens/s = 173,415.3
2025-01-17 23:48:08.680 | INFO     | __main__:<module>:319 - job_name='gpt2-training-124M-2025-01-17-06-54-52' finished in 60790.95s
2025-01-17 23:48:08.680 | INFO     | __main__:<module>:320 - Trained for 20,000 steps total_training_tokens=10,485,760,000 and achieved  best eval loss=2.9848785400390625
2025-01-17 23:48:15.246 | INFO     | __main__:<module>:345 - Loss: 2.9657 (T) 2.9747 (V) | 60800.84223985672s
